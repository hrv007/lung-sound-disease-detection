{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:08:23.943604Z",
     "iopub.status.busy": "2023-08-08T22:08:23.943229Z",
     "iopub.status.idle": "2023-08-08T22:08:32.206389Z",
     "shell.execute_reply": "2023-08-08T22:08:32.205372Z",
     "shell.execute_reply.started": "2023-08-08T22:08:23.943574Z"
    },
    "id": "EXy5Ggoqczap"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2023-08-08T22:08:32.209052Z",
     "iopub.status.busy": "2023-08-08T22:08:32.208301Z",
     "iopub.status.idle": "2023-08-08T22:08:32.232941Z",
     "shell.execute_reply": "2023-08-08T22:08:32.231815Z",
     "shell.execute_reply.started": "2023-08-08T22:08:32.209018Z"
    },
    "id": "ArtW5CVwuApp",
    "outputId": "fe2935a3-842f-4305-996a-bb1edcb03165"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>101</th>\n",
       "      <th>URTI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103</td>\n",
       "      <td>Asthma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>COPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>URTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106</td>\n",
       "      <td>COPD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   101     URTI\n",
       "0  102  Healthy\n",
       "1  103   Asthma\n",
       "2  104     COPD\n",
       "3  105     URTI\n",
       "4  106     COPD"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/transferlearning-ls-data/patient_diagnosis.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:08:32.234859Z",
     "iopub.status.busy": "2023-08-08T22:08:32.234302Z",
     "iopub.status.idle": "2023-08-08T22:08:32.245210Z",
     "shell.execute_reply": "2023-08-08T22:08:32.244280Z",
     "shell.execute_reply.started": "2023-08-08T22:08:32.234811Z"
    },
    "id": "eAdDHbX6u_iz"
   },
   "outputs": [],
   "source": [
    "sr_no = {'101':'URTI'}\n",
    "for i, j in zip(df['101'].unique(), df['URTI']):\n",
    "    sr_no[str(i)] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-08T22:08:32.249776Z",
     "iopub.status.busy": "2023-08-08T22:08:32.248909Z",
     "iopub.status.idle": "2023-08-08T22:08:32.256064Z",
     "shell.execute_reply": "2023-08-08T22:08:32.254975Z",
     "shell.execute_reply.started": "2023-08-08T22:08:32.249745Z"
    },
    "id": "1j95yfuivIOL",
    "outputId": "c4ce184c-bb32-43e4-acbb-ef143254077e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_no.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:08:32.257747Z",
     "iopub.status.busy": "2023-08-08T22:08:32.257405Z",
     "iopub.status.idle": "2023-08-08T22:08:32.467987Z",
     "shell.execute_reply": "2023-08-08T22:08:32.467016Z",
     "shell.execute_reply.started": "2023-08-08T22:08:32.257717Z"
    },
    "id": "k_apddzYvK_5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "sound_files = os.listdir('/kaggle/input/transferlearning-ls-data/Mel Spectrogram/Mel Spectrogram/Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-08-08T22:08:32.469745Z",
     "iopub.status.busy": "2023-08-08T22:08:32.469327Z",
     "iopub.status.idle": "2023-08-08T22:08:32.507016Z",
     "shell.execute_reply": "2023-08-08T22:08:32.505867Z",
     "shell.execute_reply.started": "2023-08-08T22:08:32.469713Z"
    },
    "id": "jNTE66gVvVEg",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['176_2b3_Lr_mc_AKGC417L.png'],\n",
       " ['112_1p1_Pr_sc_Litt3200.png'],\n",
       " ['130_2b2_Pr_mc_AKGC417L.png'],\n",
       " ['193_7b3_Ll_mc_AKGC417L.png'],\n",
       " ['156_5b3_Pl_mc_AKGC417L.png'],\n",
       " ['162_2b2_Tc_mc_AKGC417L.png'],\n",
       " ['134_2b3_Ar_mc_LittC2SE.png'],\n",
       " ['160_1b4_Tc_mc_AKGC417L.png'],\n",
       " ['200_2p4_Pl_mc_AKGC417L.png'],\n",
       " ['169_1b2_Ll_sc_Meditron.png'],\n",
       " ['144_1b1_Tc_sc_Meditron.png'],\n",
       " ['160_2b4_Pl_mc_AKGC417L.png'],\n",
       " ['133_2p3_Pr_mc_AKGC417L.png'],\n",
       " ['205_1b3_Al_mc_AKGC417L.png'],\n",
       " ['130_3p4_Tc_mc_AKGC417L.png'],\n",
       " ['130_1p4_Lr_mc_AKGC417L.png'],\n",
       " ['200_3p4_Pl_mc_AKGC417L.png'],\n",
       " ['107_2b4_Ar_mc_AKGC417L.png'],\n",
       " ['203_2p3_Al_mc_AKGC417L.png'],\n",
       " ['113_1b1_Ar_sc_Litt3200.png'],\n",
       " ['174_2p3_Al_mc_AKGC417L.png'],\n",
       " ['178_1b2_Lr_mc_AKGC417L.png'],\n",
       " ['172_1b5_Ll_mc_AKGC417L.png'],\n",
       " ['216_1b1_Al_sc_Meditron.png'],\n",
       " ['205_4b2_Pl_mc_AKGC417L.png'],\n",
       " ['177_1b2_Lr_mc_AKGC417L.png'],\n",
       " ['151_2p4_Ll_mc_AKGC417L.png'],\n",
       " ['141_1b1_Pr_mc_LittC2SE.png'],\n",
       " ['162_1b2_Lr_mc_AKGC417L.png'],\n",
       " ['133_3p4_Tc_mc_AKGC417L.png'],\n",
       " ['147_2b3_Ll_mc_AKGC417L.png'],\n",
       " ['143_1b1_Al_sc_Meditron.png'],\n",
       " ['218_1p1_Pr_sc_Litt3200.png'],\n",
       " ['138_2p2_Al_mc_AKGC417L.png'],\n",
       " ['113_1b1_Al_sc_Litt3200.png'],\n",
       " ['144_1b1_Al_sc_Meditron.png'],\n",
       " ['130_1p4_Pl_mc_AKGC417L.png'],\n",
       " ['185_1b1_Ar_sc_Litt3200.png'],\n",
       " ['138_1p3_Pl_mc_AKGC417L.png'],\n",
       " ['122_2b2_Ar_mc_LittC2SE.png'],\n",
       " ['126_1b1_Al_sc_Meditron.png'],\n",
       " ['140_2b3_Ll_mc_LittC2SE.png'],\n",
       " ['160_1b3_Al_mc_AKGC417L.png'],\n",
       " ['186_2b4_Pr_mc_AKGC417L.png'],\n",
       " ['176_2b3_Pr_mc_AKGC417L.png'],\n",
       " ['160_1b2_Al_mc_AKGC417L.png'],\n",
       " ['136_1b1_Ar_sc_Meditron.png'],\n",
       " ['172_2b5_Tc_mc_AKGC417L.png'],\n",
       " ['176_2b3_Pl_mc_AKGC417L.png'],\n",
       " ['178_2b2_Lr_mc_AKGC417L.png'],\n",
       " ['162_1b2_Al_mc_AKGC417L.png'],\n",
       " ['133_2p2_Tc_mc_AKGC417L.png'],\n",
       " ['205_4b2_Al_mc_AKGC417L.png'],\n",
       " ['113_1b1_Pl_sc_Litt3200.png'],\n",
       " ['178_2b2_Ar_mc_AKGC417L.png'],\n",
       " ['156_5b3_Pr_mc_AKGC417L.png'],\n",
       " ['198_6p1_Ar_mc_AKGC417L.png'],\n",
       " ['213_1p3_Pr_mc_AKGC417L.png'],\n",
       " ['170_1b2_Ar_mc_AKGC417L.png'],\n",
       " ['204_7p5_Lr_mc_AKGC417L.png'],\n",
       " ['107_2b3_Pl_mc_AKGC417L.png'],\n",
       " ['176_2b3_Tc_mc_AKGC417L.png'],\n",
       " ['197_1b1_Tc_sc_Meditron.png'],\n",
       " ['196_1b1_Pr_sc_Meditron.png'],\n",
       " ['130_1p2_Pr_mc_AKGC417L.png'],\n",
       " ['146_8p3_Ar_mc_AKGC417L.png'],\n",
       " ['151_3p2_Ar_mc_AKGC417L.png'],\n",
       " ['141_1b2_Tc_mc_LittC2SE.png'],\n",
       " ['103_2b2_Ar_mc_LittC2SE.png'],\n",
       " ['211_2p4_Tc_mc_AKGC417L.png'],\n",
       " ['160_1b4_Pr_mc_AKGC417L.png'],\n",
       " ['176_1b4_Lr_mc_AKGC417L.png'],\n",
       " ['156_8b3_Ll_mc_AKGC417L.png'],\n",
       " ['205_4b2_Pr_mc_AKGC417L.png'],\n",
       " ['172_1b3_Tc_mc_AKGC417L.png'],\n",
       " ['133_2p3_Pl_mc_AKGC417L.png'],\n",
       " ['154_4b4_Pl_mc_AKGC417L.png'],\n",
       " ['176_1b4_Tc_mc_AKGC417L.png'],\n",
       " ['107_3p2_Tc_mc_AKGC417L.png'],\n",
       " ['114_1b4_Al_mc_AKGC417L.png'],\n",
       " ['207_2b4_Tc_mc_AKGC417L.png'],\n",
       " ['130_2p5_Lr_mc_AKGC417L.png'],\n",
       " ['198_6p1_Pl_mc_AKGC417L.png'],\n",
       " ['138_1p4_Ar_mc_AKGC417L.png'],\n",
       " ['151_2p3_Ar_mc_AKGC417L.png'],\n",
       " ['147_2b4_Pl_mc_AKGC417L.png'],\n",
       " ['198_1b5_Lr_mc_AKGC417L.png'],\n",
       " ['135_2b1_Tc_mc_LittC2SE.png'],\n",
       " ['200_2p2_Tc_mc_AKGC417L.png'],\n",
       " ['159_1b1_Pr_sc_Meditron.png'],\n",
       " ['186_2b4_Ar_mc_AKGC417L.png'],\n",
       " ['156_2b3_Ar_mc_AKGC417L.png'],\n",
       " ['116_1b2_Tc_sc_Meditron.png'],\n",
       " ['156_2b3_Pl_mc_AKGC417L.png'],\n",
       " ['213_2p2_Ar_mc_AKGC417L.png'],\n",
       " ['213_1p3_Ar_mc_AKGC417L.png'],\n",
       " ['120_1b1_Al_sc_Meditron.png'],\n",
       " ['160_1b3_Lr_mc_AKGC417L.png'],\n",
       " ['207_2b2_Pr_mc_AKGC417L.png'],\n",
       " ['177_1b2_Al_mc_AKGC417L.png'],\n",
       " ['221_2b2_Al_mc_LittC2SE.png'],\n",
       " ['133_2p4_Al_mc_AKGC417L.png'],\n",
       " ['154_2b4_Tc_mc_AKGC417L.png'],\n",
       " ['205_2b3_Ll_mc_AKGC417L.png'],\n",
       " ['178_1b3_Tc_mc_AKGC417L.png'],\n",
       " ['158_1p4_Al_mc_AKGC417L.png'],\n",
       " ['205_3b4_Ar_mc_AKGC417L.png'],\n",
       " ['159_1b1_Ll_sc_Meditron.png'],\n",
       " ['138_2p2_Ll_mc_AKGC417L.png'],\n",
       " ['205_1b3_Ll_mc_AKGC417L.png'],\n",
       " ['176_1b4_Pl_mc_AKGC417L.png'],\n",
       " ['162_2b4_Ar_mc_AKGC417L.png'],\n",
       " ['151_2p4_Lr_mc_AKGC417L.png'],\n",
       " ['207_2b3_Ar_mc_AKGC417L.png'],\n",
       " ['135_2b3_Al_mc_LittC2SE.png'],\n",
       " ['151_2p3_Ll_mc_AKGC417L.png'],\n",
       " ['101_1b1_Pr_sc_Meditron.png'],\n",
       " ['104_1b1_Ar_sc_Litt3200.png'],\n",
       " ['135_2b3_Pr_mc_LittC2SE.png'],\n",
       " ['151_3p2_Tc_mc_AKGC417L.png'],\n",
       " ['170_2b2_Lr_mc_AKGC417L.png'],\n",
       " ['140_2b2_Tc_mc_LittC2SE.png'],\n",
       " ['218_1p1_Pl_sc_Litt3200.png'],\n",
       " ['170_1b4_Tc_mc_AKGC417L.png'],\n",
       " ['192_2b3_Ar_mc_LittC2SE.png'],\n",
       " ['200_2p4_Al_mc_AKGC417L.png'],\n",
       " ['204_7p5_Ar_mc_AKGC417L.png'],\n",
       " ['178_2b2_Tc_mc_AKGC417L.png'],\n",
       " ['135_2b3_Tc_mc_LittC2SE.png'],\n",
       " ['221_2b2_Lr_mc_LittC2SE.png'],\n",
       " ['130_3b4_Pr_mc_AKGC417L.png'],\n",
       " ['162_2b4_Pl_mc_AKGC417L.png'],\n",
       " ['138_1p2_Ll_mc_AKGC417L.png'],\n",
       " ['109_1b1_Lr_sc_Litt3200.png'],\n",
       " ['213_1p2_Tc_mc_AKGC417L.png'],\n",
       " ['122_2b2_Tc_mc_LittC2SE.png'],\n",
       " ['174_1p4_Tc_mc_AKGC417L.png'],\n",
       " ['122_2b1_Tc_mc_LittC2SE.png'],\n",
       " ['141_1b2_Ar_mc_LittC2SE.png'],\n",
       " ['198_6p1_Lr_mc_AKGC417L.png'],\n",
       " ['149_1b1_Al_sc_Meditron.png'],\n",
       " ['176_2b3_Al_mc_AKGC417L.png'],\n",
       " ['107_2b5_Tc_mc_AKGC417L.png'],\n",
       " ['109_1b1_Al_sc_Litt3200.png'],\n",
       " ['213_1p5_Pl_mc_AKGC417L.png'],\n",
       " ['158_1p4_Tc_mc_AKGC417L.png'],\n",
       " ['200_2p3_Pl_mc_AKGC417L.png'],\n",
       " ['177_1b2_Pl_mc_AKGC417L.png'],\n",
       " ['151_2p3_Al_mc_AKGC417L.png'],\n",
       " ['147_2b2_Pl_mc_AKGC417L.png'],\n",
       " ['175_1b1_Pr_sc_Litt3200.png'],\n",
       " ['157_1b1_Ar_sc_Meditron.png'],\n",
       " ['122_2b3_Tc_mc_LittC2SE.png'],\n",
       " ['203_1p3_Tc_mc_AKGC417L.png'],\n",
       " ['166_1p1_Pl_sc_Meditron.png'],\n",
       " ['213_1p2_Al_mc_AKGC417L.png'],\n",
       " ['215_1b3_Tc_sc_Meditron.png'],\n",
       " ['110_1p1_Ll_sc_Meditron.png'],\n",
       " ['200_2p2_Ar_mc_AKGC417L.png'],\n",
       " ['202_1b1_Ar_sc_Meditron.png'],\n",
       " ['158_1p2_Lr_mc_AKGC417L.png'],\n",
       " ['147_1b2_Tc_mc_AKGC417L.png'],\n",
       " ['147_2b3_Ar_mc_AKGC417L.png'],\n",
       " ['174_2p3_Tc_mc_AKGC417L.png'],\n",
       " ['200_3p4_Al_mc_AKGC417L.png'],\n",
       " ['213_2p2_Pl_mc_AKGC417L.png'],\n",
       " ['177_1b2_Pr_mc_AKGC417L.png'],\n",
       " ['204_7p5_Ll_mc_AKGC417L.png'],\n",
       " ['162_2b3_Pr_mc_AKGC417L.png'],\n",
       " ['117_1b2_Tc_mc_LittC2SE.png'],\n",
       " ['140_2b2_Ll_mc_LittC2SE.png'],\n",
       " ['222_1b1_Lr_sc_Meditron.png'],\n",
       " ['130_2b2_Ll_mc_AKGC417L.png'],\n",
       " ['130_2p5_Pl_mc_AKGC417L.png'],\n",
       " ['172_2b5_Al_mc_AKGC417L.png'],\n",
       " ['147_2b4_Lr_mc_AKGC417L.png'],\n",
       " ['138_1p3_Ll_mc_AKGC417L.png'],\n",
       " ['138_1p4_Ll_mc_AKGC417L.png'],\n",
       " ['160_2b4_Ar_mc_AKGC417L.png'],\n",
       " ['147_2b2_Ar_mc_AKGC417L.png'],\n",
       " ['141_1b3_Ar_mc_LittC2SE.png'],\n",
       " ['124_1b1_Ll_sc_Litt3200.png'],\n",
       " ['178_1b3_Pl_mc_AKGC417L.png'],\n",
       " ['107_3p2_Ll_mc_AKGC417L.png'],\n",
       " ['130_2p5_Tc_mc_AKGC417L.png'],\n",
       " ['106_2b1_Pl_mc_LittC2SE.png'],\n",
       " ['198_1b5_Ar_mc_AKGC417L.png'],\n",
       " ['193_7b3_Pr_mc_AKGC417L.png'],\n",
       " ['198_1b5_Pr_mc_AKGC417L.png'],\n",
       " ['203_1p4_Al_mc_AKGC417L.png'],\n",
       " ['201_1b3_Ar_sc_Meditron.png'],\n",
       " ['146_2b4_Ll_mc_AKGC417L.png'],\n",
       " ['208_1b1_Ll_sc_Meditron.png'],\n",
       " ['138_2p2_Tc_mc_AKGC417L.png'],\n",
       " ['158_1p3_Ll_mc_AKGC417L.png'],\n",
       " ['178_1b6_Ll_mc_AKGC417L.png'],\n",
       " ['130_2p5_Pr_mc_AKGC417L.png'],\n",
       " ['133_2p4_Pr_mc_AKGC417L.png'],\n",
       " ['195_1b1_Pr_sc_Litt3200.png'],\n",
       " ['170_2b2_Pl_mc_AKGC417L.png'],\n",
       " ['107_2b5_Lr_mc_AKGC417L.png'],\n",
       " ['170_1b3_Lr_mc_AKGC417L.png'],\n",
       " ['174_1p3_Pl_mc_AKGC417L.png'],\n",
       " ['200_3p4_Ar_mc_AKGC417L.png'],\n",
       " ['178_1b6_Pr_mc_AKGC417L.png'],\n",
       " ['205_1b3_Ar_mc_AKGC417L.png'],\n",
       " ['198_6p1_Tc_mc_AKGC417L.png'],\n",
       " ['107_3p2_Pr_mc_AKGC417L.png'],\n",
       " ['174_1p2_Pr_mc_AKGC417L.png'],\n",
       " ['205_2b3_Ar_mc_AKGC417L.png'],\n",
       " ['188_1b1_Ar_sc_Meditron.png'],\n",
       " ['151_2p4_Pr_mc_AKGC417L.png'],\n",
       " ['176_1b3_Tc_mc_AKGC417L.png'],\n",
       " ['138_1p2_Pr_mc_AKGC417L.png'],\n",
       " ['174_1p4_Ar_mc_AKGC417L.png'],\n",
       " ['158_1p4_Pl_mc_AKGC417L.png'],\n",
       " ['158_1p3_Pl_mc_AKGC417L.png'],\n",
       " ['205_2b2_Pr_mc_AKGC417L.png'],\n",
       " ['198_6p1_Al_mc_AKGC417L.png'],\n",
       " ['170_1b2_Pl_mc_AKGC417L.png'],\n",
       " ['203_2p3_Tc_mc_AKGC417L.png'],\n",
       " ['130_3p2_Ar_mc_AKGC417L.png'],\n",
       " ['178_1b3_Al_mc_AKGC417L.png'],\n",
       " ['188_1b1_Tc_sc_Meditron.png'],\n",
       " ['147_2b2_Al_mc_AKGC417L.png'],\n",
       " ['218_1b1_Ar_sc_Meditron.png'],\n",
       " ['130_2b2_Pl_mc_AKGC417L.png'],\n",
       " ['205_1b3_Pr_mc_AKGC417L.png'],\n",
       " ['130_2p3_Pl_mc_AKGC417L.png'],\n",
       " ['172_1b3_Pr_mc_AKGC417L.png'],\n",
       " ['200_2p2_Pr_mc_AKGC417L.png'],\n",
       " ['205_1b3_Lr_mc_AKGC417L.png'],\n",
       " ['156_8b3_Lr_mc_AKGC417L.png'],\n",
       " ['200_2p2_Al_mc_AKGC417L.png'],\n",
       " ['133_3p2_Pr_mc_AKGC417L.png'],\n",
       " ['176_1b3_Lr_mc_AKGC417L.png'],\n",
       " ['135_2b2_Tc_mc_LittC2SE.png'],\n",
       " ['207_2b2_Tc_mc_AKGC417L.png'],\n",
       " ['180_1b4_Al_mc_AKGC417L.png'],\n",
       " ['120_1b1_Lr_sc_Meditron.png'],\n",
       " ['158_1p3_Pr_mc_AKGC417L.png'],\n",
       " ['154_2b4_Ar_mc_AKGC417L.png'],\n",
       " ['130_3b4_Pl_mc_AKGC417L.png'],\n",
       " ['107_2b3_Lr_mc_AKGC417L.png'],\n",
       " ['107_2b5_Ll_mc_AKGC417L.png'],\n",
       " ['211_1p2_Pr_mc_AKGC417L.png'],\n",
       " ['225_1b1_Pl_sc_Meditron.png'],\n",
       " ['207_2b4_Al_mc_AKGC417L.png'],\n",
       " ['154_3b3_Ar_mc_AKGC417L.png'],\n",
       " ['113_1b1_Pr_sc_Litt3200.png'],\n",
       " ['135_2b2_Al_mc_LittC2SE.png'],\n",
       " ['213_1p2_Pr_mc_AKGC417L.png'],\n",
       " ['207_2b3_Pr_mc_AKGC417L.png'],\n",
       " ['172_2b5_Lr_mc_AKGC417L.png'],\n",
       " ['191_2b2_Tc_mc_LittC2SE.png'],\n",
       " ['130_1p3_Ar_mc_AKGC417L.png'],\n",
       " ['162_1b2_Ll_mc_AKGC417L.png'],\n",
       " ['201_1b3_Al_sc_Meditron.png'],\n",
       " ['201_1b1_Ar_sc_Meditron.png'],\n",
       " ['213_2p2_Pr_mc_AKGC417L.png'],\n",
       " ['206_1b1_Ar_sc_Meditron.png'],\n",
       " ['178_1b3_Lr_mc_AKGC417L.png'],\n",
       " ['221_2b3_Lr_mc_LittC2SE.png'],\n",
       " ['200_2p3_Lr_mc_AKGC417L.png'],\n",
       " ['129_1b1_Ar_sc_Meditron.png'],\n",
       " ['192_2b3_Al_mc_LittC2SE.png'],\n",
       " ['221_2b3_Pr_mc_LittC2SE.png'],\n",
       " ['160_1b3_Pr_mc_AKGC417L.png'],\n",
       " ['130_2b3_Pl_mc_AKGC417L.png'],\n",
       " ['170_1b3_Al_mc_AKGC417L.png'],\n",
       " ['181_1b3_Tc_mc_LittC2SE.png'],\n",
       " ['141_1b3_Al_mc_LittC2SE.png'],\n",
       " ['186_3b3_Ar_mc_AKGC417L.png'],\n",
       " ['133_3p2_Ar_mc_AKGC417L.png'],\n",
       " ['162_1b2_Ar_mc_AKGC417L.png'],\n",
       " ['198_6p1_Ll_mc_AKGC417L.png'],\n",
       " ['130_3p2_Al_mc_AKGC417L.png'],\n",
       " ['203_2p3_Pl_mc_AKGC417L.png'],\n",
       " ['118_1b1_Al_sc_Litt3200.png'],\n",
       " ['162_2b2_Pl_mc_AKGC417L.png'],\n",
       " ['130_1p2_Tc_mc_AKGC417L.png'],\n",
       " ['104_1b1_Al_sc_Litt3200.png'],\n",
       " ['151_3p2_Lr_mc_AKGC417L.png'],\n",
       " ['205_3b4_Pr_mc_AKGC417L.png'],\n",
       " ['213_1p2_Pl_mc_AKGC417L.png'],\n",
       " ['158_1p4_Lr_mc_AKGC417L.png'],\n",
       " ['124_1b1_Lr_sc_Litt3200.png'],\n",
       " ['193_7b3_Lr_mc_AKGC417L.png'],\n",
       " ['192_2b1_Al_mc_LittC2SE.png'],\n",
       " ['220_1b1_Tc_mc_LittC2SE.png'],\n",
       " ['164_1b1_Ll_sc_Meditron.png'],\n",
       " ['154_4b4_Al_mc_AKGC417L.png'],\n",
       " ['198_1b5_Ll_mc_AKGC417L.png'],\n",
       " ['147_1b4_Tc_mc_AKGC417L.png'],\n",
       " ['130_3p3_Al_mc_AKGC417L.png'],\n",
       " ['170_1b2_Lr_mc_AKGC417L.png'],\n",
       " ['200_2p3_Tc_mc_AKGC417L.png'],\n",
       " ['181_1b2_Ar_mc_LittC2SE.png'],\n",
       " ['124_1b1_Ar_sc_Litt3200.png'],\n",
       " ['130_3p3_Pr_mc_AKGC417L.png'],\n",
       " ['166_1p1_Ar_sc_Meditron.png'],\n",
       " ['224_1b1_Tc_sc_Meditron.png'],\n",
       " ['130_3p4_Pl_mc_AKGC417L.png'],\n",
       " ['203_2p3_Ar_mc_AKGC417L.png'],\n",
       " ['215_1b2_Ar_sc_Meditron.png'],\n",
       " ['211_1p2_Pl_mc_AKGC417L.png'],\n",
       " ['172_2b5_Ar_mc_AKGC417L.png'],\n",
       " ['147_1b3_Tc_mc_AKGC417L.png'],\n",
       " ['176_1b3_Ar_mc_AKGC417L.png'],\n",
       " ['154_3b3_Ll_mc_AKGC417L.png'],\n",
       " ['122_2b1_Ar_mc_LittC2SE.png'],\n",
       " ['192_2b2_Al_mc_LittC2SE.png'],\n",
       " ['172_1b3_Lr_mc_AKGC417L.png'],\n",
       " ['130_2b3_Al_mc_AKGC417L.png'],\n",
       " ['207_2b2_Al_mc_AKGC417L.png'],\n",
       " ['112_1p1_Ll_sc_Litt3200.png'],\n",
       " ['117_1b3_Tc_mc_LittC2SE.png'],\n",
       " ['203_1p4_Tc_mc_AKGC417L.png'],\n",
       " ['135_2b2_Pl_mc_LittC2SE.png'],\n",
       " ['156_8b3_Pl_mc_AKGC417L.png'],\n",
       " ['133_3p2_Al_mc_AKGC417L.png'],\n",
       " ['130_2p5_Al_mc_AKGC417L.png'],\n",
       " ['162_2b2_Al_mc_AKGC417L.png'],\n",
       " ['141_1b3_Pr_mc_LittC2SE.png'],\n",
       " ['195_1b1_Ll_sc_Litt3200.png'],\n",
       " ['199_2b3_Ll_mc_LittC2SE.png'],\n",
       " ['108_1b1_Al_sc_Meditron.png'],\n",
       " ['138_1p3_Lr_mc_AKGC417L.png'],\n",
       " ['122_2b1_Al_mc_LittC2SE.png'],\n",
       " ['130_1p3_Tc_mc_AKGC417L.png'],\n",
       " ['163_2b2_Pl_mc_AKGC417L.png'],\n",
       " ['158_1p2_Ll_mc_AKGC417L.png'],\n",
       " ['163_2b2_Ar_mc_AKGC417L.png'],\n",
       " ['133_2p4_Pl_mc_AKGC417L.png'],\n",
       " ['174_1p3_Ll_mc_AKGC417L.png'],\n",
       " ['162_1b2_Pl_mc_AKGC417L.png'],\n",
       " ['162_1b2_Tc_mc_AKGC417L.png'],\n",
       " ['172_1b4_Ll_mc_AKGC417L.png'],\n",
       " ['191_2b1_Pr_mc_LittC2SE.png'],\n",
       " ['204_7p5_Pr_mc_AKGC417L.png'],\n",
       " ['193_1b2_Al_mc_AKGC417L.png'],\n",
       " ['135_2b1_Al_mc_LittC2SE.png'],\n",
       " ['107_2b4_Lr_mc_AKGC417L.png'],\n",
       " ['154_1b3_Lr_mc_AKGC417L.png'],\n",
       " ['107_3p2_Pl_mc_AKGC417L.png'],\n",
       " ['219_2b2_Tc_mc_LittC2SE.png'],\n",
       " ['170_1b4_Lr_mc_AKGC417L.png'],\n",
       " ['158_1p4_Ar_mc_AKGC417L.png'],\n",
       " ['135_2b2_Ar_mc_LittC2SE.png'],\n",
       " ['207_2b3_Tc_mc_AKGC417L.png'],\n",
       " ['163_2b2_Ll_mc_AKGC417L.png'],\n",
       " ['130_2b3_Tc_mc_AKGC417L.png'],\n",
       " ['123_1b1_Al_sc_Meditron.png'],\n",
       " ['145_2b2_Pr_mc_AKGC417L.png'],\n",
       " ['145_3b4_Pl_mc_AKGC417L.png'],\n",
       " ['160_1b3_Pl_mc_AKGC417L.png'],\n",
       " ['150_1b2_Al_sc_Meditron.png'],\n",
       " ['151_2p3_Tc_mc_AKGC417L.png'],\n",
       " ['187_1b1_Ll_sc_Meditron.png'],\n",
       " ['204_2b5_Ll_mc_AKGC417L.png'],\n",
       " ['138_1p3_Tc_mc_AKGC417L.png'],\n",
       " ['133_2p4_Tc_mc_AKGC417L.png'],\n",
       " ['160_2b4_Tc_mc_AKGC417L.png'],\n",
       " ['156_2b3_Pr_mc_AKGC417L.png'],\n",
       " ['160_1b4_Al_mc_AKGC417L.png'],\n",
       " ['176_1b4_Pr_mc_AKGC417L.png'],\n",
       " ['207_3b2_Ar_mc_AKGC417L.png'],\n",
       " ['176_1b3_Pr_mc_AKGC417L.png'],\n",
       " ['176_2b3_Ar_mc_AKGC417L.png'],\n",
       " ['186_3b3_Pl_mc_AKGC417L.png'],\n",
       " ['148_1b1_Al_sc_Meditron.png'],\n",
       " ['167_1b1_Al_sc_Meditron.png'],\n",
       " ['176_1b4_Al_mc_AKGC417L.png'],\n",
       " ['141_1b2_Pr_mc_LittC2SE.png'],\n",
       " ['170_2b2_Pr_mc_AKGC417L.png'],\n",
       " ['139_1b1_Al_sc_Litt3200.png'],\n",
       " ['178_1b2_Ar_mc_AKGC417L.png'],\n",
       " ['151_2p2_Ll_mc_AKGC417L.png'],\n",
       " ['200_2p3_Pr_mc_AKGC417L.png'],\n",
       " ['221_2b2_Pl_mc_LittC2SE.png'],\n",
       " ['154_4b4_Ar_mc_AKGC417L.png'],\n",
       " ['138_1p2_Lr_mc_AKGC417L.png'],\n",
       " ['133_2p4_Ar_mc_AKGC417L.png'],\n",
       " ['172_1b4_Pl_mc_AKGC417L.png'],\n",
       " ['217_1b1_Tc_sc_Meditron.png'],\n",
       " ['222_1b1_Ar_sc_Meditron.png'],\n",
       " ['162_2b4_Al_mc_AKGC417L.png'],\n",
       " ['199_2b1_Ll_mc_LittC2SE.png'],\n",
       " ['130_1p4_Al_mc_AKGC417L.png'],\n",
       " ['193_1b2_Pr_mc_AKGC417L.png'],\n",
       " ['166_1p1_Ll_sc_Meditron.png'],\n",
       " ['174_1p2_Ar_mc_AKGC417L.png'],\n",
       " ['153_1b1_Al_sc_Meditron.png'],\n",
       " ['101_1b1_Al_sc_Meditron.png'],\n",
       " ['130_3b4_Ar_mc_AKGC417L.png'],\n",
       " ['146_2b4_Al_mc_AKGC417L.png'],\n",
       " ['130_2b3_Lr_mc_AKGC417L.png'],\n",
       " ['120_1b1_Ar_sc_Meditron.png'],\n",
       " ['177_1b2_Tc_mc_AKGC417L.png'],\n",
       " ['178_1b6_Tc_mc_AKGC417L.png'],\n",
       " ['207_3b2_Tc_mc_AKGC417L.png'],\n",
       " ['197_1b1_Al_sc_Meditron.png'],\n",
       " ['207_2b4_Pl_mc_AKGC417L.png'],\n",
       " ['200_2p4_Pr_mc_AKGC417L.png'],\n",
       " ['174_1p2_Lr_mc_AKGC417L.png'],\n",
       " ['130_2b4_Al_mc_AKGC417L.png'],\n",
       " ['107_2b3_Ar_mc_AKGC417L.png'],\n",
       " ['122_2b3_Al_mc_LittC2SE.png'],\n",
       " ['213_1p5_Ar_mc_AKGC417L.png'],\n",
       " ['138_1p4_Tc_mc_AKGC417L.png'],\n",
       " ['203_1p4_Pl_mc_AKGC417L.png'],\n",
       " ['177_1b4_Ar_mc_AKGC417L.png'],\n",
       " ['163_2b2_Lr_mc_AKGC417L.png'],\n",
       " ['130_1p4_Ll_mc_AKGC417L.png'],\n",
       " ['146_8p3_Lr_mc_AKGC417L.png'],\n",
       " ['122_2b2_Al_mc_LittC2SE.png'],\n",
       " ['151_2p4_Tc_mc_AKGC417L.png'],\n",
       " ['146_2b4_Pr_mc_AKGC417L.png'],\n",
       " ['107_3p2_Ar_mc_AKGC417L.png'],\n",
       " ['206_1b1_Lr_sc_Meditron.png'],\n",
       " ['176_1b3_Ll_mc_AKGC417L.png'],\n",
       " ['158_1p2_Al_mc_AKGC417L.png'],\n",
       " ['213_1p5_Tc_mc_AKGC417L.png'],\n",
       " ['157_1b1_Lr_sc_Meditron.png'],\n",
       " ['170_1b2_Tc_mc_AKGC417L.png'],\n",
       " ['198_1b5_Tc_mc_AKGC417L.png'],\n",
       " ['172_1b4_Pr_mc_AKGC417L.png'],\n",
       " ['130_3p2_Pl_mc_AKGC417L.png'],\n",
       " ['161_1b1_Al_sc_Meditron.png'],\n",
       " ['172_1b4_Lr_mc_AKGC417L.png'],\n",
       " ['213_1p2_Ar_mc_AKGC417L.png'],\n",
       " ['151_3p2_Pl_mc_AKGC417L.png'],\n",
       " ['204_7p5_Tc_mc_AKGC417L.png'],\n",
       " ['165_1b1_Pl_sc_Meditron.png'],\n",
       " ['170_1b4_Al_mc_AKGC417L.png'],\n",
       " ['211_1p2_Ar_mc_AKGC417L.png'],\n",
       " ['178_1b2_Tc_mc_AKGC417L.png'],\n",
       " ['139_1b1_Ll_sc_Litt3200.png'],\n",
       " ['151_2p2_Pl_mc_AKGC417L.png'],\n",
       " ['177_1b2_Ar_mc_AKGC417L.png'],\n",
       " ['130_2b2_Ar_mc_AKGC417L.png'],\n",
       " ['160_2b4_Pr_mc_AKGC417L.png'],\n",
       " ['174_1p3_Pr_mc_AKGC417L.png'],\n",
       " ['160_1b2_Ar_mc_AKGC417L.png'],\n",
       " ['201_1b2_Ar_sc_Meditron.png'],\n",
       " ['172_1b5_Al_mc_AKGC417L.png'],\n",
       " ['114_1b4_Pr_mc_AKGC417L.png'],\n",
       " ['161_1b1_Pl_sc_Meditron.png'],\n",
       " ['107_2b5_Pl_mc_AKGC417L.png'],\n",
       " ['200_2p4_Lr_mc_AKGC417L.png'],\n",
       " ['205_3b4_Pl_mc_AKGC417L.png'],\n",
       " ['195_1b1_Ar_sc_Litt3200.png'],\n",
       " ['130_1p2_Ll_mc_AKGC417L.png'],\n",
       " ['104_1b1_Pl_sc_Litt3200.png'],\n",
       " ['114_1b4_Lr_mc_AKGC417L.png'],\n",
       " ['203_1p2_Al_mc_AKGC417L.png'],\n",
       " ['211_2p2_Tc_mc_AKGC417L.png'],\n",
       " ['223_1b1_Pl_sc_Meditron.png'],\n",
       " ['218_1b1_Pr_sc_Meditron.png'],\n",
       " ['158_1p2_Pr_mc_AKGC417L.png'],\n",
       " ['158_1b3_Ar_mc_LittC2SE.png'],\n",
       " ['172_1b5_Lr_mc_AKGC417L.png'],\n",
       " ['151_2p2_Lr_mc_AKGC417L.png'],\n",
       " ['163_2b2_Tc_mc_AKGC417L.png'],\n",
       " ['114_1b4_Ar_mc_AKGC417L.png'],\n",
       " ['176_1b3_Pl_mc_AKGC417L.png'],\n",
       " ['130_1p4_Tc_mc_AKGC417L.png'],\n",
       " ['193_7b3_Ar_mc_AKGC417L.png'],\n",
       " ['194_1b1_Pr_sc_Meditron.png'],\n",
       " ['186_2b2_Tc_mc_AKGC417L.png'],\n",
       " ['172_1b5_Tc_mc_AKGC417L.png'],\n",
       " ['211_2p3_Tc_mc_AKGC417L.png'],\n",
       " ['167_1b1_Pr_sc_Meditron.png'],\n",
       " ['174_2p3_Ar_mc_AKGC417L.png'],\n",
       " ['156_5b3_Al_mc_AKGC417L.png'],\n",
       " ['130_1p3_Ll_mc_AKGC417L.png'],\n",
       " ['205_2b4_Pl_mc_AKGC417L.png'],\n",
       " ['146_8p3_Pr_mc_AKGC417L.png'],\n",
       " ['124_1b1_Al_sc_Litt3200.png'],\n",
       " ['162_2b3_Lr_mc_AKGC417L.png'],\n",
       " ['119_1b1_Ar_sc_Meditron.png'],\n",
       " ['121_1p1_Tc_sc_Meditron.png'],\n",
       " ['178_1b6_Lr_mc_AKGC417L.png'],\n",
       " ['174_1p4_Ll_mc_AKGC417L.png'],\n",
       " ['138_1p3_Pr_mc_AKGC417L.png'],\n",
       " ['170_1b3_Ll_mc_AKGC417L.png'],\n",
       " ['179_1b1_Al_sc_Meditron.png'],\n",
       " ['139_1b1_Pl_sc_Litt3200.png'],\n",
       " ['130_2p5_Ar_mc_AKGC417L.png'],\n",
       " ['186_2b3_Lr_mc_AKGC417L.png'],\n",
       " ['154_1b3_Tc_mc_AKGC417L.png'],\n",
       " ['130_1p3_Lr_mc_AKGC417L.png'],\n",
       " ['180_1b4_Pl_mc_AKGC417L.png'],\n",
       " ['222_1b1_Pr_sc_Meditron.png'],\n",
       " ['212_2b2_Tc_mc_LittC2SE.png'],\n",
       " ['133_2p3_Al_mc_AKGC417L.png'],\n",
       " ['130_3b4_Lr_mc_AKGC417L.png'],\n",
       " ['195_1b1_Al_sc_Litt3200.png'],\n",
       " ['111_1b2_Tc_sc_Meditron.png'],\n",
       " ['200_2p4_Ar_mc_AKGC417L.png'],\n",
       " ['204_2b5_Ar_mc_AKGC417L.png'],\n",
       " ['186_2b2_Pl_mc_AKGC417L.png'],\n",
       " ['220_1b2_Al_mc_LittC2SE.png'],\n",
       " ['151_3p2_Pr_mc_AKGC417L.png'],\n",
       " ['162_2b3_Tc_mc_AKGC417L.png'],\n",
       " ['118_1b1_Lr_sc_Litt3200.png'],\n",
       " ['219_2b1_Ar_mc_LittC2SE.png'],\n",
       " ['200_2p3_Ar_mc_AKGC417L.png'],\n",
       " ['221_2b1_Al_mc_LittC2SE.png'],\n",
       " ['177_1b4_Pl_mc_AKGC417L.png'],\n",
       " ['207_2b4_Pr_mc_AKGC417L.png'],\n",
       " ['213_1p5_Pr_mc_AKGC417L.png'],\n",
       " ['137_1b1_Ar_sc_Meditron.png'],\n",
       " ['193_1b2_Ar_mc_AKGC417L.png'],\n",
       " ['130_1p3_Pl_mc_AKGC417L.png'],\n",
       " ['207_3b2_Pr_mc_AKGC417L.png'],\n",
       " ['107_2b4_Pr_mc_AKGC417L.png'],\n",
       " ['203_1p3_Ar_mc_AKGC417L.png'],\n",
       " ['178_1b2_Pl_mc_AKGC417L.png'],\n",
       " ['107_3p2_Lr_mc_AKGC417L.png'],\n",
       " ['154_1b3_Al_mc_AKGC417L.png'],\n",
       " ['162_2b3_Pl_mc_AKGC417L.png'],\n",
       " ['207_2b3_Al_mc_AKGC417L.png'],\n",
       " ['174_2p3_Pr_mc_AKGC417L.png'],\n",
       " ['172_1b3_Al_mc_AKGC417L.png'],\n",
       " ['166_1p1_Pr_sc_Meditron.png'],\n",
       " ['186_3b3_Al_mc_AKGC417L.png'],\n",
       " ['154_1b3_Pl_mc_AKGC417L.png'],\n",
       " ['107_3p2_Al_mc_AKGC417L.png'],\n",
       " ['191_2b1_Pl_mc_LittC2SE.png'],\n",
       " ['180_1b4_Ar_mc_AKGC417L.png'],\n",
       " ['213_1p5_Al_mc_AKGC417L.png'],\n",
       " ['176_2b3_Ll_mc_AKGC417L.png'],\n",
       " ['130_2b2_Al_mc_AKGC417L.png'],\n",
       " ['138_1p4_Lr_mc_AKGC417L.png'],\n",
       " ['107_2b5_Al_mc_AKGC417L.png'],\n",
       " ['151_2p2_Ar_mc_AKGC417L.png'],\n",
       " ['163_8b3_Al_mc_AKGC417L.png'],\n",
       " ['163_8b3_Pl_mc_AKGC417L.png'],\n",
       " ['145_2b2_Al_mc_AKGC417L.png'],\n",
       " ['121_1b1_Tc_sc_Meditron.png'],\n",
       " ['118_1b1_Ar_sc_Litt3200.png'],\n",
       " ['130_1p3_Al_mc_AKGC417L.png'],\n",
       " ['112_1p1_Pl_sc_Litt3200.png'],\n",
       " ['138_1p2_Pl_mc_AKGC417L.png'],\n",
       " ['152_1b1_Al_sc_Meditron.png'],\n",
       " ['201_1b1_Al_sc_Meditron.png'],\n",
       " ['219_2b1_Tc_mc_LittC2SE.png'],\n",
       " ['147_2b3_Al_mc_AKGC417L.png'],\n",
       " ['130_2b3_Pr_mc_AKGC417L.png'],\n",
       " ['146_8p3_Pl_mc_AKGC417L.png'],\n",
       " ['221_2b1_Lr_mc_LittC2SE.png'],\n",
       " ['170_2b2_Tc_mc_AKGC417L.png'],\n",
       " ['162_2b3_Al_mc_AKGC417L.png'],\n",
       " ['156_5b3_Ar_mc_AKGC417L.png'],\n",
       " ['154_1b3_Ll_mc_AKGC417L.png'],\n",
       " ['158_1p2_Ar_mc_AKGC417L.png'],\n",
       " ['205_4b2_Lr_mc_AKGC417L.png'],\n",
       " ['201_1b2_Al_sc_Meditron.png'],\n",
       " ['203_1p2_Lr_mc_AKGC417L.png'],\n",
       " ['162_2b2_Pr_mc_AKGC417L.png'],\n",
       " ['174_1p2_Pl_mc_AKGC417L.png'],\n",
       " ['158_1p4_Pr_mc_AKGC417L.png'],\n",
       " ['171_1b1_Al_sc_Meditron.png'],\n",
       " ['186_2b4_Tc_mc_AKGC417L.png'],\n",
       " ['118_1b1_Ll_sc_Litt3200.png'],\n",
       " ['159_1b1_Al_sc_Meditron.png'],\n",
       " ['188_1b1_Pl_sc_Meditron.png'],\n",
       " ['163_8b3_Pr_mc_AKGC417L.png'],\n",
       " ['151_2p3_Lr_mc_AKGC417L.png'],\n",
       " ['133_2p3_Ar_mc_AKGC417L.png'],\n",
       " ['226_1b1_Pl_sc_LittC2SE.png'],\n",
       " ['133_2p2_Ar_mc_AKGC417L.png'],\n",
       " ['188_1b1_Al_sc_Meditron.png'],\n",
       " ['213_1p3_Al_mc_AKGC417L.png'],\n",
       " ['110_1b1_Pr_sc_Meditron.png'],\n",
       " ['175_1b1_Pl_sc_Litt3200.png'],\n",
       " ['213_1p2_Lr_mc_AKGC417L.png'],\n",
       " ['145_3b2_Lr_mc_AKGC417L.png'],\n",
       " ['193_1b2_Pl_mc_AKGC417L.png'],\n",
       " ['213_1p3_Pl_mc_AKGC417L.png'],\n",
       " ['109_1b1_Pl_sc_Litt3200.png'],\n",
       " ['186_2b4_Lr_mc_AKGC417L.png'],\n",
       " ['186_3b3_Lr_mc_AKGC417L.png'],\n",
       " ['130_3b3_Ll_mc_AKGC417L.png'],\n",
       " ['207_2b4_Ar_mc_AKGC417L.png'],\n",
       " ['154_2b4_Pl_mc_AKGC417L.png'],\n",
       " ['190_1b1_Tc_sc_Meditron.png'],\n",
       " ['168_1b1_Al_sc_Meditron.png'],\n",
       " ['158_1p2_Pl_mc_AKGC417L.png'],\n",
       " ['138_1p2_Ar_mc_AKGC417L.png'],\n",
       " ['145_2b2_Ar_mc_AKGC417L.png'],\n",
       " ['203_1p3_Pl_mc_AKGC417L.png'],\n",
       " ['107_2b4_Tc_mc_AKGC417L.png'],\n",
       " ['130_2b3_Ar_mc_AKGC417L.png'],\n",
       " ['193_7b3_Tc_mc_AKGC417L.png'],\n",
       " ['207_3b2_Al_mc_AKGC417L.png'],\n",
       " ['151_2p4_Ar_mc_AKGC417L.png'],\n",
       " ['109_1b1_Pr_sc_Litt3200.png'],\n",
       " ['130_2b3_Ll_mc_AKGC417L.png'],\n",
       " ['154_4b4_Pr_mc_AKGC417L.png'],\n",
       " ['139_1b1_Lr_sc_Litt3200.png'],\n",
       " ['160_2b3_Lr_mc_AKGC417L.png'],\n",
       " ['151_3p3_Ll_mc_AKGC417L.png'],\n",
       " ['145_3b2_Ar_mc_AKGC417L.png'],\n",
       " ['170_1b4_Pr_mc_AKGC417L.png'],\n",
       " ['104_1b1_Pr_sc_Litt3200.png'],\n",
       " ['203_1p2_Tc_mc_AKGC417L.png'],\n",
       " ['162_2b4_Pr_mc_AKGC417L.png'],\n",
       " ['134_2b2_Ar_mc_LittC2SE.png'],\n",
       " ['172_1b4_Ar_mc_AKGC417L.png'],\n",
       " ['186_2b3_Pr_mc_AKGC417L.png'],\n",
       " ['106_2b1_Pr_mc_LittC2SE.png'],\n",
       " ['206_1b1_Pl_sc_Meditron.png'],\n",
       " ['154_2b4_Pr_mc_AKGC417L.png'],\n",
       " ['193_1b2_Ll_mc_AKGC417L.png'],\n",
       " ['102_1b1_Ar_sc_Meditron.png'],\n",
       " ['113_1b1_Ll_sc_Litt3200.png'],\n",
       " ['156_8b3_Al_mc_AKGC417L.png'],\n",
       " ['125_1b1_Tc_sc_Meditron.png'],\n",
       " ['200_2p4_Tc_mc_AKGC417L.png'],\n",
       " ['109_1b1_Ar_sc_Litt3200.png'],\n",
       " ['138_1p3_Al_mc_AKGC417L.png'],\n",
       " ['178_1b6_Ar_mc_AKGC417L.png'],\n",
       " ['147_2b4_Al_mc_AKGC417L.png'],\n",
       " ['156_2b3_Al_mc_AKGC417L.png'],\n",
       " ['163_8b3_Ll_mc_AKGC417L.png'],\n",
       " ['158_2p2_Ar_mc_AKGC417L.png'],\n",
       " ['151_2p4_Al_mc_AKGC417L.png'],\n",
       " ['210_1b1_Al_sc_Meditron.png'],\n",
       " ['107_2b3_Tc_mc_AKGC417L.png'],\n",
       " ['186_2b4_Al_mc_AKGC417L.png'],\n",
       " ['177_2b4_Al_mc_AKGC417L.png'],\n",
       " ['142_1b1_Pl_mc_LittC2SE.png'],\n",
       " ['111_1b3_Tc_sc_Meditron.png'],\n",
       " ['154_3b3_Al_mc_AKGC417L.png'],\n",
       " ['133_2p2_Al_mc_AKGC417L.png'],\n",
       " ['192_2b1_Ar_mc_LittC2SE.png'],\n",
       " ['177_1b4_Pr_mc_AKGC417L.png'],\n",
       " ['154_1b3_Pr_mc_AKGC417L.png'],\n",
       " ['170_2b2_Ar_mc_AKGC417L.png'],\n",
       " ['157_1b1_Pr_sc_Meditron.png'],\n",
       " ['216_1b1_Pl_sc_Meditron.png'],\n",
       " ['193_7b3_Pl_mc_AKGC417L.png'],\n",
       " ['172_1b5_Pl_mc_AKGC417L.png'],\n",
       " ['174_2p3_Pl_mc_AKGC417L.png'],\n",
       " ['183_1b1_Tc_sc_Meditron.png'],\n",
       " ['179_1b1_Tc_sc_Meditron.png'],\n",
       " ['170_2b2_Al_mc_AKGC417L.png'],\n",
       " ['130_2b4_Ar_mc_AKGC417L.png'],\n",
       " ['203_1p2_Ar_mc_AKGC417L.png'],\n",
       " ['128_1b3_Tc_mc_LittC2SE.png'],\n",
       " ['145_2b2_Lr_mc_AKGC417L.png'],\n",
       " ['165_1b1_Pr_sc_Meditron.png'],\n",
       " ['118_1b1_Pl_sc_Litt3200.png'],\n",
       " ['170_1b3_Tc_mc_AKGC417L.png'],\n",
       " ['130_1p2_Al_mc_AKGC417L.png'],\n",
       " ['147_2b3_Pl_mc_AKGC417L.png'],\n",
       " ['205_1b3_Pl_mc_AKGC417L.png'],\n",
       " ['219_2b2_Ar_mc_LittC2SE.png'],\n",
       " ['154_4b4_Ll_mc_AKGC417L.png'],\n",
       " ['154_2b4_Ll_mc_AKGC417L.png'],\n",
       " ['172_1b5_Ar_mc_AKGC417L.png'],\n",
       " ['185_1b1_Ll_sc_Litt3200.png'],\n",
       " ['176_1b4_Ll_mc_AKGC417L.png'],\n",
       " ['182_1b1_Tc_sc_Meditron.png'],\n",
       " ['156_2b3_Ll_mc_AKGC417L.png'],\n",
       " ['122_2b3_Ar_mc_LittC2SE.png'],\n",
       " ['175_1b1_Ll_sc_Litt3200.png'],\n",
       " ['170_1b4_Pl_mc_AKGC417L.png'],\n",
       " ['160_1b2_Pr_mc_AKGC417L.png'],\n",
       " ['176_1b3_Al_mc_AKGC417L.png'],\n",
       " ['147_2b4_Ll_mc_AKGC417L.png'],\n",
       " ['149_1b1_Pl_sc_Meditron.png'],\n",
       " ['178_1b2_Pr_mc_AKGC417L.png'],\n",
       " ['170_1b3_Pl_mc_AKGC417L.png'],\n",
       " ['174_1p3_Tc_mc_AKGC417L.png'],\n",
       " ['158_1p3_Al_mc_AKGC417L.png'],\n",
       " ['186_2b3_Pl_mc_AKGC417L.png'],\n",
       " ['130_3p4_Al_mc_AKGC417L.png'],\n",
       " ['130_3p2_Pr_mc_AKGC417L.png'],\n",
       " ['133_2p3_Tc_mc_AKGC417L.png'],\n",
       " ['133_3p2_Pl_mc_AKGC417L.png'],\n",
       " ['207_2b2_Ar_mc_AKGC417L.png'],\n",
       " ['151_2p3_Pr_mc_AKGC417L.png'],\n",
       " ['154_2b4_Al_mc_AKGC417L.png'],\n",
       " ['116_1b2_Pl_sc_Meditron.png'],\n",
       " ['210_1b1_Ar_sc_Meditron.png'],\n",
       " ['137_1b1_Ll_sc_Meditron.png'],\n",
       " ['177_2b4_Lr_mc_AKGC417L.png'],\n",
       " ['151_3p2_Al_mc_AKGC417L.png'],\n",
       " ['131_1b1_Al_sc_Meditron.png'],\n",
       " ['151_2p2_Al_mc_AKGC417L.png'],\n",
       " ['226_1b1_Ll_sc_Meditron.png'],\n",
       " ['178_1b3_Ar_mc_AKGC417L.png'],\n",
       " ['219_2b3_Tc_mc_LittC2SE.png'],\n",
       " ['186_2b2_Ar_mc_AKGC417L.png'],\n",
       " ['157_1b1_Al_sc_Meditron.png'],\n",
       " ['203_2p3_Pr_mc_AKGC417L.png'],\n",
       " ['213_2p2_Tc_mc_AKGC417L.png'],\n",
       " ['218_1b1_Pl_sc_Meditron.png'],\n",
       " ['151_2p3_Pl_mc_AKGC417L.png'],\n",
       " ['172_1b3_Ll_mc_AKGC417L.png'],\n",
       " ['132_2b2_Lr_mc_LittC2SE.png'],\n",
       " ['218_1b1_Al_sc_Meditron.png'],\n",
       " ['180_1b4_Lr_mc_AKGC417L.png'],\n",
       " ['185_1b1_Pl_sc_Litt3200.png'],\n",
       " ['138_1p4_Pr_mc_AKGC417L.png'],\n",
       " ['110_1p1_Al_sc_Meditron.png'],\n",
       " ['170_1b3_Pr_mc_AKGC417L.png'],\n",
       " ['221_2b3_Al_mc_LittC2SE.png'],\n",
       " ['130_3p3_Pl_mc_AKGC417L.png'],\n",
       " ['214_1b1_Ar_sc_Meditron.png'],\n",
       " ['130_1p2_Ar_mc_AKGC417L.png'],\n",
       " ['107_2b3_Pr_mc_AKGC417L.png'],\n",
       " ['186_3b3_Tc_mc_AKGC417L.png'],\n",
       " ['127_1b1_Ar_sc_Meditron.png'],\n",
       " ['120_1b1_Pr_sc_Meditron.png'],\n",
       " ['107_2b4_Al_mc_AKGC417L.png'],\n",
       " ['162_2b4_Tc_mc_AKGC417L.png'],\n",
       " ['107_2b4_Ll_mc_AKGC417L.png'],\n",
       " ['107_2b3_Ll_mc_AKGC417L.png'],\n",
       " ['218_1p1_Ar_sc_Litt3200.png'],\n",
       " ['138_2p2_Lr_mc_AKGC417L.png'],\n",
       " ['178_1b3_Pr_mc_AKGC417L.png'],\n",
       " ['130_3b4_Al_mc_AKGC417L.png'],\n",
       " ['112_1b1_Ar_sc_Meditron.png'],\n",
       " ['160_1b2_Lr_mc_AKGC417L.png'],\n",
       " ['195_1b1_Pl_sc_Litt3200.png'],\n",
       " ['177_1b4_Al_mc_AKGC417L.png'],\n",
       " ['115_1b1_Ar_sc_Meditron.png'],\n",
       " ['204_2b5_Al_mc_AKGC417L.png'],\n",
       " ['186_2b3_Tc_mc_AKGC417L.png'],\n",
       " ['183_1b1_Pl_sc_Meditron.png'],\n",
       " ['147_2b3_Lr_mc_AKGC417L.png'],\n",
       " ['200_3p4_Tc_mc_AKGC417L.png'],\n",
       " ['203_1p3_Al_mc_AKGC417L.png'],\n",
       " ['104_1b1_Ll_sc_Litt3200.png'],\n",
       " ['110_1p1_Lr_sc_Meditron.png'],\n",
       " ['172_1b4_Tc_mc_AKGC417L.png'],\n",
       " ['170_1b2_Al_mc_AKGC417L.png'],\n",
       " ['157_1b1_Pl_sc_Meditron.png'],\n",
       " ['172_2b5_Pl_mc_AKGC417L.png'],\n",
       " ['163_8b3_Lr_mc_AKGC417L.png'],\n",
       " ['174_1p3_Ar_mc_AKGC417L.png'],\n",
       " ['177_1b4_Lr_mc_AKGC417L.png'],\n",
       " ['120_1b1_Pl_sc_Meditron.png'],\n",
       " ['193_1b4_Lr_mc_AKGC417L.png'],\n",
       " ['186_2b3_Ar_mc_AKGC417L.png'],\n",
       " ['107_2b5_Pr_mc_AKGC417L.png'],\n",
       " ['175_1b1_Al_sc_Litt3200.png'],\n",
       " ['140_2b3_Tc_mc_LittC2SE.png'],\n",
       " ['200_2p2_Pl_mc_AKGC417L.png'],\n",
       " ['162_2b3_Ar_mc_AKGC417L.png'],\n",
       " ['158_1p3_Ar_mc_AKGC417L.png'],\n",
       " ['205_3b4_Al_mc_AKGC417L.png'],\n",
       " ['130_2b4_Ll_mc_AKGC417L.png'],\n",
       " ['130_3p3_Tc_mc_AKGC417L.png'],\n",
       " ['130_3p2_Tc_mc_AKGC417L.png'],\n",
       " ['203_1p3_Pr_mc_AKGC417L.png'],\n",
       " ['172_1b5_Pr_mc_AKGC417L.png'],\n",
       " ['130_1p2_Pl_mc_AKGC417L.png'],\n",
       " ['151_2p2_Tc_mc_AKGC417L.png'],\n",
       " ['193_7b3_Al_mc_AKGC417L.png'],\n",
       " ['207_2b2_Pl_mc_AKGC417L.png'],\n",
       " ['118_1b1_Pr_sc_Litt3200.png'],\n",
       " ['107_2b3_Al_mc_AKGC417L.png'],\n",
       " ['170_1b3_Ar_mc_AKGC417L.png'],\n",
       " ['174_1p4_Pl_mc_AKGC417L.png'],\n",
       " ['178_1b6_Pl_mc_AKGC417L.png'],\n",
       " ['223_1b1_Lr_sc_Meditron.png'],\n",
       " ['138_2p2_Ar_mc_AKGC417L.png'],\n",
       " ['130_1p4_Pr_mc_AKGC417L.png'],\n",
       " ['186_2b3_Al_mc_AKGC417L.png'],\n",
       " ['178_2b2_Pr_mc_AKGC417L.png'],\n",
       " ['172_1b4_Al_mc_AKGC417L.png'],\n",
       " ['223_1b1_Ll_sc_Meditron.png'],\n",
       " ['186_3b3_Pr_mc_AKGC417L.png'],\n",
       " ['170_1b2_Pr_mc_AKGC417L.png'],\n",
       " ['221_2b2_Ar_mc_LittC2SE.png'],\n",
       " ['135_2b1_Pl_mc_LittC2SE.png'],\n",
       " ['211_1p5_Ar_mc_AKGC417L.png'],\n",
       " ['221_2b1_Ar_mc_LittC2SE.png'],\n",
       " ['162_2b2_Ar_mc_AKGC417L.png'],\n",
       " ['204_7p5_Al_mc_AKGC417L.png'],\n",
       " ['107_2b4_Pl_mc_AKGC417L.png'],\n",
       " ['135_2b3_Pl_mc_LittC2SE.png'],\n",
       " ['147_2b4_Ar_mc_AKGC417L.png'],\n",
       " ['223_1b1_Pr_sc_Meditron.png'],\n",
       " ['209_1b1_Tc_sc_Meditron.png'],\n",
       " ['224_1b2_Al_sc_Meditron.png'],\n",
       " ['203_1p4_Pr_mc_AKGC417L.png'],\n",
       " ['163_2b2_Al_mc_AKGC417L.png'],\n",
       " ['169_1b1_Lr_sc_Meditron.png'],\n",
       " ['160_1b3_Tc_mc_AKGC417L.png'],\n",
       " ['178_2b2_Al_mc_AKGC417L.png'],\n",
       " ['207_2b3_Pl_mc_AKGC417L.png'],\n",
       " ['218_1b1_Lr_sc_Meditron.png'],\n",
       " ['154_2b4_Lr_mc_AKGC417L.png'],\n",
       " ['207_3b2_Pl_mc_AKGC417L.png'],\n",
       " ['135_2b3_Ar_mc_LittC2SE.png'],\n",
       " ['195_1b1_Lr_sc_Litt3200.png'],\n",
       " ['138_1p3_Ar_mc_AKGC417L.png'],\n",
       " ['200_2p3_Al_mc_AKGC417L.png'],\n",
       " ['149_1b1_Lr_sc_Meditron.png'],\n",
       " ['172_1b3_Pl_mc_AKGC417L.png'],\n",
       " ['159_1b1_Ar_sc_Meditron.png'],\n",
       " ['130_2b4_Lr_mc_AKGC417L.png'],\n",
       " ['105_1b1_Tc_sc_Meditron.png'],\n",
       " ['189_1b2_Lr_mc_LittC2SE.png'],\n",
       " ['193_1b2_Tc_mc_AKGC417L.png'],\n",
       " ['160_1b2_Tc_mc_AKGC417L.png'],\n",
       " ['156_8b3_Ar_mc_AKGC417L.png'],\n",
       " ['130_1p2_Lr_mc_AKGC417L.png'],\n",
       " ['174_1p4_Pr_mc_AKGC417L.png'],\n",
       " ['180_1b4_Pr_mc_AKGC417L.png'],\n",
       " ['160_1b4_Pl_mc_AKGC417L.png'],\n",
       " ['110_1p1_Pr_sc_Meditron.png'],\n",
       " ['185_1b1_Al_sc_Litt3200.png'],\n",
       " ['194_1b1_Lr_sc_Meditron.png'],\n",
       " ['163_2b2_Pr_mc_AKGC417L.png'],\n",
       " ['198_1b5_Al_mc_AKGC417L.png'],\n",
       " ['200_2p2_Lr_mc_AKGC417L.png'],\n",
       " ['203_1p2_Pl_mc_AKGC417L.png'],\n",
       " ['186_2b2_Pr_mc_AKGC417L.png'],\n",
       " ['151_2p4_Pl_mc_AKGC417L.png'],\n",
       " ['154_4b4_Lr_mc_AKGC417L.png'],\n",
       " ['177_1b4_Tc_mc_AKGC417L.png'],\n",
       " ['205_4b2_Ar_mc_AKGC417L.png'],\n",
       " ['172_2b5_Pr_mc_AKGC417L.png'],\n",
       " ['176_1b4_Ar_mc_AKGC417L.png'],\n",
       " ['163_8b3_Ar_mc_AKGC417L.png'],\n",
       " ['223_1b1_Al_sc_Meditron.png'],\n",
       " ['205_2b3_Al_mc_AKGC417L.png'],\n",
       " ['221_2b3_Ar_mc_LittC2SE.png'],\n",
       " ['198_6p1_Pr_mc_AKGC417L.png'],\n",
       " ['221_2b1_Pl_mc_LittC2SE.png'],\n",
       " ['134_2b1_Ar_mc_LittC2SE.png'],\n",
       " ['186_2b4_Pl_mc_AKGC417L.png'],\n",
       " ['160_1b4_Lr_mc_AKGC417L.png'],\n",
       " ['146_8p3_Al_mc_AKGC417L.png'],\n",
       " ['139_1b1_Pr_sc_Litt3200.png'],\n",
       " ['155_2b1_Al_mc_LittC2SE.png'],\n",
       " ['154_1b3_Ar_mc_AKGC417L.png'],\n",
       " ['156_5b3_Ll_mc_AKGC417L.png'],\n",
       " ['113_1b1_Lr_sc_Litt3200.png'],\n",
       " ['124_1b1_Pl_sc_Litt3200.png'],\n",
       " ['177_2b4_Pl_mc_AKGC417L.png'],\n",
       " ['104_1b1_Lr_sc_Litt3200.png'],\n",
       " ['162_2b4_Lr_mc_AKGC417L.png'],\n",
       " ['160_1b3_Ar_mc_AKGC417L.png'],\n",
       " ['226_1b1_Al_sc_Meditron.png'],\n",
       " ['207_3b2_Lr_mc_AKGC417L.png'],\n",
       " ['130_2b2_Tc_mc_AKGC417L.png'],\n",
       " ['192_2b2_Ar_mc_LittC2SE.png'],\n",
       " ['200_3p4_Pr_mc_AKGC417L.png'],\n",
       " ['156_2b3_Lr_mc_AKGC417L.png'],\n",
       " ['133_2p2_Pl_mc_AKGC417L.png'],\n",
       " ['178_1b2_Al_mc_AKGC417L.png'],\n",
       " ['177_2b4_Tc_mc_AKGC417L.png'],\n",
       " ['223_1b1_Ar_sc_Meditron.png'],\n",
       " ['135_2b1_Ar_mc_LittC2SE.png'],\n",
       " ['138_1p4_Pl_mc_AKGC417L.png'],\n",
       " ['178_1b6_Al_mc_AKGC417L.png'],\n",
       " ['130_2b2_Lr_mc_AKGC417L.png'],\n",
       " ['158_1p3_Lr_mc_AKGC417L.png'],\n",
       " ['138_1p2_Tc_mc_AKGC417L.png'],\n",
       " ['130_1p4_Ar_mc_AKGC417L.png'],\n",
       " ['141_1b2_Lr_mc_LittC2SE.png'],\n",
       " ['146_2b4_Ar_mc_AKGC417L.png'],\n",
       " ['177_2b4_Pr_mc_AKGC417L.png'],\n",
       " ['198_1b5_Pl_mc_AKGC417L.png'],\n",
       " ['175_1b1_Ar_sc_Litt3200.png'],\n",
       " ['134_2b1_Al_mc_LittC2SE.png'],\n",
       " ['114_1b4_Pl_mc_AKGC417L.png'],\n",
       " ['170_1b4_Ar_mc_AKGC417L.png'],\n",
       " ['139_1b1_Ar_sc_Litt3200.png'],\n",
       " ['158_2p3_Tc_mc_AKGC417L.png'],\n",
       " ['185_1b1_Lr_sc_Litt3200.png'],\n",
       " ['165_1b1_Ar_sc_Meditron.png'],\n",
       " ['174_1p2_Ll_mc_AKGC417L.png'],\n",
       " ['203_1p4_Ar_mc_AKGC417L.png'],\n",
       " ['112_1b1_Lr_sc_Meditron.png'],\n",
       " ['158_2p3_Lr_mc_AKGC417L.png'],\n",
       " ['130_3p4_Pr_mc_AKGC417L.png'],\n",
       " ['151_2p2_Pr_mc_AKGC417L.png'],\n",
       " ['146_2b2_Pl_mc_AKGC417L.png'],\n",
       " ['158_1p2_Tc_mc_AKGC417L.png'],\n",
       " ['181_1b1_Ar_mc_LittC2SE.png'],\n",
       " ['132_2b1_Lr_mc_LittC2SE.png'],\n",
       " ['130_1p3_Pr_mc_AKGC417L.png'],\n",
       " ['130_2b4_Pl_mc_AKGC417L.png'],\n",
       " ['160_1b4_Ar_mc_AKGC417L.png'],\n",
       " ['138_2p2_Pl_mc_AKGC417L.png'],\n",
       " ['162_1b2_Pr_mc_AKGC417L.png'],\n",
       " ['138_2p2_Pr_mc_AKGC417L.png'],\n",
       " ['138_1p2_Al_mc_AKGC417L.png'],\n",
       " ['146_2b4_Lr_mc_AKGC417L.png'],\n",
       " ['109_1b1_Ll_sc_Litt3200.png'],\n",
       " ['158_1p3_Tc_mc_AKGC417L.png'],\n",
       " ['186_2b2_Al_mc_AKGC417L.png'],\n",
       " ['173_1b1_Al_sc_Meditron.png'],\n",
       " ['181_1b1_Tc_mc_LittC2SE.png'],\n",
       " ['124_1b1_Pr_sc_Litt3200.png'],\n",
       " ['174_1p3_Lr_mc_AKGC417L.png'],\n",
       " ['156_5b3_Lr_mc_AKGC417L.png'],\n",
       " ['185_1b1_Pr_sc_Litt3200.png'],\n",
       " ['134_2b2_Al_mc_LittC2SE.png'],\n",
       " ['172_1b3_Ar_mc_AKGC417L.png'],\n",
       " ['174_1p4_Lr_mc_AKGC417L.png'],\n",
       " ['175_1b1_Lr_sc_Litt3200.png'],\n",
       " ['107_2b5_Ar_mc_AKGC417L.png'],\n",
       " ['174_1p2_Tc_mc_AKGC417L.png'],\n",
       " ['211_1p3_Ar_mc_AKGC417L.png'],\n",
       " ['166_1p1_Al_sc_Meditron.png'],\n",
       " ['186_2b2_Lr_mc_AKGC417L.png'],\n",
       " ['184_1b1_Ar_sc_Meditron.png'],\n",
       " ['203_1p2_Pr_mc_AKGC417L.png'],\n",
       " ['160_1b2_Pl_mc_AKGC417L.png'],\n",
       " ['213_2p2_Al_mc_AKGC417L.png']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_file_names = []\n",
    "\n",
    "for i in sound_files:\n",
    "      req_file_names.append([i])\n",
    "\n",
    "req_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:08:32.509079Z",
     "iopub.status.busy": "2023-08-08T22:08:32.508709Z",
     "iopub.status.idle": "2023-08-08T22:08:32.516738Z",
     "shell.execute_reply": "2023-08-08T22:08:32.515474Z",
     "shell.execute_reply.started": "2023-08-08T22:08:32.509046Z"
    },
    "id": "LCKsXMpUvggI"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(req_file_names)):\n",
    "    req_file_names[i].append(sr_no[req_file_names[i][0][:3]])\n",
    "    labels.append(sr_no[req_file_names[i][0][:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:08:32.518692Z",
     "iopub.status.busy": "2023-08-08T22:08:32.518299Z",
     "iopub.status.idle": "2023-08-08T22:08:32.526200Z",
     "shell.execute_reply": "2023-08-08T22:08:32.525090Z",
     "shell.execute_reply.started": "2023-08-08T22:08:32.518661Z"
    }
   },
   "outputs": [],
   "source": [
    "labels *= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-08T22:08:32.529879Z",
     "iopub.status.busy": "2023-08-08T22:08:32.528736Z",
     "iopub.status.idle": "2023-08-08T22:09:31.696027Z",
     "shell.execute_reply": "2023-08-08T22:09:31.694153Z",
     "shell.execute_reply.started": "2023-08-08T22:08:32.529845Z"
    },
    "id": "_PoMb8etvpAk",
    "outputId": "65cd04d4-ba35-460e-b497-d9b5ac091122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2760, 350, 350, 3)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "\n",
    "for i in req_file_names:\n",
    "    img = cv2.imread('/kaggle/input/transferlearning-ls-data/Mel Spectrogram/Mel Spectrogram/Time Stretch/'+i[0])\n",
    "    img = cv2.resize(img, (350, 350))\n",
    "    x.append(img)\n",
    "\n",
    "for i in req_file_names:\n",
    "    img = cv2.imread('/kaggle/input/transferlearning-ls-data/Mel Spectrogram/Mel Spectrogram/Pitch Shift/'+i[0])\n",
    "    img = cv2.resize(img, (350, 350))\n",
    "    x.append(img)\n",
    "    \n",
    "for i in req_file_names:\n",
    "    img = cv2.imread('/kaggle/input/transferlearning-ls-data/Mel Spectrogram/Mel Spectrogram/Audio Shift/'+i[0])\n",
    "    img = cv2.resize(img, (350, 350))\n",
    "    x.append(img)\n",
    "\n",
    "x = np.array(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:09:31.700812Z",
     "iopub.status.busy": "2023-08-08T22:09:31.700124Z",
     "iopub.status.idle": "2023-08-08T22:09:31.705540Z",
     "shell.execute_reply": "2023-08-08T22:09:31.704056Z",
     "shell.execute_reply.started": "2023-08-08T22:09:31.700777Z"
    }
   },
   "outputs": [],
   "source": [
    "req_file_names *= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-08T22:09:31.707416Z",
     "iopub.status.busy": "2023-08-08T22:09:31.707050Z",
     "iopub.status.idle": "2023-08-08T22:09:31.722756Z",
     "shell.execute_reply": "2023-08-08T22:09:31.721688Z",
     "shell.execute_reply.started": "2023-08-08T22:09:31.707382Z"
    },
    "id": "AbwY828LxkMZ",
    "outputId": "54c8937f-563d-41af-c159-3bd798c5cdf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2760,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(labels)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:09:31.724494Z",
     "iopub.status.busy": "2023-08-08T22:09:31.724154Z",
     "iopub.status.idle": "2023-08-08T22:09:31.736126Z",
     "shell.execute_reply": "2023-08-08T22:09:31.735216Z",
     "shell.execute_reply.started": "2023-08-08T22:09:31.724463Z"
    },
    "id": "bTiogsRk3ujL"
   },
   "outputs": [],
   "source": [
    "one_hot_y = np.array(pd.get_dummies(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:09:31.738079Z",
     "iopub.status.busy": "2023-08-08T22:09:31.737739Z",
     "iopub.status.idle": "2023-08-08T22:09:31.992862Z",
     "shell.execute_reply": "2023-08-08T22:09:31.991900Z",
     "shell.execute_reply.started": "2023-08-08T22:09:31.738048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1656, 350, 350, 3) (1656, 8) (1104, 350, 350, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, one_hot_y, test_size=0.4, random_state=33, stratify=y)\n",
    "print(x_train.shape, y_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T22:05:18.217624Z",
     "iopub.status.busy": "2023-08-06T22:05:18.216693Z",
     "iopub.status.idle": "2023-08-06T22:05:20.836441Z",
     "shell.execute_reply": "2023-08-06T22:05:20.835680Z",
     "shell.execute_reply.started": "2023-08-06T22:05:18.217589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 344, 344, 256)     37888     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 114, 114, 256)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 110, 110, 64)      409664    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 32)        18464     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36992)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4735104   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,209,896\n",
      "Trainable params: 5,209,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(256, (7,7), activation='relu', input_shape=(350, 350, 3)))\n",
    "model.add(keras.layers.MaxPool2D((3,3)))\n",
    "model.add(keras.layers.Conv2D(64, (5,5), activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D((3,3)))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T22:05:20.837821Z",
     "iopub.status.busy": "2023-08-06T22:05:20.837483Z",
     "iopub.status.idle": "2023-08-06T22:05:20.864826Z",
     "shell.execute_reply": "2023-08-06T22:05:20.863914Z",
     "shell.execute_reply.started": "2023-08-06T22:05:20.837787Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-06T22:05:20.866950Z",
     "iopub.status.busy": "2023-08-06T22:05:20.866318Z",
     "iopub.status.idle": "2023-08-06T22:19:45.054236Z",
     "shell.execute_reply": "2023-08-06T22:19:45.053087Z",
     "shell.execute_reply.started": "2023-08-06T22:05:20.866917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "52/52 [==============================] - 37s 420ms/step - loss: 2.9345 - accuracy: 0.7796 - val_loss: 1.3338 - val_accuracy: 0.8043\n",
      "Epoch 2/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.9930 - accuracy: 0.8303 - val_loss: 0.9902 - val_accuracy: 0.7908\n",
      "Epoch 3/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.6953 - accuracy: 0.8539 - val_loss: 0.7464 - val_accuracy: 0.8487\n",
      "Epoch 4/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.5172 - accuracy: 0.8581 - val_loss: 0.6470 - val_accuracy: 0.8424\n",
      "Epoch 5/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.4939 - accuracy: 0.8678 - val_loss: 0.8297 - val_accuracy: 0.8551\n",
      "Epoch 6/60\n",
      "52/52 [==============================] - 14s 264ms/step - loss: 0.4905 - accuracy: 0.8720 - val_loss: 0.5329 - val_accuracy: 0.8659\n",
      "Epoch 7/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.4559 - accuracy: 0.8714 - val_loss: 0.5930 - val_accuracy: 0.8741\n",
      "Epoch 8/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.3100 - accuracy: 0.9124 - val_loss: 0.4727 - val_accuracy: 0.8741\n",
      "Epoch 9/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.2897 - accuracy: 0.9149 - val_loss: 0.4123 - val_accuracy: 0.8813\n",
      "Epoch 10/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.2320 - accuracy: 0.9203 - val_loss: 0.3399 - val_accuracy: 0.8995\n",
      "Epoch 11/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.2118 - accuracy: 0.9360 - val_loss: 0.3374 - val_accuracy: 0.8859\n",
      "Epoch 12/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.2172 - accuracy: 0.9318 - val_loss: 0.3783 - val_accuracy: 0.8886\n",
      "Epoch 13/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.2006 - accuracy: 0.9336 - val_loss: 0.3370 - val_accuracy: 0.9058\n",
      "Epoch 14/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.1922 - accuracy: 0.9432 - val_loss: 0.3033 - val_accuracy: 0.9067\n",
      "Epoch 15/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.1443 - accuracy: 0.9553 - val_loss: 0.2963 - val_accuracy: 0.9049\n",
      "Epoch 16/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.1304 - accuracy: 0.9565 - val_loss: 0.2651 - val_accuracy: 0.9167\n",
      "Epoch 17/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.1302 - accuracy: 0.9638 - val_loss: 0.2485 - val_accuracy: 0.9239\n",
      "Epoch 18/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.1800 - accuracy: 0.9481 - val_loss: 0.3204 - val_accuracy: 0.9149\n",
      "Epoch 19/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.1312 - accuracy: 0.9535 - val_loss: 0.3038 - val_accuracy: 0.9076\n",
      "Epoch 20/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.1097 - accuracy: 0.9626 - val_loss: 0.2728 - val_accuracy: 0.9167\n",
      "Epoch 21/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.0720 - accuracy: 0.9771 - val_loss: 0.2277 - val_accuracy: 0.9257\n",
      "Epoch 22/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.0659 - accuracy: 0.9843 - val_loss: 0.2483 - val_accuracy: 0.9230\n",
      "Epoch 23/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0777 - accuracy: 0.9680 - val_loss: 0.2169 - val_accuracy: 0.9239\n",
      "Epoch 24/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.0721 - accuracy: 0.9771 - val_loss: 0.2495 - val_accuracy: 0.9266\n",
      "Epoch 25/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0486 - accuracy: 0.9891 - val_loss: 0.2335 - val_accuracy: 0.9357\n",
      "Epoch 26/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0348 - accuracy: 0.9934 - val_loss: 0.2098 - val_accuracy: 0.9293\n",
      "Epoch 27/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.0458 - accuracy: 0.9879 - val_loss: 0.2120 - val_accuracy: 0.9384\n",
      "Epoch 28/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0356 - accuracy: 0.9928 - val_loss: 0.1980 - val_accuracy: 0.9457\n",
      "Epoch 29/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0337 - accuracy: 0.9952 - val_loss: 0.1809 - val_accuracy: 0.9475\n",
      "Epoch 30/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0255 - accuracy: 0.9976 - val_loss: 0.2022 - val_accuracy: 0.9393\n",
      "Epoch 31/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0262 - accuracy: 0.9964 - val_loss: 0.2156 - val_accuracy: 0.9393\n",
      "Epoch 32/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0298 - accuracy: 0.9952 - val_loss: 0.2075 - val_accuracy: 0.9429\n",
      "Epoch 33/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0308 - accuracy: 0.9921 - val_loss: 0.2075 - val_accuracy: 0.9429\n",
      "Epoch 34/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0219 - accuracy: 0.9976 - val_loss: 0.1884 - val_accuracy: 0.9384\n",
      "Epoch 35/60\n",
      "52/52 [==============================] - 14s 262ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.2773 - val_accuracy: 0.9293\n",
      "Epoch 36/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0429 - accuracy: 0.9879 - val_loss: 0.1758 - val_accuracy: 0.9493\n",
      "Epoch 37/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0465 - accuracy: 0.9855 - val_loss: 0.2288 - val_accuracy: 0.9420\n",
      "Epoch 38/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.0161 - accuracy: 0.9982 - val_loss: 0.1936 - val_accuracy: 0.9493\n",
      "Epoch 39/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.0179 - accuracy: 0.9970 - val_loss: 0.2391 - val_accuracy: 0.9384\n",
      "Epoch 40/60\n",
      "52/52 [==============================] - 14s 262ms/step - loss: 0.0371 - accuracy: 0.9903 - val_loss: 0.1902 - val_accuracy: 0.9466\n",
      "Epoch 41/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.0145 - accuracy: 0.9982 - val_loss: 0.1949 - val_accuracy: 0.9493\n",
      "Epoch 42/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 0.1615 - val_accuracy: 0.9556\n",
      "Epoch 43/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9520\n",
      "Epoch 44/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0109 - accuracy: 0.9988 - val_loss: 0.1873 - val_accuracy: 0.9475\n",
      "Epoch 45/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0147 - accuracy: 0.9976 - val_loss: 0.1628 - val_accuracy: 0.9565\n",
      "Epoch 46/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0078 - accuracy: 0.9994 - val_loss: 0.1974 - val_accuracy: 0.9475\n",
      "Epoch 47/60\n",
      "52/52 [==============================] - 14s 262ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.2072 - val_accuracy: 0.9447\n",
      "Epoch 48/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9574\n",
      "Epoch 49/60\n",
      "52/52 [==============================] - 14s 262ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9493\n",
      "Epoch 50/60\n",
      "52/52 [==============================] - 14s 262ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9574\n",
      "Epoch 51/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9601\n",
      "Epoch 52/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9592\n",
      "Epoch 53/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9547\n",
      "Epoch 54/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9565\n",
      "Epoch 55/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9547\n",
      "Epoch 56/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9592\n",
      "Epoch 57/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.1939 - val_accuracy: 0.9502\n",
      "Epoch 58/60\n",
      "52/52 [==============================] - 14s 261ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.1878 - val_accuracy: 0.9520\n",
      "Epoch 59/60\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9565\n",
      "Epoch 60/60\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7addd41d2bc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:22:31.849810Z",
     "iopub.status.busy": "2023-08-08T22:22:31.849448Z",
     "iopub.status.idle": "2023-08-08T22:22:33.224106Z",
     "shell.execute_reply": "2023-08-08T22:22:33.223098Z",
     "shell.execute_reply.started": "2023-08-08T22:22:31.849780Z"
    }
   },
   "outputs": [],
   "source": [
    "xception_wo_top = keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(350, 350, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:22:33.226186Z",
     "iopub.status.busy": "2023-08-08T22:22:33.225815Z",
     "iopub.status.idle": "2023-08-08T22:22:33.237288Z",
     "shell.execute_reply": "2023-08-08T22:22:33.236318Z",
     "shell.execute_reply.started": "2023-08-08T22:22:33.226150Z"
    }
   },
   "outputs": [],
   "source": [
    "xception_wo_top.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:22:35.863120Z",
     "iopub.status.busy": "2023-08-08T22:22:35.862042Z",
     "iopub.status.idle": "2023-08-08T22:22:36.477488Z",
     "shell.execute_reply": "2023-08-08T22:22:36.476629Z",
     "shell.execute_reply.started": "2023-08-08T22:22:35.863076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 11, 11, 2048)      20861480  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 247808)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               31719552  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,589,808\n",
      "Trainable params: 31,728,328\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xception_model = keras.models.Sequential()\n",
    "xception_model.add(xception_wo_top)\n",
    "xception_model.add(keras.layers.Flatten())\n",
    "xception_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "xception_model.add(keras.layers.Dense(64, activation='relu'))\n",
    "xception_model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:22:45.829985Z",
     "iopub.status.busy": "2023-08-08T22:22:45.829574Z",
     "iopub.status.idle": "2023-08-08T22:22:45.847174Z",
     "shell.execute_reply": "2023-08-08T22:22:45.846053Z",
     "shell.execute_reply.started": "2023-08-08T22:22:45.829951Z"
    }
   },
   "outputs": [],
   "source": [
    "xception_model.compile(optimizer=keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:22:49.039119Z",
     "iopub.status.busy": "2023-08-08T22:22:49.037731Z",
     "iopub.status.idle": "2023-08-08T22:40:56.124607Z",
     "shell.execute_reply": "2023-08-08T22:40:56.123451Z",
     "shell.execute_reply.started": "2023-08-08T22:22:49.039075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "52/52 [==============================] - 24s 404ms/step - loss: 107.2661 - accuracy: 0.7844 - val_loss: 55.2472 - val_accuracy: 0.8623\n",
      "Epoch 2/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 35.2185 - accuracy: 0.8581 - val_loss: 38.4667 - val_accuracy: 0.7989\n",
      "Epoch 3/60\n",
      "52/52 [==============================] - 15s 283ms/step - loss: 21.7539 - accuracy: 0.8641 - val_loss: 47.9440 - val_accuracy: 0.8777\n",
      "Epoch 4/60\n",
      "52/52 [==============================] - 15s 283ms/step - loss: 10.9762 - accuracy: 0.9058 - val_loss: 25.1156 - val_accuracy: 0.8877\n",
      "Epoch 5/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 9.8383 - accuracy: 0.9016 - val_loss: 26.6368 - val_accuracy: 0.8813\n",
      "Epoch 6/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 16.9494 - accuracy: 0.8895 - val_loss: 15.6193 - val_accuracy: 0.8913\n",
      "Epoch 7/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 6.9322 - accuracy: 0.9088 - val_loss: 17.2045 - val_accuracy: 0.8922\n",
      "Epoch 8/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 2.9389 - accuracy: 0.9457 - val_loss: 15.5174 - val_accuracy: 0.9076\n",
      "Epoch 9/60\n",
      "52/52 [==============================] - 15s 283ms/step - loss: 2.6769 - accuracy: 0.9481 - val_loss: 14.9613 - val_accuracy: 0.9094\n",
      "Epoch 10/60\n",
      "52/52 [==============================] - 15s 284ms/step - loss: 1.5837 - accuracy: 0.9626 - val_loss: 14.0915 - val_accuracy: 0.8986\n",
      "Epoch 11/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 2.0645 - accuracy: 0.9620 - val_loss: 13.5285 - val_accuracy: 0.9076\n",
      "Epoch 12/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 1.4022 - accuracy: 0.9614 - val_loss: 12.4892 - val_accuracy: 0.9158\n",
      "Epoch 13/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 2.2858 - accuracy: 0.9511 - val_loss: 25.5377 - val_accuracy: 0.8668\n",
      "Epoch 14/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 9.4938 - accuracy: 0.8998 - val_loss: 18.3441 - val_accuracy: 0.8714\n",
      "Epoch 15/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 2.3113 - accuracy: 0.9360 - val_loss: 12.7742 - val_accuracy: 0.9004\n",
      "Epoch 16/60\n",
      "52/52 [==============================] - 15s 283ms/step - loss: 1.3620 - accuracy: 0.9607 - val_loss: 15.9746 - val_accuracy: 0.9031\n",
      "Epoch 17/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 1.4159 - accuracy: 0.9632 - val_loss: 13.4377 - val_accuracy: 0.8931\n",
      "Epoch 18/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 1.0209 - accuracy: 0.9668 - val_loss: 20.1696 - val_accuracy: 0.9103\n",
      "Epoch 19/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.9775 - accuracy: 0.9686 - val_loss: 13.0828 - val_accuracy: 0.9167\n",
      "Epoch 20/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.1835 - accuracy: 0.9879 - val_loss: 11.2286 - val_accuracy: 0.9257\n",
      "Epoch 21/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.0906 - accuracy: 0.9903 - val_loss: 12.6600 - val_accuracy: 0.9194\n",
      "Epoch 22/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.5355 - accuracy: 0.9843 - val_loss: 14.9207 - val_accuracy: 0.9139\n",
      "Epoch 23/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.6016 - accuracy: 0.9758 - val_loss: 16.7846 - val_accuracy: 0.8804\n",
      "Epoch 24/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 1.1497 - accuracy: 0.9601 - val_loss: 14.6431 - val_accuracy: 0.8904\n",
      "Epoch 25/60\n",
      "52/52 [==============================] - 15s 283ms/step - loss: 5.7898 - accuracy: 0.9372 - val_loss: 33.2909 - val_accuracy: 0.7880\n",
      "Epoch 26/60\n",
      "52/52 [==============================] - 15s 284ms/step - loss: 10.0822 - accuracy: 0.8907 - val_loss: 17.9435 - val_accuracy: 0.8940\n",
      "Epoch 27/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 2.3380 - accuracy: 0.9493 - val_loss: 14.7874 - val_accuracy: 0.8913\n",
      "Epoch 28/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 1.3495 - accuracy: 0.9626 - val_loss: 10.8708 - val_accuracy: 0.9203\n",
      "Epoch 29/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.2374 - accuracy: 0.9855 - val_loss: 10.1200 - val_accuracy: 0.9212\n",
      "Epoch 30/60\n",
      "52/52 [==============================] - 15s 283ms/step - loss: 0.0692 - accuracy: 0.9958 - val_loss: 9.0247 - val_accuracy: 0.9312\n",
      "Epoch 31/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.1138 - accuracy: 0.9897 - val_loss: 17.3418 - val_accuracy: 0.8995\n",
      "Epoch 32/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.3852 - accuracy: 0.9825 - val_loss: 13.0461 - val_accuracy: 0.9058\n",
      "Epoch 33/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.0656 - accuracy: 0.9940 - val_loss: 9.4188 - val_accuracy: 0.9149\n",
      "Epoch 34/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.1036 - accuracy: 0.9928 - val_loss: 9.3031 - val_accuracy: 0.9112\n",
      "Epoch 35/60\n",
      "52/52 [==============================] - 15s 284ms/step - loss: 0.2998 - accuracy: 0.9831 - val_loss: 10.1230 - val_accuracy: 0.9149\n",
      "Epoch 36/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.2626 - accuracy: 0.9861 - val_loss: 10.7092 - val_accuracy: 0.9149\n",
      "Epoch 37/60\n",
      "52/52 [==============================] - 15s 283ms/step - loss: 0.1365 - accuracy: 0.9921 - val_loss: 11.8115 - val_accuracy: 0.9094\n",
      "Epoch 38/60\n",
      "52/52 [==============================] - 15s 283ms/step - loss: 0.0431 - accuracy: 0.9976 - val_loss: 7.5625 - val_accuracy: 0.9167\n",
      "Epoch 39/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.3154 - accuracy: 0.9867 - val_loss: 8.8100 - val_accuracy: 0.9121\n",
      "Epoch 40/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.5003 - accuracy: 0.9777 - val_loss: 12.3263 - val_accuracy: 0.9212\n",
      "Epoch 41/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.0811 - accuracy: 0.9891 - val_loss: 8.8712 - val_accuracy: 0.9221\n",
      "Epoch 42/60\n",
      "52/52 [==============================] - 15s 284ms/step - loss: 0.1960 - accuracy: 0.9879 - val_loss: 10.6651 - val_accuracy: 0.9248\n",
      "Epoch 43/60\n",
      "52/52 [==============================] - 15s 283ms/step - loss: 0.1407 - accuracy: 0.9921 - val_loss: 12.9765 - val_accuracy: 0.9239\n",
      "Epoch 44/60\n",
      "52/52 [==============================] - 15s 284ms/step - loss: 0.1898 - accuracy: 0.9903 - val_loss: 12.1723 - val_accuracy: 0.9185\n",
      "Epoch 45/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.1275 - accuracy: 0.9897 - val_loss: 8.7290 - val_accuracy: 0.9158\n",
      "Epoch 46/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.1471 - accuracy: 0.9879 - val_loss: 9.9042 - val_accuracy: 0.9330\n",
      "Epoch 47/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.2041 - accuracy: 0.9897 - val_loss: 11.3926 - val_accuracy: 0.9112\n",
      "Epoch 48/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 1.1953 - accuracy: 0.9614 - val_loss: 11.0772 - val_accuracy: 0.9013\n",
      "Epoch 49/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 1.3758 - accuracy: 0.9668 - val_loss: 12.9362 - val_accuracy: 0.8804\n",
      "Epoch 50/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 1.1630 - accuracy: 0.9583 - val_loss: 16.1649 - val_accuracy: 0.8750\n",
      "Epoch 51/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 1.5246 - accuracy: 0.9674 - val_loss: 16.1499 - val_accuracy: 0.9139\n",
      "Epoch 52/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.6675 - accuracy: 0.9777 - val_loss: 12.3903 - val_accuracy: 0.8940\n",
      "Epoch 53/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 1.0835 - accuracy: 0.9614 - val_loss: 13.2238 - val_accuracy: 0.9149\n",
      "Epoch 54/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.7491 - accuracy: 0.9764 - val_loss: 12.3445 - val_accuracy: 0.9266\n",
      "Epoch 55/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.5895 - accuracy: 0.9825 - val_loss: 11.7121 - val_accuracy: 0.9293\n",
      "Epoch 56/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.1847 - accuracy: 0.9915 - val_loss: 8.8014 - val_accuracy: 0.9230\n",
      "Epoch 57/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.0597 - accuracy: 0.9928 - val_loss: 8.6695 - val_accuracy: 0.9248\n",
      "Epoch 58/60\n",
      "52/52 [==============================] - 15s 283ms/step - loss: 0.0413 - accuracy: 0.9946 - val_loss: 12.9566 - val_accuracy: 0.9130\n",
      "Epoch 59/60\n",
      "52/52 [==============================] - 19s 371ms/step - loss: 0.4240 - accuracy: 0.9861 - val_loss: 15.9857 - val_accuracy: 0.9049\n",
      "Epoch 60/60\n",
      "52/52 [==============================] - 19s 372ms/step - loss: 0.4310 - accuracy: 0.9873 - val_loss: 9.7493 - val_accuracy: 0.9185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e27867c6920>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xception_model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:02:43.397115Z",
     "iopub.status.busy": "2023-08-08T23:02:43.396092Z",
     "iopub.status.idle": "2023-08-08T23:02:43.826879Z",
     "shell.execute_reply": "2023-08-08T23:02:43.825817Z",
     "shell.execute_reply.started": "2023-08-08T23:02:43.397069Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg_wo_top = keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', input_shape=(350, 350, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:02:43.829135Z",
     "iopub.status.busy": "2023-08-08T23:02:43.828761Z",
     "iopub.status.idle": "2023-08-08T23:02:43.835502Z",
     "shell.execute_reply": "2023-08-08T23:02:43.834570Z",
     "shell.execute_reply.started": "2023-08-08T23:02:43.829102Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg_wo_top.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:02:44.881385Z",
     "iopub.status.busy": "2023-08-08T23:02:44.880639Z",
     "iopub.status.idle": "2023-08-08T23:02:45.014983Z",
     "shell.execute_reply": "2023-08-08T23:02:45.014148Z",
     "shell.execute_reply.started": "2023-08-08T23:02:44.881347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 10, 10, 512)       20024384  \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 51200)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               6553728   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,586,888\n",
      "Trainable params: 6,562,504\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model = keras.models.Sequential()\n",
    "vgg_model.add(vgg_wo_top)\n",
    "vgg_model.add(keras.layers.Flatten())\n",
    "vgg_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "vgg_model.add(keras.layers.Dense(64, activation='relu'))\n",
    "vgg_model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:02:51.233159Z",
     "iopub.status.busy": "2023-08-08T23:02:51.232796Z",
     "iopub.status.idle": "2023-08-08T23:02:51.247299Z",
     "shell.execute_reply": "2023-08-08T23:02:51.246385Z",
     "shell.execute_reply.started": "2023-08-08T23:02:51.233129Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg_model.compile(optimizer=keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:02:52.597053Z",
     "iopub.status.busy": "2023-08-08T23:02:52.596674Z",
     "iopub.status.idle": "2023-08-08T23:21:13.328603Z",
     "shell.execute_reply": "2023-08-08T23:21:13.327663Z",
     "shell.execute_reply.started": "2023-08-08T23:02:52.597021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "52/52 [==============================] - 22s 401ms/step - loss: 85.9902 - accuracy: 0.7911 - val_loss: 22.0625 - val_accuracy: 0.8659\n",
      "Epoch 2/60\n",
      "52/52 [==============================] - 16s 300ms/step - loss: 9.3314 - accuracy: 0.9004 - val_loss: 7.1684 - val_accuracy: 0.9013\n",
      "Epoch 3/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 3.9253 - accuracy: 0.9414 - val_loss: 3.8011 - val_accuracy: 0.9402\n",
      "Epoch 4/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 3.3530 - accuracy: 0.9330 - val_loss: 5.3074 - val_accuracy: 0.9112\n",
      "Epoch 5/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 1.2143 - accuracy: 0.9589 - val_loss: 3.5653 - val_accuracy: 0.9266\n",
      "Epoch 6/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 0.9388 - accuracy: 0.9620 - val_loss: 7.1450 - val_accuracy: 0.9139\n",
      "Epoch 7/60\n",
      "52/52 [==============================] - 16s 302ms/step - loss: 0.9211 - accuracy: 0.9746 - val_loss: 2.7691 - val_accuracy: 0.9366\n",
      "Epoch 8/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 0.5136 - accuracy: 0.9746 - val_loss: 2.3522 - val_accuracy: 0.9339\n",
      "Epoch 9/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 0.1783 - accuracy: 0.9885 - val_loss: 1.0874 - val_accuracy: 0.9647\n",
      "Epoch 10/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 0.1995 - accuracy: 0.9903 - val_loss: 1.1319 - val_accuracy: 0.9647\n",
      "Epoch 11/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 0.2352 - accuracy: 0.9903 - val_loss: 3.3612 - val_accuracy: 0.9293\n",
      "Epoch 12/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 4.7518 - accuracy: 0.9390 - val_loss: 5.3197 - val_accuracy: 0.9384\n",
      "Epoch 13/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 2.5587 - accuracy: 0.9523 - val_loss: 4.5312 - val_accuracy: 0.9112\n",
      "Epoch 14/60\n",
      "52/52 [==============================] - 20s 383ms/step - loss: 0.8314 - accuracy: 0.9698 - val_loss: 1.3848 - val_accuracy: 0.9656\n",
      "Epoch 15/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 1.0579 - accuracy: 0.9680 - val_loss: 2.0546 - val_accuracy: 0.9420\n",
      "Epoch 16/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 0.2574 - accuracy: 0.9891 - val_loss: 1.7647 - val_accuracy: 0.9683\n",
      "Epoch 17/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 0.0304 - accuracy: 0.9976 - val_loss: 2.2809 - val_accuracy: 0.9601\n",
      "Epoch 18/60\n",
      "52/52 [==============================] - 20s 383ms/step - loss: 0.7991 - accuracy: 0.9837 - val_loss: 3.8638 - val_accuracy: 0.9556\n",
      "Epoch 19/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 0.9722 - accuracy: 0.9777 - val_loss: 1.4689 - val_accuracy: 0.9728\n",
      "Epoch 20/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 0.2782 - accuracy: 0.9897 - val_loss: 2.5678 - val_accuracy: 0.9665\n",
      "Epoch 21/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 0.0507 - accuracy: 0.9958 - val_loss: 2.4646 - val_accuracy: 0.9656\n",
      "Epoch 22/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 0.1463 - accuracy: 0.9952 - val_loss: 2.4310 - val_accuracy: 0.9683\n",
      "Epoch 23/60\n",
      "52/52 [==============================] - 20s 383ms/step - loss: 0.0163 - accuracy: 0.9976 - val_loss: 1.7971 - val_accuracy: 0.9665\n",
      "Epoch 24/60\n",
      "52/52 [==============================] - 16s 300ms/step - loss: 0.1249 - accuracy: 0.9952 - val_loss: 3.2285 - val_accuracy: 0.9484\n",
      "Epoch 25/60\n",
      "52/52 [==============================] - 16s 302ms/step - loss: 0.1723 - accuracy: 0.9940 - val_loss: 4.5290 - val_accuracy: 0.9538\n",
      "Epoch 26/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 0.5327 - accuracy: 0.9849 - val_loss: 2.8573 - val_accuracy: 0.9275\n",
      "Epoch 27/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 0.1732 - accuracy: 0.9897 - val_loss: 0.8022 - val_accuracy: 0.9792\n",
      "Epoch 28/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 0.1775 - accuracy: 0.9934 - val_loss: 1.7753 - val_accuracy: 0.9638\n",
      "Epoch 29/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 0.0949 - accuracy: 0.9946 - val_loss: 1.8963 - val_accuracy: 0.9737\n",
      "Epoch 30/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 0.0528 - accuracy: 0.9982 - val_loss: 2.6051 - val_accuracy: 0.9674\n",
      "Epoch 31/60\n",
      "52/52 [==============================] - 16s 300ms/step - loss: 0.0553 - accuracy: 0.9964 - val_loss: 2.5181 - val_accuracy: 0.9674\n",
      "Epoch 32/60\n",
      "52/52 [==============================] - 20s 383ms/step - loss: 0.0539 - accuracy: 0.9970 - val_loss: 2.2925 - val_accuracy: 0.9692\n",
      "Epoch 33/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 0.2333 - accuracy: 0.9940 - val_loss: 4.0217 - val_accuracy: 0.9565\n",
      "Epoch 34/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 0.4167 - accuracy: 0.9891 - val_loss: 5.1368 - val_accuracy: 0.9321\n",
      "Epoch 35/60\n",
      "52/52 [==============================] - 16s 302ms/step - loss: 0.5376 - accuracy: 0.9891 - val_loss: 1.5085 - val_accuracy: 0.9692\n",
      "Epoch 36/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 0.2151 - accuracy: 0.9921 - val_loss: 3.8452 - val_accuracy: 0.9529\n",
      "Epoch 37/60\n",
      "52/52 [==============================] - 16s 302ms/step - loss: 0.5540 - accuracy: 0.9843 - val_loss: 2.3583 - val_accuracy: 0.9538\n",
      "Epoch 38/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 0.3220 - accuracy: 0.9903 - val_loss: 3.0828 - val_accuracy: 0.9583\n",
      "Epoch 39/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 0.0276 - accuracy: 0.9976 - val_loss: 2.6430 - val_accuracy: 0.9529\n",
      "Epoch 40/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 0.0153 - accuracy: 0.9982 - val_loss: 2.0424 - val_accuracy: 0.9692\n",
      "Epoch 41/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0655 - val_accuracy: 0.9701\n",
      "Epoch 42/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 43/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 44/60\n",
      "52/52 [==============================] - 20s 383ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 45/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 46/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 47/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 48/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 49/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 50/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 51/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 52/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 53/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 54/60\n",
      "52/52 [==============================] - 20s 383ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 55/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 56/60\n",
      "52/52 [==============================] - 20s 382ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 57/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 58/60\n",
      "52/52 [==============================] - 20s 381ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 59/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n",
      "Epoch 60/60\n",
      "52/52 [==============================] - 16s 301ms/step - loss: 7.1986e-11 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e22be7a7d90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:21:13.331078Z",
     "iopub.status.busy": "2023-08-08T23:21:13.330336Z",
     "iopub.status.idle": "2023-08-08T23:31:05.879965Z",
     "shell.execute_reply": "2023-08-08T23:31:05.878846Z",
     "shell.execute_reply.started": "2023-08-08T23:21:13.331044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16705208/16705208 [==============================] - 1s 0us/step\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 23:21:43.603878: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_6/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 18s 212ms/step - loss: 6.1423 - accuracy: 0.8043 - val_loss: 2.6178 - val_accuracy: 0.8605\n",
      "Epoch 2/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 2.2040 - accuracy: 0.8581 - val_loss: 2.8578 - val_accuracy: 0.8152\n",
      "Epoch 3/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 1.4169 - accuracy: 0.8931 - val_loss: 1.2205 - val_accuracy: 0.9022\n",
      "Epoch 4/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 1.0544 - accuracy: 0.9112 - val_loss: 1.0693 - val_accuracy: 0.8868\n",
      "Epoch 5/60\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 1.7739 - accuracy: 0.8889 - val_loss: 0.7137 - val_accuracy: 0.9022\n",
      "Epoch 6/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.6496 - accuracy: 0.9257 - val_loss: 0.5299 - val_accuracy: 0.9185\n",
      "Epoch 7/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.5772 - accuracy: 0.9221 - val_loss: 0.4936 - val_accuracy: 0.9248\n",
      "Epoch 8/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.6231 - accuracy: 0.9251 - val_loss: 0.7590 - val_accuracy: 0.9004\n",
      "Epoch 9/60\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.4325 - accuracy: 0.9384 - val_loss: 0.2769 - val_accuracy: 0.9429\n",
      "Epoch 10/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.3266 - accuracy: 0.9499 - val_loss: 0.5143 - val_accuracy: 0.9339\n",
      "Epoch 11/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.2929 - accuracy: 0.9432 - val_loss: 0.2512 - val_accuracy: 0.9538\n",
      "Epoch 12/60\n",
      "52/52 [==============================] - 10s 192ms/step - loss: 0.1770 - accuracy: 0.9638 - val_loss: 0.7838 - val_accuracy: 0.9022\n",
      "Epoch 13/60\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.2176 - accuracy: 0.9577 - val_loss: 0.9904 - val_accuracy: 0.9013\n",
      "Epoch 14/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.2323 - accuracy: 0.9523 - val_loss: 0.8665 - val_accuracy: 0.9185\n",
      "Epoch 15/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.1482 - accuracy: 0.9644 - val_loss: 0.4642 - val_accuracy: 0.9330\n",
      "Epoch 16/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.4323 - accuracy: 0.9457 - val_loss: 0.9423 - val_accuracy: 0.8976\n",
      "Epoch 17/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.1665 - accuracy: 0.9710 - val_loss: 0.2793 - val_accuracy: 0.9574\n",
      "Epoch 18/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0869 - accuracy: 0.9831 - val_loss: 0.3011 - val_accuracy: 0.9611\n",
      "Epoch 19/60\n",
      "52/52 [==============================] - 10s 192ms/step - loss: 0.0960 - accuracy: 0.9789 - val_loss: 0.2967 - val_accuracy: 0.9529\n",
      "Epoch 20/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0835 - accuracy: 0.9849 - val_loss: 0.2913 - val_accuracy: 0.9511\n",
      "Epoch 21/60\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.0900 - accuracy: 0.9825 - val_loss: 0.3949 - val_accuracy: 0.9511\n",
      "Epoch 22/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.1137 - accuracy: 0.9746 - val_loss: 0.4684 - val_accuracy: 0.9520\n",
      "Epoch 23/60\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.3172 - accuracy: 0.9626 - val_loss: 0.5746 - val_accuracy: 0.9429\n",
      "Epoch 24/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.2486 - accuracy: 0.9632 - val_loss: 0.2808 - val_accuracy: 0.9520\n",
      "Epoch 25/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.1220 - accuracy: 0.9783 - val_loss: 0.3056 - val_accuracy: 0.9583\n",
      "Epoch 26/60\n",
      "52/52 [==============================] - 7s 145ms/step - loss: 0.3137 - accuracy: 0.9535 - val_loss: 0.8460 - val_accuracy: 0.9312\n",
      "Epoch 27/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.2145 - accuracy: 0.9674 - val_loss: 0.5546 - val_accuracy: 0.9438\n",
      "Epoch 28/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.1929 - accuracy: 0.9680 - val_loss: 0.6900 - val_accuracy: 0.9321\n",
      "Epoch 29/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.1303 - accuracy: 0.9795 - val_loss: 0.3000 - val_accuracy: 0.9674\n",
      "Epoch 30/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0871 - accuracy: 0.9831 - val_loss: 0.6123 - val_accuracy: 0.9375\n",
      "Epoch 31/60\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.2627 - accuracy: 0.9638 - val_loss: 1.6223 - val_accuracy: 0.8967\n",
      "Epoch 32/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.2627 - accuracy: 0.9626 - val_loss: 0.4030 - val_accuracy: 0.9565\n",
      "Epoch 33/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.5566 - accuracy: 0.9438 - val_loss: 0.4867 - val_accuracy: 0.9457\n",
      "Epoch 34/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.2235 - accuracy: 0.9692 - val_loss: 0.3198 - val_accuracy: 0.9411\n",
      "Epoch 35/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0731 - accuracy: 0.9825 - val_loss: 0.3134 - val_accuracy: 0.9611\n",
      "Epoch 36/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.1319 - accuracy: 0.9716 - val_loss: 0.3343 - val_accuracy: 0.9520\n",
      "Epoch 37/60\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.0804 - accuracy: 0.9789 - val_loss: 0.3220 - val_accuracy: 0.9529\n",
      "Epoch 38/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0807 - accuracy: 0.9843 - val_loss: 0.1851 - val_accuracy: 0.9701\n",
      "Epoch 39/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0886 - accuracy: 0.9831 - val_loss: 0.2229 - val_accuracy: 0.9674\n",
      "Epoch 40/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0405 - accuracy: 0.9903 - val_loss: 0.3506 - val_accuracy: 0.9601\n",
      "Epoch 41/60\n",
      "52/52 [==============================] - 10s 192ms/step - loss: 0.0548 - accuracy: 0.9855 - val_loss: 0.3034 - val_accuracy: 0.9574\n",
      "Epoch 42/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.1175 - accuracy: 0.9813 - val_loss: 0.1664 - val_accuracy: 0.9710\n",
      "Epoch 43/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.0389 - accuracy: 0.9921 - val_loss: 0.2555 - val_accuracy: 0.9592\n",
      "Epoch 44/60\n",
      "52/52 [==============================] - 7s 145ms/step - loss: 0.0694 - accuracy: 0.9837 - val_loss: 0.3212 - val_accuracy: 0.9457\n",
      "Epoch 45/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0844 - accuracy: 0.9837 - val_loss: 0.7345 - val_accuracy: 0.9185\n",
      "Epoch 46/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.2063 - accuracy: 0.9650 - val_loss: 0.5354 - val_accuracy: 0.9438\n",
      "Epoch 47/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0638 - accuracy: 0.9831 - val_loss: 0.2984 - val_accuracy: 0.9601\n",
      "Epoch 48/60\n",
      "52/52 [==============================] - 7s 145ms/step - loss: 0.0637 - accuracy: 0.9855 - val_loss: 0.5703 - val_accuracy: 0.9511\n",
      "Epoch 49/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.1212 - accuracy: 0.9789 - val_loss: 0.5581 - val_accuracy: 0.9429\n",
      "Epoch 50/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.2251 - accuracy: 0.9656 - val_loss: 0.6722 - val_accuracy: 0.9266\n",
      "Epoch 51/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.1135 - accuracy: 0.9740 - val_loss: 0.4554 - val_accuracy: 0.9284\n",
      "Epoch 52/60\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.0955 - accuracy: 0.9783 - val_loss: 0.1780 - val_accuracy: 0.9583\n",
      "Epoch 53/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0849 - accuracy: 0.9771 - val_loss: 0.3105 - val_accuracy: 0.9556\n",
      "Epoch 54/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.1140 - accuracy: 0.9771 - val_loss: 0.1748 - val_accuracy: 0.9674\n",
      "Epoch 55/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0335 - accuracy: 0.9928 - val_loss: 0.1731 - val_accuracy: 0.9683\n",
      "Epoch 56/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.1425 - accuracy: 0.9752 - val_loss: 0.2992 - val_accuracy: 0.9447\n",
      "Epoch 57/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.4788 - accuracy: 0.9420 - val_loss: 0.1946 - val_accuracy: 0.9393\n",
      "Epoch 58/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.1730 - accuracy: 0.9583 - val_loss: 0.1676 - val_accuracy: 0.9574\n",
      "Epoch 59/60\n",
      "52/52 [==============================] - 10s 192ms/step - loss: 0.1022 - accuracy: 0.9710 - val_loss: 0.2446 - val_accuracy: 0.9466\n",
      "Epoch 60/60\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.1586 - accuracy: 0.9565 - val_loss: 0.4281 - val_accuracy: 0.9203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e27a01eafe0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enb0_wo_top = keras.applications.efficientnet.EfficientNetB0(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n",
    "\n",
    "enb0_wo_top.trainable = False\n",
    "\n",
    "enb0_model = keras.models.Sequential()\n",
    "enb0_model.add(enb0_wo_top)\n",
    "enb0_model.add(keras.layers.Flatten())\n",
    "enb0_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "enb0_model.add(keras.layers.Dense(64, activation='relu'))\n",
    "enb0_model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "enb0_model.compile(optimizer=keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "enb0_model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:33:52.744967Z",
     "iopub.status.busy": "2023-08-08T23:33:52.743959Z",
     "iopub.status.idle": "2023-08-08T23:45:29.747600Z",
     "shell.execute_reply": "2023-08-08T23:45:29.746515Z",
     "shell.execute_reply.started": "2023-08-08T23:33:52.744928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 23:34:07.340949: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_8/efficientnetb1/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 25s 278ms/step - loss: 6.1659 - accuracy: 0.7790 - val_loss: 0.6102 - val_accuracy: 0.8641\n",
      "Epoch 2/60\n",
      "52/52 [==============================] - 11s 223ms/step - loss: 0.8217 - accuracy: 0.8569 - val_loss: 0.3347 - val_accuracy: 0.8895\n",
      "Epoch 3/60\n",
      "52/52 [==============================] - 11s 223ms/step - loss: 0.5218 - accuracy: 0.8901 - val_loss: 0.9057 - val_accuracy: 0.8886\n",
      "Epoch 4/60\n",
      "52/52 [==============================] - 11s 223ms/step - loss: 0.5193 - accuracy: 0.8925 - val_loss: 0.3960 - val_accuracy: 0.9049\n",
      "Epoch 5/60\n",
      "52/52 [==============================] - 12s 223ms/step - loss: 0.4840 - accuracy: 0.8949 - val_loss: 0.4034 - val_accuracy: 0.8922\n",
      "Epoch 6/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.3091 - accuracy: 0.9094 - val_loss: 0.2264 - val_accuracy: 0.9284\n",
      "Epoch 7/60\n",
      "52/52 [==============================] - 12s 223ms/step - loss: 0.3014 - accuracy: 0.9185 - val_loss: 0.3291 - val_accuracy: 0.9149\n",
      "Epoch 8/60\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.2349 - accuracy: 0.9300 - val_loss: 0.1794 - val_accuracy: 0.9248\n",
      "Epoch 9/60\n",
      "52/52 [==============================] - 10s 196ms/step - loss: 0.1562 - accuracy: 0.9402 - val_loss: 0.1964 - val_accuracy: 0.9284\n",
      "Epoch 10/60\n",
      "52/52 [==============================] - 12s 223ms/step - loss: 0.1421 - accuracy: 0.9475 - val_loss: 0.2444 - val_accuracy: 0.9094\n",
      "Epoch 11/60\n",
      "52/52 [==============================] - 12s 225ms/step - loss: 0.2513 - accuracy: 0.9227 - val_loss: 0.2274 - val_accuracy: 0.9167\n",
      "Epoch 12/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.1697 - accuracy: 0.9487 - val_loss: 0.1599 - val_accuracy: 0.9293\n",
      "Epoch 13/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.1586 - accuracy: 0.9450 - val_loss: 0.2681 - val_accuracy: 0.9230\n",
      "Epoch 14/60\n",
      "52/52 [==============================] - 10s 196ms/step - loss: 0.1630 - accuracy: 0.9366 - val_loss: 0.1387 - val_accuracy: 0.9520\n",
      "Epoch 15/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.1225 - accuracy: 0.9535 - val_loss: 0.2724 - val_accuracy: 0.9049\n",
      "Epoch 16/60\n",
      "52/52 [==============================] - 11s 223ms/step - loss: 0.1245 - accuracy: 0.9547 - val_loss: 0.3164 - val_accuracy: 0.9013\n",
      "Epoch 17/60\n",
      "52/52 [==============================] - 12s 225ms/step - loss: 0.1708 - accuracy: 0.9402 - val_loss: 0.1185 - val_accuracy: 0.9538\n",
      "Epoch 18/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.1258 - accuracy: 0.9571 - val_loss: 0.1233 - val_accuracy: 0.9520\n",
      "Epoch 19/60\n",
      "52/52 [==============================] - 11s 222ms/step - loss: 0.1076 - accuracy: 0.9626 - val_loss: 0.1615 - val_accuracy: 0.9420\n",
      "Epoch 20/60\n",
      "52/52 [==============================] - 12s 224ms/step - loss: 0.1131 - accuracy: 0.9559 - val_loss: 0.1624 - val_accuracy: 0.9457\n",
      "Epoch 21/60\n",
      "52/52 [==============================] - 12s 223ms/step - loss: 0.1063 - accuracy: 0.9644 - val_loss: 0.1643 - val_accuracy: 0.9429\n",
      "Epoch 22/60\n",
      "52/52 [==============================] - 10s 196ms/step - loss: 0.0991 - accuracy: 0.9589 - val_loss: 0.1453 - val_accuracy: 0.9493\n",
      "Epoch 23/60\n",
      "52/52 [==============================] - 12s 224ms/step - loss: 0.0815 - accuracy: 0.9746 - val_loss: 0.1022 - val_accuracy: 0.9629\n",
      "Epoch 24/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.0802 - accuracy: 0.9698 - val_loss: 0.2133 - val_accuracy: 0.9475\n",
      "Epoch 25/60\n",
      "52/52 [==============================] - 11s 223ms/step - loss: 0.0572 - accuracy: 0.9789 - val_loss: 0.1263 - val_accuracy: 0.9574\n",
      "Epoch 26/60\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.0834 - accuracy: 0.9692 - val_loss: 0.1254 - val_accuracy: 0.9565\n",
      "Epoch 27/60\n",
      "52/52 [==============================] - 12s 223ms/step - loss: 0.1095 - accuracy: 0.9589 - val_loss: 0.1984 - val_accuracy: 0.9375\n",
      "Epoch 28/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.1310 - accuracy: 0.9583 - val_loss: 0.2445 - val_accuracy: 0.9348\n",
      "Epoch 29/60\n",
      "52/52 [==============================] - 12s 225ms/step - loss: 0.1285 - accuracy: 0.9529 - val_loss: 0.1448 - val_accuracy: 0.9574\n",
      "Epoch 30/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.1393 - accuracy: 0.9577 - val_loss: 0.1717 - val_accuracy: 0.9420\n",
      "Epoch 31/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.1714 - accuracy: 0.9547 - val_loss: 0.1348 - val_accuracy: 0.9502\n",
      "Epoch 32/60\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.0854 - accuracy: 0.9668 - val_loss: 0.1383 - val_accuracy: 0.9592\n",
      "Epoch 33/60\n",
      "52/52 [==============================] - 12s 224ms/step - loss: 0.0304 - accuracy: 0.9867 - val_loss: 0.1502 - val_accuracy: 0.9574\n",
      "Epoch 34/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.0589 - accuracy: 0.9807 - val_loss: 0.1993 - val_accuracy: 0.9475\n",
      "Epoch 35/60\n",
      "52/52 [==============================] - 12s 224ms/step - loss: 0.0830 - accuracy: 0.9704 - val_loss: 0.1478 - val_accuracy: 0.9638\n",
      "Epoch 36/60\n",
      "52/52 [==============================] - 11s 223ms/step - loss: 0.1297 - accuracy: 0.9571 - val_loss: 0.1587 - val_accuracy: 0.9420\n",
      "Epoch 37/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.1179 - accuracy: 0.9674 - val_loss: 0.1783 - val_accuracy: 0.9366\n",
      "Epoch 38/60\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.1046 - accuracy: 0.9680 - val_loss: 0.1381 - val_accuracy: 0.9601\n",
      "Epoch 39/60\n",
      "52/52 [==============================] - 12s 223ms/step - loss: 0.0705 - accuracy: 0.9783 - val_loss: 0.1931 - val_accuracy: 0.9375\n",
      "Epoch 40/60\n",
      "52/52 [==============================] - 12s 223ms/step - loss: 0.0581 - accuracy: 0.9777 - val_loss: 0.1620 - val_accuracy: 0.9475\n",
      "Epoch 41/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.0704 - accuracy: 0.9771 - val_loss: 0.0935 - val_accuracy: 0.9692\n",
      "Epoch 42/60\n",
      "52/52 [==============================] - 11s 223ms/step - loss: 0.0643 - accuracy: 0.9789 - val_loss: 0.1501 - val_accuracy: 0.9547\n",
      "Epoch 43/60\n",
      "52/52 [==============================] - 10s 196ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.1571 - val_accuracy: 0.9629\n",
      "Epoch 44/60\n",
      "52/52 [==============================] - 12s 224ms/step - loss: 0.0466 - accuracy: 0.9825 - val_loss: 0.1698 - val_accuracy: 0.9574\n",
      "Epoch 45/60\n",
      "52/52 [==============================] - 12s 223ms/step - loss: 0.0457 - accuracy: 0.9831 - val_loss: 0.2491 - val_accuracy: 0.9502\n",
      "Epoch 46/60\n",
      "52/52 [==============================] - 11s 223ms/step - loss: 0.0459 - accuracy: 0.9861 - val_loss: 0.1310 - val_accuracy: 0.9620\n",
      "Epoch 47/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.0359 - accuracy: 0.9885 - val_loss: 0.1035 - val_accuracy: 0.9683\n",
      "Epoch 48/60\n",
      "52/52 [==============================] - 11s 223ms/step - loss: 0.1113 - accuracy: 0.9704 - val_loss: 0.4823 - val_accuracy: 0.9239\n",
      "Epoch 49/60\n",
      "52/52 [==============================] - 12s 224ms/step - loss: 0.1095 - accuracy: 0.9656 - val_loss: 0.2282 - val_accuracy: 0.9366\n",
      "Epoch 50/60\n",
      "52/52 [==============================] - 10s 196ms/step - loss: 0.1219 - accuracy: 0.9674 - val_loss: 0.1446 - val_accuracy: 0.9511\n",
      "Epoch 51/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.0731 - accuracy: 0.9716 - val_loss: 0.1715 - val_accuracy: 0.9475\n",
      "Epoch 52/60\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.0848 - accuracy: 0.9752 - val_loss: 0.2547 - val_accuracy: 0.9384\n",
      "Epoch 53/60\n",
      "52/52 [==============================] - 10s 196ms/step - loss: 0.0633 - accuracy: 0.9807 - val_loss: 0.1495 - val_accuracy: 0.9592\n",
      "Epoch 54/60\n",
      "52/52 [==============================] - 10s 196ms/step - loss: 0.0461 - accuracy: 0.9807 - val_loss: 0.1137 - val_accuracy: 0.9692\n",
      "Epoch 55/60\n",
      "52/52 [==============================] - 12s 224ms/step - loss: 0.0429 - accuracy: 0.9873 - val_loss: 0.1494 - val_accuracy: 0.9629\n",
      "Epoch 56/60\n",
      "52/52 [==============================] - 11s 223ms/step - loss: 0.0301 - accuracy: 0.9891 - val_loss: 0.1255 - val_accuracy: 0.9674\n",
      "Epoch 57/60\n",
      "52/52 [==============================] - 12s 223ms/step - loss: 0.0352 - accuracy: 0.9867 - val_loss: 0.1551 - val_accuracy: 0.9611\n",
      "Epoch 58/60\n",
      "52/52 [==============================] - 12s 225ms/step - loss: 0.0222 - accuracy: 0.9903 - val_loss: 0.1104 - val_accuracy: 0.9665\n",
      "Epoch 59/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.0360 - accuracy: 0.9861 - val_loss: 0.1077 - val_accuracy: 0.9728\n",
      "Epoch 60/60\n",
      "52/52 [==============================] - 10s 195ms/step - loss: 0.0439 - accuracy: 0.9843 - val_loss: 0.2874 - val_accuracy: 0.9321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e23415c5180>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enb1_wo_top = keras.applications.efficientnet.EfficientNetB1(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n",
    "\n",
    "enb1_wo_top.trainable = False\n",
    "\n",
    "enb1_model = keras.models.Sequential()\n",
    "enb1_model.add(enb1_wo_top)\n",
    "enb1_model.add(keras.layers.Flatten())\n",
    "enb1_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "enb1_model.add(keras.layers.Dense(64, activation='relu'))\n",
    "enb1_model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "enb1_model.compile(optimizer=keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "enb1_model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:45:29.750308Z",
     "iopub.status.busy": "2023-08-08T23:45:29.749927Z",
     "iopub.status.idle": "2023-08-08T23:55:09.765371Z",
     "shell.execute_reply": "2023-08-08T23:55:09.764195Z",
     "shell.execute_reply.started": "2023-08-08T23:45:29.750272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n",
      "31790344/31790344 [==============================] - 2s 0us/step\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 23:45:47.483126: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_9/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 22s 188ms/step - loss: 5.4259 - accuracy: 0.8080 - val_loss: 2.3266 - val_accuracy: 0.8505\n",
      "Epoch 2/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 2.1643 - accuracy: 0.8557 - val_loss: 1.1332 - val_accuracy: 0.8388\n",
      "Epoch 3/60\n",
      "52/52 [==============================] - 10s 192ms/step - loss: 0.6941 - accuracy: 0.8955 - val_loss: 0.5625 - val_accuracy: 0.9013\n",
      "Epoch 4/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.5179 - accuracy: 0.9052 - val_loss: 0.3942 - val_accuracy: 0.9158\n",
      "Epoch 5/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.3307 - accuracy: 0.9251 - val_loss: 0.2081 - val_accuracy: 0.9384\n",
      "Epoch 6/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.2605 - accuracy: 0.9414 - val_loss: 0.5969 - val_accuracy: 0.8832\n",
      "Epoch 7/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.3232 - accuracy: 0.9354 - val_loss: 0.3032 - val_accuracy: 0.9357\n",
      "Epoch 8/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.5712 - accuracy: 0.9233 - val_loss: 1.0412 - val_accuracy: 0.8895\n",
      "Epoch 9/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.3884 - accuracy: 0.9269 - val_loss: 0.3644 - val_accuracy: 0.9303\n",
      "Epoch 10/60\n",
      "52/52 [==============================] - 10s 192ms/step - loss: 0.2309 - accuracy: 0.9475 - val_loss: 0.3009 - val_accuracy: 0.9303\n",
      "Epoch 11/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.1515 - accuracy: 0.9577 - val_loss: 0.2148 - val_accuracy: 0.9457\n",
      "Epoch 12/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.1531 - accuracy: 0.9571 - val_loss: 0.4272 - val_accuracy: 0.9475\n",
      "Epoch 13/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.2243 - accuracy: 0.9511 - val_loss: 0.4230 - val_accuracy: 0.9203\n",
      "Epoch 14/60\n",
      "52/52 [==============================] - 8s 145ms/step - loss: 0.3373 - accuracy: 0.9179 - val_loss: 0.3711 - val_accuracy: 0.9230\n",
      "Epoch 15/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.2830 - accuracy: 0.9463 - val_loss: 0.3229 - val_accuracy: 0.9466\n",
      "Epoch 16/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.1029 - accuracy: 0.9728 - val_loss: 0.1711 - val_accuracy: 0.9556\n",
      "Epoch 17/60\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.0870 - accuracy: 0.9710 - val_loss: 0.2202 - val_accuracy: 0.9475\n",
      "Epoch 18/60\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.0884 - accuracy: 0.9716 - val_loss: 0.2643 - val_accuracy: 0.9447\n",
      "Epoch 19/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0501 - accuracy: 0.9861 - val_loss: 0.1324 - val_accuracy: 0.9592\n",
      "Epoch 20/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0494 - accuracy: 0.9867 - val_loss: 0.1597 - val_accuracy: 0.9601\n",
      "Epoch 21/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0847 - accuracy: 0.9771 - val_loss: 0.4530 - val_accuracy: 0.9158\n",
      "Epoch 22/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.1049 - accuracy: 0.9734 - val_loss: 0.2734 - val_accuracy: 0.9447\n",
      "Epoch 23/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.0706 - accuracy: 0.9764 - val_loss: 0.2439 - val_accuracy: 0.9520\n",
      "Epoch 24/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.2297 - accuracy: 0.9620 - val_loss: 1.0479 - val_accuracy: 0.8940\n",
      "Epoch 25/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.1271 - accuracy: 0.9656 - val_loss: 0.2568 - val_accuracy: 0.9457\n",
      "Epoch 26/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0900 - accuracy: 0.9728 - val_loss: 0.1443 - val_accuracy: 0.9638\n",
      "Epoch 27/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0450 - accuracy: 0.9849 - val_loss: 0.1634 - val_accuracy: 0.9556\n",
      "Epoch 28/60\n",
      "52/52 [==============================] - 7s 145ms/step - loss: 0.0512 - accuracy: 0.9807 - val_loss: 0.1423 - val_accuracy: 0.9647\n",
      "Epoch 29/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0250 - accuracy: 0.9909 - val_loss: 0.1298 - val_accuracy: 0.9728\n",
      "Epoch 30/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0346 - accuracy: 0.9897 - val_loss: 0.1134 - val_accuracy: 0.9755\n",
      "Epoch 31/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0947 - accuracy: 0.9746 - val_loss: 0.1746 - val_accuracy: 0.9620\n",
      "Epoch 32/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.1412 - accuracy: 0.9638 - val_loss: 0.6572 - val_accuracy: 0.8741\n",
      "Epoch 33/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.2420 - accuracy: 0.9487 - val_loss: 0.2771 - val_accuracy: 0.9457\n",
      "Epoch 34/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0445 - accuracy: 0.9879 - val_loss: 0.1902 - val_accuracy: 0.9529\n",
      "Epoch 35/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.1791 - val_accuracy: 0.9656\n",
      "Epoch 36/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 0.1232 - val_accuracy: 0.9737\n",
      "Epoch 37/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.0556 - accuracy: 0.9843 - val_loss: 0.2067 - val_accuracy: 0.9592\n",
      "Epoch 38/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.1073 - accuracy: 0.9752 - val_loss: 0.2597 - val_accuracy: 0.9574\n",
      "Epoch 39/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.1181 - accuracy: 0.9692 - val_loss: 0.1813 - val_accuracy: 0.9592\n",
      "Epoch 40/60\n",
      "52/52 [==============================] - 7s 144ms/step - loss: 0.0710 - accuracy: 0.9771 - val_loss: 0.4620 - val_accuracy: 0.9429\n",
      "Epoch 41/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.3628 - accuracy: 0.9493 - val_loss: 0.2692 - val_accuracy: 0.9538\n",
      "Epoch 42/60\n",
      "52/52 [==============================] - 7s 142ms/step - loss: 0.1486 - accuracy: 0.9674 - val_loss: 0.1883 - val_accuracy: 0.9611\n",
      "Epoch 43/60\n",
      "52/52 [==============================] - 7s 142ms/step - loss: 0.0697 - accuracy: 0.9813 - val_loss: 0.1227 - val_accuracy: 0.9683\n",
      "Epoch 44/60\n",
      "52/52 [==============================] - 10s 191ms/step - loss: 0.0310 - accuracy: 0.9915 - val_loss: 0.2356 - val_accuracy: 0.9592\n",
      "Epoch 45/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0518 - accuracy: 0.9825 - val_loss: 0.5095 - val_accuracy: 0.9266\n",
      "Epoch 46/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0512 - accuracy: 0.9855 - val_loss: 0.1652 - val_accuracy: 0.9638\n",
      "Epoch 47/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0548 - accuracy: 0.9819 - val_loss: 0.1818 - val_accuracy: 0.9701\n",
      "Epoch 48/60\n",
      "52/52 [==============================] - 7s 142ms/step - loss: 0.0198 - accuracy: 0.9946 - val_loss: 0.1759 - val_accuracy: 0.9583\n",
      "Epoch 49/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0141 - accuracy: 0.9946 - val_loss: 0.1883 - val_accuracy: 0.9629\n",
      "Epoch 50/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.1116 - accuracy: 0.9740 - val_loss: 0.2494 - val_accuracy: 0.9438\n",
      "Epoch 51/60\n",
      "52/52 [==============================] - 10s 193ms/step - loss: 0.0715 - accuracy: 0.9807 - val_loss: 0.2092 - val_accuracy: 0.9565\n",
      "Epoch 52/60\n",
      "52/52 [==============================] - 10s 190ms/step - loss: 0.0467 - accuracy: 0.9855 - val_loss: 0.1812 - val_accuracy: 0.9656\n",
      "Epoch 53/60\n",
      "52/52 [==============================] - 7s 142ms/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.1467 - val_accuracy: 0.9592\n",
      "Epoch 54/60\n",
      "52/52 [==============================] - 10s 189ms/step - loss: 0.0431 - accuracy: 0.9879 - val_loss: 0.1709 - val_accuracy: 0.9647\n",
      "Epoch 55/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0510 - accuracy: 0.9849 - val_loss: 0.0986 - val_accuracy: 0.9801\n",
      "Epoch 56/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0621 - accuracy: 0.9789 - val_loss: 0.0963 - val_accuracy: 0.9710\n",
      "Epoch 57/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.1329 - val_accuracy: 0.9755\n",
      "Epoch 58/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0735 - accuracy: 0.9831 - val_loss: 0.1936 - val_accuracy: 0.9638\n",
      "Epoch 59/60\n",
      "52/52 [==============================] - 10s 192ms/step - loss: 0.0325 - accuracy: 0.9891 - val_loss: 0.1482 - val_accuracy: 0.9638\n",
      "Epoch 60/60\n",
      "52/52 [==============================] - 7s 143ms/step - loss: 0.0737 - accuracy: 0.9819 - val_loss: 0.2438 - val_accuracy: 0.9529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e23417f27a0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enb2_wo_top = keras.applications.efficientnet.EfficientNetB2(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n",
    "\n",
    "enb2_wo_top.trainable = False\n",
    "\n",
    "enb2_model = keras.models.Sequential()\n",
    "enb2_model.add(enb0_wo_top)\n",
    "enb2_model.add(keras.layers.Flatten())\n",
    "enb2_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "enb2_model.add(keras.layers.Dense(64, activation='relu'))\n",
    "enb2_model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "enb2_model.compile(optimizer=keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "enb2_model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:55:09.768882Z",
     "iopub.status.busy": "2023-08-08T23:55:09.768130Z",
     "iopub.status.idle": "2023-08-09T00:09:21.243960Z",
     "shell.execute_reply": "2023-08-09T00:09:21.242914Z",
     "shell.execute_reply.started": "2023-08-08T23:55:09.768806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "43941136/43941136 [==============================] - 2s 0us/step\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 23:55:27.439774: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_10/efficientnetb3/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 34s 435ms/step - loss: 6.7080 - accuracy: 0.8116 - val_loss: 1.5043 - val_accuracy: 0.8406\n",
      "Epoch 2/60\n",
      "52/52 [==============================] - 14s 263ms/step - loss: 2.0377 - accuracy: 0.8611 - val_loss: 1.2587 - val_accuracy: 0.8976\n",
      "Epoch 3/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 1.2253 - accuracy: 0.8804 - val_loss: 1.0481 - val_accuracy: 0.8868\n",
      "Epoch 4/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.6752 - accuracy: 0.8998 - val_loss: 1.6829 - val_accuracy: 0.8723\n",
      "Epoch 5/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.5549 - accuracy: 0.9100 - val_loss: 0.6438 - val_accuracy: 0.9076\n",
      "Epoch 6/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.5370 - accuracy: 0.9155 - val_loss: 0.4864 - val_accuracy: 0.9312\n",
      "Epoch 7/60\n",
      "52/52 [==============================] - 14s 268ms/step - loss: 0.3383 - accuracy: 0.9342 - val_loss: 0.3832 - val_accuracy: 0.9348\n",
      "Epoch 8/60\n",
      "52/52 [==============================] - 14s 268ms/step - loss: 0.1333 - accuracy: 0.9577 - val_loss: 0.9283 - val_accuracy: 0.9103\n",
      "Epoch 9/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.3967 - accuracy: 0.9330 - val_loss: 0.5338 - val_accuracy: 0.9266\n",
      "Epoch 10/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.3376 - accuracy: 0.9354 - val_loss: 0.8324 - val_accuracy: 0.9049\n",
      "Epoch 11/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.4704 - accuracy: 0.9233 - val_loss: 0.4474 - val_accuracy: 0.9085\n",
      "Epoch 12/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.3558 - accuracy: 0.9281 - val_loss: 1.2272 - val_accuracy: 0.8397\n",
      "Epoch 13/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.2903 - accuracy: 0.9372 - val_loss: 0.2885 - val_accuracy: 0.9275\n",
      "Epoch 14/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.6046 - accuracy: 0.9167 - val_loss: 0.3811 - val_accuracy: 0.9366\n",
      "Epoch 15/60\n",
      "52/52 [==============================] - 14s 268ms/step - loss: 0.2356 - accuracy: 0.9493 - val_loss: 0.1849 - val_accuracy: 0.9484\n",
      "Epoch 16/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.1013 - accuracy: 0.9758 - val_loss: 0.1581 - val_accuracy: 0.9574\n",
      "Epoch 17/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.0858 - accuracy: 0.9783 - val_loss: 0.2229 - val_accuracy: 0.9583\n",
      "Epoch 18/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.3772 - accuracy: 0.9281 - val_loss: 0.3300 - val_accuracy: 0.9375\n",
      "Epoch 19/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.2209 - accuracy: 0.9499 - val_loss: 0.3056 - val_accuracy: 0.9411\n",
      "Epoch 20/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.0712 - accuracy: 0.9764 - val_loss: 0.2329 - val_accuracy: 0.9484\n",
      "Epoch 21/60\n",
      "52/52 [==============================] - 14s 264ms/step - loss: 0.0773 - accuracy: 0.9746 - val_loss: 0.1939 - val_accuracy: 0.9520\n",
      "Epoch 22/60\n",
      "52/52 [==============================] - 14s 268ms/step - loss: 0.0797 - accuracy: 0.9740 - val_loss: 0.6393 - val_accuracy: 0.9004\n",
      "Epoch 23/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.1146 - accuracy: 0.9722 - val_loss: 0.1559 - val_accuracy: 0.9601\n",
      "Epoch 24/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.0432 - accuracy: 0.9855 - val_loss: 0.2775 - val_accuracy: 0.9312\n",
      "Epoch 25/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.0495 - accuracy: 0.9813 - val_loss: 0.2319 - val_accuracy: 0.9466\n",
      "Epoch 26/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.0910 - accuracy: 0.9746 - val_loss: 0.2547 - val_accuracy: 0.9321\n",
      "Epoch 27/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.0888 - accuracy: 0.9752 - val_loss: 0.1461 - val_accuracy: 0.9592\n",
      "Epoch 28/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.1135 - accuracy: 0.9668 - val_loss: 0.4578 - val_accuracy: 0.9004\n",
      "Epoch 29/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.0456 - accuracy: 0.9903 - val_loss: 0.1987 - val_accuracy: 0.9574\n",
      "Epoch 30/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.0324 - accuracy: 0.9873 - val_loss: 0.1782 - val_accuracy: 0.9538\n",
      "Epoch 31/60\n",
      "52/52 [==============================] - 14s 268ms/step - loss: 0.0368 - accuracy: 0.9855 - val_loss: 0.1789 - val_accuracy: 0.9629\n",
      "Epoch 32/60\n",
      "52/52 [==============================] - 14s 264ms/step - loss: 0.0679 - accuracy: 0.9819 - val_loss: 0.3769 - val_accuracy: 0.9049\n",
      "Epoch 33/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.1011 - accuracy: 0.9758 - val_loss: 0.2430 - val_accuracy: 0.9457\n",
      "Epoch 34/60\n",
      "52/52 [==============================] - 14s 264ms/step - loss: 0.0813 - accuracy: 0.9716 - val_loss: 0.2594 - val_accuracy: 0.9420\n",
      "Epoch 35/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.0732 - accuracy: 0.9801 - val_loss: 0.1680 - val_accuracy: 0.9710\n",
      "Epoch 36/60\n",
      "52/52 [==============================] - 14s 264ms/step - loss: 0.0843 - accuracy: 0.9789 - val_loss: 0.3848 - val_accuracy: 0.9429\n",
      "Epoch 37/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.0790 - accuracy: 0.9752 - val_loss: 0.2093 - val_accuracy: 0.9393\n",
      "Epoch 38/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.0889 - accuracy: 0.9740 - val_loss: 0.3123 - val_accuracy: 0.9520\n",
      "Epoch 39/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.0464 - accuracy: 0.9861 - val_loss: 0.1907 - val_accuracy: 0.9538\n",
      "Epoch 40/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.0627 - accuracy: 0.9813 - val_loss: 0.1504 - val_accuracy: 0.9611\n",
      "Epoch 41/60\n",
      "52/52 [==============================] - 14s 264ms/step - loss: 0.0930 - accuracy: 0.9680 - val_loss: 0.3827 - val_accuracy: 0.9429\n",
      "Epoch 42/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.1300 - accuracy: 0.9698 - val_loss: 0.3537 - val_accuracy: 0.9429\n",
      "Epoch 43/60\n",
      "52/52 [==============================] - 14s 264ms/step - loss: 0.1568 - accuracy: 0.9614 - val_loss: 0.2531 - val_accuracy: 0.9447\n",
      "Epoch 44/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.0293 - accuracy: 0.9897 - val_loss: 0.1745 - val_accuracy: 0.9592\n",
      "Epoch 45/60\n",
      "52/52 [==============================] - 14s 268ms/step - loss: 0.0457 - accuracy: 0.9843 - val_loss: 0.2436 - val_accuracy: 0.9393\n",
      "Epoch 46/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.0918 - accuracy: 0.9740 - val_loss: 0.1589 - val_accuracy: 0.9674\n",
      "Epoch 47/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.1264 - accuracy: 0.9704 - val_loss: 0.2959 - val_accuracy: 0.9429\n",
      "Epoch 48/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.1035 - accuracy: 0.9740 - val_loss: 0.3126 - val_accuracy: 0.9520\n",
      "Epoch 49/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.1434 - accuracy: 0.9686 - val_loss: 0.2756 - val_accuracy: 0.9601\n",
      "Epoch 50/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.0776 - accuracy: 0.9807 - val_loss: 0.1866 - val_accuracy: 0.9692\n",
      "Epoch 51/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 0.2321 - val_accuracy: 0.9611\n",
      "Epoch 52/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.0338 - accuracy: 0.9885 - val_loss: 0.2126 - val_accuracy: 0.9665\n",
      "Epoch 53/60\n",
      "52/52 [==============================] - 14s 264ms/step - loss: 0.0507 - accuracy: 0.9909 - val_loss: 0.2708 - val_accuracy: 0.9502\n",
      "Epoch 54/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.0573 - accuracy: 0.9837 - val_loss: 0.2121 - val_accuracy: 0.9638\n",
      "Epoch 55/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.0540 - accuracy: 0.9867 - val_loss: 0.2841 - val_accuracy: 0.9611\n",
      "Epoch 56/60\n",
      "52/52 [==============================] - 14s 265ms/step - loss: 0.0629 - accuracy: 0.9825 - val_loss: 0.1746 - val_accuracy: 0.9764\n",
      "Epoch 57/60\n",
      "52/52 [==============================] - 14s 264ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.1621 - val_accuracy: 0.9755\n",
      "Epoch 58/60\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 0.2713 - val_accuracy: 0.9547\n",
      "Epoch 59/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.0444 - accuracy: 0.9831 - val_loss: 0.2265 - val_accuracy: 0.9574\n",
      "Epoch 60/60\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.1154 - accuracy: 0.9740 - val_loss: 0.5335 - val_accuracy: 0.9112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e232385a9e0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enb3_wo_top = keras.applications.efficientnet.EfficientNetB3(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n",
    "\n",
    "enb3_wo_top.trainable = False\n",
    "\n",
    "enb3_model = keras.models.Sequential()\n",
    "enb3_model.add(enb3_wo_top)\n",
    "enb3_model.add(keras.layers.Flatten())\n",
    "enb3_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "enb3_model.add(keras.layers.Dense(64, activation='relu'))\n",
    "enb3_model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "enb3_model.compile(optimizer=keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "enb3_model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T16:13:54.113603Z",
     "iopub.status.busy": "2023-08-08T16:13:54.113228Z",
     "iopub.status.idle": "2023-08-08T16:24:36.452653Z",
     "shell.execute_reply": "2023-08-08T16:24:36.451603Z",
     "shell.execute_reply.started": "2023-08-08T16:13:54.113571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "71686520/71686520 [==============================] - 0s 0us/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 16:14:13.795919: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/efficientnetb4/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 39s 496ms/step - loss: 16.2970 - accuracy: 0.7723 - val_loss: 2.4699 - val_accuracy: 0.8170\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 22s 424ms/step - loss: 1.6939 - accuracy: 0.8611 - val_loss: 0.9919 - val_accuracy: 0.8668\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 18s 353ms/step - loss: 1.0390 - accuracy: 0.8907 - val_loss: 1.7910 - val_accuracy: 0.8053\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 22s 423ms/step - loss: 0.8329 - accuracy: 0.9070 - val_loss: 0.9539 - val_accuracy: 0.9139\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 22s 422ms/step - loss: 1.1016 - accuracy: 0.8979 - val_loss: 1.6362 - val_accuracy: 0.8931\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 18s 352ms/step - loss: 0.9206 - accuracy: 0.9046 - val_loss: 0.7742 - val_accuracy: 0.9130\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 22s 423ms/step - loss: 0.4585 - accuracy: 0.9330 - val_loss: 0.6695 - val_accuracy: 0.9221\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 18s 352ms/step - loss: 0.3021 - accuracy: 0.9529 - val_loss: 0.6316 - val_accuracy: 0.9248\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 22s 422ms/step - loss: 0.3068 - accuracy: 0.9475 - val_loss: 0.3934 - val_accuracy: 0.9493\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 18s 353ms/step - loss: 0.5822 - accuracy: 0.9306 - val_loss: 0.8503 - val_accuracy: 0.9203\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 18s 352ms/step - loss: 0.5044 - accuracy: 0.9348 - val_loss: 0.5839 - val_accuracy: 0.9266\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 22s 423ms/step - loss: 0.4016 - accuracy: 0.9420 - val_loss: 2.0281 - val_accuracy: 0.8931\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 22s 423ms/step - loss: 0.5542 - accuracy: 0.9390 - val_loss: 1.0836 - val_accuracy: 0.8940\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 22s 422ms/step - loss: 0.3785 - accuracy: 0.9511 - val_loss: 0.5732 - val_accuracy: 0.9330\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 22s 422ms/step - loss: 0.2578 - accuracy: 0.9499 - val_loss: 0.6669 - val_accuracy: 0.8995\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 18s 353ms/step - loss: 0.3288 - accuracy: 0.9505 - val_loss: 0.6144 - val_accuracy: 0.9438\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 18s 352ms/step - loss: 0.2504 - accuracy: 0.9626 - val_loss: 0.4677 - val_accuracy: 0.9357\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 22s 423ms/step - loss: 0.3787 - accuracy: 0.9505 - val_loss: 1.0466 - val_accuracy: 0.8542\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 18s 354ms/step - loss: 0.2267 - accuracy: 0.9607 - val_loss: 0.4676 - val_accuracy: 0.9511\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 18s 353ms/step - loss: 0.1656 - accuracy: 0.9674 - val_loss: 0.5972 - val_accuracy: 0.9330\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 22s 423ms/step - loss: 0.2028 - accuracy: 0.9710 - val_loss: 0.5200 - val_accuracy: 0.9466\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 22s 423ms/step - loss: 0.0902 - accuracy: 0.9795 - val_loss: 0.7485 - val_accuracy: 0.9366\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 18s 352ms/step - loss: 0.1333 - accuracy: 0.9740 - val_loss: 0.3964 - val_accuracy: 0.9457\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 22s 423ms/step - loss: 0.2764 - accuracy: 0.9565 - val_loss: 0.3097 - val_accuracy: 0.9556\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 18s 352ms/step - loss: 0.1467 - accuracy: 0.9656 - val_loss: 0.6119 - val_accuracy: 0.9366\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 22s 423ms/step - loss: 0.1342 - accuracy: 0.9740 - val_loss: 0.5946 - val_accuracy: 0.9257\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 22s 423ms/step - loss: 0.1692 - accuracy: 0.9650 - val_loss: 0.4676 - val_accuracy: 0.9357\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 22s 422ms/step - loss: 0.1914 - accuracy: 0.9692 - val_loss: 0.3298 - val_accuracy: 0.9438\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 22s 422ms/step - loss: 0.0901 - accuracy: 0.9789 - val_loss: 0.3811 - val_accuracy: 0.9511\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 22s 422ms/step - loss: 0.1905 - accuracy: 0.9650 - val_loss: 0.7595 - val_accuracy: 0.9384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x79b0e60ae3e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enb4_wo_top = keras.applications.efficientnet.EfficientNetB4(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n",
    "\n",
    "enb4_wo_top.trainable = False\n",
    "\n",
    "enb4_model = keras.models.Sequential()\n",
    "enb4_model.add(enb4_wo_top)\n",
    "enb4_model.add(keras.layers.Flatten())\n",
    "enb4_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "enb4_model.add(keras.layers.Dense(64, activation='relu'))\n",
    "enb4_model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "enb4_model.compile(optimizer=keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "enb4_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T16:25:14.414558Z",
     "iopub.status.busy": "2023-08-08T16:25:14.413483Z",
     "iopub.status.idle": "2023-08-08T16:38:53.342629Z",
     "shell.execute_reply": "2023-08-08T16:38:53.341476Z",
     "shell.execute_reply.started": "2023-08-08T16:25:14.414504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n",
      "115263384/115263384 [==============================] - 1s 0us/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 16:25:39.832937: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/efficientnetb5/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 58s 794ms/step - loss: 14.6170 - accuracy: 0.7874 - val_loss: 3.3066 - val_accuracy: 0.8623\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 25s 492ms/step - loss: 3.8318 - accuracy: 0.8315 - val_loss: 3.0094 - val_accuracy: 0.8877\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 25s 491ms/step - loss: 3.3900 - accuracy: 0.8521 - val_loss: 5.2666 - val_accuracy: 0.8261\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 26s 509ms/step - loss: 1.6034 - accuracy: 0.8792 - val_loss: 1.1937 - val_accuracy: 0.8886\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 26s 508ms/step - loss: 1.3244 - accuracy: 0.8913 - val_loss: 0.9691 - val_accuracy: 0.9022\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 25s 490ms/step - loss: 0.6872 - accuracy: 0.9215 - val_loss: 0.8188 - val_accuracy: 0.9121\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 26s 509ms/step - loss: 0.6973 - accuracy: 0.9257 - val_loss: 0.7954 - val_accuracy: 0.9149\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 26s 508ms/step - loss: 1.1151 - accuracy: 0.9016 - val_loss: 1.6219 - val_accuracy: 0.8822\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 25s 490ms/step - loss: 1.0556 - accuracy: 0.9076 - val_loss: 0.8859 - val_accuracy: 0.9139\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 25s 490ms/step - loss: 0.9023 - accuracy: 0.9179 - val_loss: 0.4620 - val_accuracy: 0.9303\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 25s 490ms/step - loss: 0.2743 - accuracy: 0.9475 - val_loss: 0.4171 - val_accuracy: 0.9275\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 25s 490ms/step - loss: 0.3568 - accuracy: 0.9469 - val_loss: 0.3610 - val_accuracy: 0.9366\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 25s 490ms/step - loss: 0.4385 - accuracy: 0.9457 - val_loss: 0.6243 - val_accuracy: 0.9384\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 25s 490ms/step - loss: 0.5887 - accuracy: 0.9203 - val_loss: 0.4403 - val_accuracy: 0.9303\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 26s 509ms/step - loss: 0.5186 - accuracy: 0.9245 - val_loss: 0.7303 - val_accuracy: 0.9049\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 26s 508ms/step - loss: 0.3024 - accuracy: 0.9511 - val_loss: 0.5021 - val_accuracy: 0.9357\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 25s 490ms/step - loss: 0.2561 - accuracy: 0.9529 - val_loss: 0.2227 - val_accuracy: 0.9493\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 26s 509ms/step - loss: 0.2373 - accuracy: 0.9481 - val_loss: 0.4880 - val_accuracy: 0.9248\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 26s 509ms/step - loss: 0.5427 - accuracy: 0.9179 - val_loss: 0.6189 - val_accuracy: 0.9158\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 26s 508ms/step - loss: 0.3141 - accuracy: 0.9390 - val_loss: 0.8658 - val_accuracy: 0.9031\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 26s 508ms/step - loss: 0.2598 - accuracy: 0.9511 - val_loss: 0.3488 - val_accuracy: 0.9384\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 26s 508ms/step - loss: 0.1560 - accuracy: 0.9674 - val_loss: 0.4051 - val_accuracy: 0.9357\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 26s 509ms/step - loss: 0.2912 - accuracy: 0.9457 - val_loss: 1.3913 - val_accuracy: 0.9149\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 26s 509ms/step - loss: 0.3184 - accuracy: 0.9541 - val_loss: 0.3680 - val_accuracy: 0.9375\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 26s 509ms/step - loss: 0.1682 - accuracy: 0.9632 - val_loss: 0.3580 - val_accuracy: 0.9402\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 26s 508ms/step - loss: 0.4220 - accuracy: 0.9426 - val_loss: 0.3209 - val_accuracy: 0.9447\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 26s 508ms/step - loss: 0.2451 - accuracy: 0.9547 - val_loss: 0.7629 - val_accuracy: 0.9040\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 26s 508ms/step - loss: 0.2362 - accuracy: 0.9529 - val_loss: 0.7903 - val_accuracy: 0.9230\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 25s 491ms/step - loss: 0.2235 - accuracy: 0.9571 - val_loss: 0.2815 - val_accuracy: 0.9529\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 26s 509ms/step - loss: 0.1570 - accuracy: 0.9680 - val_loss: 0.4111 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x79b0e2f33dc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enb5_wo_top = keras.applications.efficientnet.EfficientNetB5(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n",
    "\n",
    "enb5_wo_top.trainable = False\n",
    "\n",
    "enb5_model = keras.models.Sequential()\n",
    "enb5_model.add(enb5_wo_top)\n",
    "enb5_model.add(keras.layers.Flatten())\n",
    "enb5_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "enb5_model.add(keras.layers.Dense(64, activation='relu'))\n",
    "enb5_model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "enb5_model.compile(optimizer=keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "enb5_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T16:38:53.345419Z",
     "iopub.status.busy": "2023-08-08T16:38:53.345048Z",
     "iopub.status.idle": "2023-08-08T16:59:44.213450Z",
     "shell.execute_reply": "2023-08-08T16:59:44.211622Z",
     "shell.execute_reply.started": "2023-08-08T16:38:53.345383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6_notop.h5\n",
      "165234480/165234480 [==============================] - 1s 0us/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 16:39:21.370535: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_3/efficientnetb6/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 66s 898ms/step - loss: 20.4183 - accuracy: 0.7627 - val_loss: 4.0538 - val_accuracy: 0.8659\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 3.9529 - accuracy: 0.8339 - val_loss: 5.1934 - val_accuracy: 0.5806\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 2.7704 - accuracy: 0.8460 - val_loss: 1.9560 - val_accuracy: 0.8832\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 33s 638ms/step - loss: 1.8828 - accuracy: 0.8581 - val_loss: 5.3015 - val_accuracy: 0.5761\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 1.5618 - accuracy: 0.8702 - val_loss: 1.5069 - val_accuracy: 0.8560\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 1.7237 - accuracy: 0.8798 - val_loss: 1.6337 - val_accuracy: 0.8786\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 1.1548 - accuracy: 0.8998 - val_loss: 1.5990 - val_accuracy: 0.8976\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 1.2232 - accuracy: 0.8937 - val_loss: 1.1802 - val_accuracy: 0.8904\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 33s 639ms/step - loss: 1.2221 - accuracy: 0.9004 - val_loss: 1.3182 - val_accuracy: 0.8958\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 0.6280 - accuracy: 0.9287 - val_loss: 0.8672 - val_accuracy: 0.8986\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 33s 638ms/step - loss: 1.0145 - accuracy: 0.9106 - val_loss: 1.2674 - val_accuracy: 0.8976\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 33s 639ms/step - loss: 0.8810 - accuracy: 0.9136 - val_loss: 0.8386 - val_accuracy: 0.9185\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 0.7672 - accuracy: 0.9203 - val_loss: 0.7996 - val_accuracy: 0.9158\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 33s 639ms/step - loss: 0.6955 - accuracy: 0.9221 - val_loss: 1.8366 - val_accuracy: 0.8714\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 33s 639ms/step - loss: 0.9098 - accuracy: 0.9167 - val_loss: 1.0636 - val_accuracy: 0.9158\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 41s 803ms/step - loss: 0.7765 - accuracy: 0.9191 - val_loss: 0.8637 - val_accuracy: 0.9040\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 0.4665 - accuracy: 0.9342 - val_loss: 0.6938 - val_accuracy: 0.9149\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 41s 803ms/step - loss: 0.6344 - accuracy: 0.9227 - val_loss: 1.7362 - val_accuracy: 0.9167\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 33s 639ms/step - loss: 0.3599 - accuracy: 0.9493 - val_loss: 0.6368 - val_accuracy: 0.9185\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 0.3544 - accuracy: 0.9481 - val_loss: 0.9718 - val_accuracy: 0.9158\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 0.3587 - accuracy: 0.9511 - val_loss: 0.8504 - val_accuracy: 0.9149\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 41s 803ms/step - loss: 1.2400 - accuracy: 0.9167 - val_loss: 2.3856 - val_accuracy: 0.8714\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 41s 801ms/step - loss: 0.8124 - accuracy: 0.9143 - val_loss: 1.4851 - val_accuracy: 0.8460\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 41s 803ms/step - loss: 0.4989 - accuracy: 0.9360 - val_loss: 2.3869 - val_accuracy: 0.8813\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 0.7575 - accuracy: 0.9239 - val_loss: 1.4215 - val_accuracy: 0.9076\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 41s 803ms/step - loss: 0.6724 - accuracy: 0.9275 - val_loss: 1.4842 - val_accuracy: 0.8913\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 41s 803ms/step - loss: 0.3315 - accuracy: 0.9469 - val_loss: 0.7131 - val_accuracy: 0.9031\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 41s 801ms/step - loss: 0.1992 - accuracy: 0.9529 - val_loss: 0.6861 - val_accuracy: 0.9275\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 41s 802ms/step - loss: 0.3118 - accuracy: 0.9463 - val_loss: 0.8560 - val_accuracy: 0.8659\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 33s 639ms/step - loss: 0.2137 - accuracy: 0.9565 - val_loss: 0.5036 - val_accuracy: 0.9330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x79b0df381270>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enb6_wo_top = keras.applications.efficientnet.EfficientNetB6(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n",
    "\n",
    "enb6_wo_top.trainable = False\n",
    "\n",
    "enb6_model = keras.models.Sequential()\n",
    "enb6_model.add(enb6_wo_top)\n",
    "enb6_model.add(keras.layers.Flatten())\n",
    "enb6_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "enb6_model.add(keras.layers.Dense(64, activation='relu'))\n",
    "enb6_model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "enb6_model.compile(optimizer=keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "enb6_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T16:59:44.215591Z",
     "iopub.status.busy": "2023-08-08T16:59:44.215017Z",
     "iopub.status.idle": "2023-08-08T17:24:42.082755Z",
     "shell.execute_reply": "2023-08-08T17:24:42.081673Z",
     "shell.execute_reply.started": "2023-08-08T16:59:44.215552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
      "258076736/258076736 [==============================] - 1s 0us/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 17:00:18.938491: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_4/efficientnetb7/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 76s 1s/step - loss: 10.4503 - accuracy: 0.7766 - val_loss: 6.5107 - val_accuracy: 0.8632\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 3.7033 - accuracy: 0.8484 - val_loss: 1.7107 - val_accuracy: 0.8723\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 44s 853ms/step - loss: 1.8217 - accuracy: 0.8545 - val_loss: 1.4632 - val_accuracy: 0.8587\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 1.4227 - accuracy: 0.8738 - val_loss: 1.0049 - val_accuracy: 0.8859\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.8374 - accuracy: 0.8859 - val_loss: 0.7162 - val_accuracy: 0.9049\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.5495 - accuracy: 0.9064 - val_loss: 0.8654 - val_accuracy: 0.8949\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.5023 - accuracy: 0.9058 - val_loss: 0.7524 - val_accuracy: 0.9022\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.4077 - accuracy: 0.9161 - val_loss: 0.9410 - val_accuracy: 0.8832\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 48s 932ms/step - loss: 0.5059 - accuracy: 0.9185 - val_loss: 1.4617 - val_accuracy: 0.7246\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 44s 854ms/step - loss: 0.4325 - accuracy: 0.9173 - val_loss: 0.8119 - val_accuracy: 0.8877\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.6825 - accuracy: 0.8937 - val_loss: 0.6470 - val_accuracy: 0.9194\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.5215 - accuracy: 0.9124 - val_loss: 0.6693 - val_accuracy: 0.8668\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 44s 853ms/step - loss: 0.2647 - accuracy: 0.9426 - val_loss: 0.5267 - val_accuracy: 0.9085\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 44s 853ms/step - loss: 0.2088 - accuracy: 0.9481 - val_loss: 0.3519 - val_accuracy: 0.9293\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.1818 - accuracy: 0.9559 - val_loss: 0.3727 - val_accuracy: 0.9293\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 44s 851ms/step - loss: 0.2094 - accuracy: 0.9505 - val_loss: 0.4651 - val_accuracy: 0.9004\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 44s 852ms/step - loss: 0.1686 - accuracy: 0.9553 - val_loss: 0.3692 - val_accuracy: 0.9447\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.2183 - accuracy: 0.9463 - val_loss: 0.2417 - val_accuracy: 0.9420\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 44s 851ms/step - loss: 0.2760 - accuracy: 0.9384 - val_loss: 0.4739 - val_accuracy: 0.9004\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 44s 850ms/step - loss: 0.2889 - accuracy: 0.9354 - val_loss: 0.5266 - val_accuracy: 0.9221\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 48s 932ms/step - loss: 0.1261 - accuracy: 0.9614 - val_loss: 0.2756 - val_accuracy: 0.9420\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.0899 - accuracy: 0.9698 - val_loss: 0.2228 - val_accuracy: 0.9520\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.1861 - accuracy: 0.9595 - val_loss: 0.3230 - val_accuracy: 0.9393\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.0788 - accuracy: 0.9783 - val_loss: 0.3621 - val_accuracy: 0.9076\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 48s 930ms/step - loss: 0.1802 - accuracy: 0.9499 - val_loss: 0.6997 - val_accuracy: 0.9094\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.2497 - accuracy: 0.9444 - val_loss: 0.2623 - val_accuracy: 0.9466\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 48s 932ms/step - loss: 0.1368 - accuracy: 0.9638 - val_loss: 0.3445 - val_accuracy: 0.9303\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 48s 932ms/step - loss: 0.2623 - accuracy: 0.9475 - val_loss: 0.3760 - val_accuracy: 0.9366\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 48s 933ms/step - loss: 0.1526 - accuracy: 0.9559 - val_loss: 0.2582 - val_accuracy: 0.9366\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 44s 854ms/step - loss: 0.1258 - accuracy: 0.9662 - val_loss: 0.3750 - val_accuracy: 0.9348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x79b0db3cd810>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enb7_wo_top = keras.applications.efficientnet.EfficientNetB7(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n",
    "\n",
    "enb7_wo_top.trainable = False\n",
    "\n",
    "enb7_model = keras.models.Sequential()\n",
    "enb7_model.add(enb7_wo_top)\n",
    "enb7_model.add(keras.layers.Flatten())\n",
    "enb7_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "enb7_model.add(keras.layers.Dense(64, activation='relu'))\n",
    "enb7_model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "enb7_model.compile(optimizer=keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "enb7_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T17:24:42.166382Z",
     "iopub.status.busy": "2023-08-08T17:24:42.165559Z",
     "iopub.status.idle": "2023-08-08T17:30:11.913714Z",
     "shell.execute_reply": "2023-08-08T17:30:11.912702Z",
     "shell.execute_reply.started": "2023-08-08T17:24:42.166345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 1s 0us/step\n",
      "Epoch 1/30\n",
      "52/52 [==============================] - 19s 266ms/step - loss: 9.5755 - accuracy: 0.8110 - val_loss: 4.1062 - val_accuracy: 0.8940\n",
      "Epoch 2/30\n",
      "52/52 [==============================] - 10s 196ms/step - loss: 3.2696 - accuracy: 0.9004 - val_loss: 2.3007 - val_accuracy: 0.9221\n",
      "Epoch 3/30\n",
      "52/52 [==============================] - 11s 219ms/step - loss: 0.8234 - accuracy: 0.9457 - val_loss: 1.0823 - val_accuracy: 0.9429\n",
      "Epoch 4/30\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.9841 - accuracy: 0.9499 - val_loss: 1.3779 - val_accuracy: 0.9167\n",
      "Epoch 5/30\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 1.6150 - accuracy: 0.9372 - val_loss: 1.8411 - val_accuracy: 0.9239\n",
      "Epoch 6/30\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.3091 - accuracy: 0.9746 - val_loss: 1.3336 - val_accuracy: 0.9447\n",
      "Epoch 7/30\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.1924 - accuracy: 0.9855 - val_loss: 0.6305 - val_accuracy: 0.9629\n",
      "Epoch 8/30\n",
      "52/52 [==============================] - 11s 220ms/step - loss: 0.3304 - accuracy: 0.9813 - val_loss: 1.5922 - val_accuracy: 0.9176\n",
      "Epoch 9/30\n",
      "52/52 [==============================] - 10s 198ms/step - loss: 0.1440 - accuracy: 0.9855 - val_loss: 1.3015 - val_accuracy: 0.9493\n",
      "Epoch 10/30\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.0374 - accuracy: 0.9952 - val_loss: 0.8229 - val_accuracy: 0.9692\n",
      "Epoch 11/30\n",
      "52/52 [==============================] - 11s 220ms/step - loss: 0.0228 - accuracy: 0.9964 - val_loss: 0.9358 - val_accuracy: 0.9638\n",
      "Epoch 12/30\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.1565 - accuracy: 0.9903 - val_loss: 1.0917 - val_accuracy: 0.9592\n",
      "Epoch 13/30\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.1788 - accuracy: 0.9795 - val_loss: 0.8329 - val_accuracy: 0.9620\n",
      "Epoch 14/30\n",
      "52/52 [==============================] - 11s 221ms/step - loss: 0.1477 - accuracy: 0.9861 - val_loss: 1.7373 - val_accuracy: 0.9511\n",
      "Epoch 15/30\n",
      "52/52 [==============================] - 11s 220ms/step - loss: 0.1521 - accuracy: 0.9855 - val_loss: 2.8388 - val_accuracy: 0.9149\n",
      "Epoch 16/30\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.4384 - accuracy: 0.9783 - val_loss: 1.2302 - val_accuracy: 0.9583\n",
      "Epoch 17/30\n",
      "52/52 [==============================] - 10s 199ms/step - loss: 0.2270 - accuracy: 0.9867 - val_loss: 1.0613 - val_accuracy: 0.9529\n",
      "Epoch 18/30\n",
      "52/52 [==============================] - 10s 199ms/step - loss: 0.0851 - accuracy: 0.9946 - val_loss: 1.8737 - val_accuracy: 0.9420\n",
      "Epoch 19/30\n",
      "52/52 [==============================] - 10s 197ms/step - loss: 0.0338 - accuracy: 0.9976 - val_loss: 1.1597 - val_accuracy: 0.9683\n",
      "Epoch 20/30\n",
      "52/52 [==============================] - 10s 198ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 1.4556 - val_accuracy: 0.9529\n",
      "Epoch 21/30\n",
      "52/52 [==============================] - 11s 220ms/step - loss: 0.0495 - accuracy: 0.9952 - val_loss: 0.7854 - val_accuracy: 0.9692\n",
      "Epoch 22/30\n",
      "52/52 [==============================] - 10s 198ms/step - loss: 6.2951e-05 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.9692\n",
      "Epoch 23/30\n",
      "52/52 [==============================] - 10s 198ms/step - loss: 2.7427e-08 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.9692\n",
      "Epoch 24/30\n",
      "52/52 [==============================] - 11s 220ms/step - loss: 2.7355e-08 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.9692\n",
      "Epoch 25/30\n",
      "52/52 [==============================] - 10s 198ms/step - loss: 2.7211e-08 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.9692\n",
      "Epoch 26/30\n",
      "52/52 [==============================] - 10s 198ms/step - loss: 2.7139e-08 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.9692\n",
      "Epoch 27/30\n",
      "52/52 [==============================] - 11s 220ms/step - loss: 2.6995e-08 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.9692\n",
      "Epoch 28/30\n",
      "52/52 [==============================] - 11s 220ms/step - loss: 2.6923e-08 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.9692\n",
      "Epoch 29/30\n",
      "52/52 [==============================] - 11s 220ms/step - loss: 2.6707e-08 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.9692\n",
      "Epoch 30/30\n",
      "52/52 [==============================] - 10s 199ms/step - loss: 2.6563e-08 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.9692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x79b0e0910e80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_wo_top = keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n",
    "\n",
    "resnet_wo_top.trainable = False\n",
    "\n",
    "resnet_model = keras.models.Sequential()\n",
    "resnet_model.add(resnet_wo_top)\n",
    "resnet_model.add(keras.layers.Flatten())\n",
    "resnet_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "resnet_model.add(keras.layers.Dense(64, activation='relu'))\n",
    "resnet_model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "resnet_model.compile(optimizer=keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "resnet_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
