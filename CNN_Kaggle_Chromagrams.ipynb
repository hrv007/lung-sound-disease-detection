{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nimport cv2","metadata":{"id":"EXy5Ggoqczap","execution":{"iopub.status.busy":"2023-08-11T00:01:27.367673Z","iopub.execute_input":"2023-08-11T00:01:27.368253Z","iopub.status.idle":"2023-08-11T00:01:36.205712Z","shell.execute_reply.started":"2023-08-11T00:01:27.368205Z","shell.execute_reply":"2023-08-11T00:01:36.204685Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/chromagrams-lung-sound/patient_diagnosis.csv\")\ndf.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ArtW5CVwuApp","outputId":"fe2935a3-842f-4305-996a-bb1edcb03165","execution":{"iopub.status.busy":"2023-08-11T00:01:36.207965Z","iopub.execute_input":"2023-08-11T00:01:36.208686Z","iopub.status.idle":"2023-08-11T00:01:36.233784Z","shell.execute_reply.started":"2023-08-11T00:01:36.208649Z","shell.execute_reply":"2023-08-11T00:01:36.232850Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   101     URTI\n0  102  Healthy\n1  103   Asthma\n2  104     COPD\n3  105     URTI\n4  106     COPD","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>101</th>\n      <th>URTI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102</td>\n      <td>Healthy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103</td>\n      <td>Asthma</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>104</td>\n      <td>COPD</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>105</td>\n      <td>URTI</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>106</td>\n      <td>COPD</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sr_no = {'101':'URTI'}\nfor i, j in zip(df['101'].unique(), df['URTI']):\n    sr_no[str(i)] = j","metadata":{"id":"eAdDHbX6u_iz","execution":{"iopub.status.busy":"2023-08-11T00:01:36.234966Z","iopub.execute_input":"2023-08-11T00:01:36.235285Z","iopub.status.idle":"2023-08-11T00:01:36.243805Z","shell.execute_reply.started":"2023-08-11T00:01:36.235252Z","shell.execute_reply":"2023-08-11T00:01:36.242811Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"sr_no.keys()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1j95yfuivIOL","outputId":"c4ce184c-bb32-43e4-acbb-ef143254077e","execution":{"iopub.status.busy":"2023-08-11T00:01:36.246708Z","iopub.execute_input":"2023-08-11T00:01:36.247450Z","iopub.status.idle":"2023-08-11T00:01:36.257817Z","shell.execute_reply.started":"2023-08-11T00:01:36.247416Z","shell.execute_reply":"2023-08-11T00:01:36.256834Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"dict_keys(['101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226'])"},"metadata":{}}]},{"cell_type":"code","source":"import os\nsound_files = os.listdir('/kaggle/input/chromagrams-lung-sound/Chromagrams/Chromagrams/Original')","metadata":{"id":"k_apddzYvK_5","execution":{"iopub.status.busy":"2023-08-11T00:01:36.259084Z","iopub.execute_input":"2023-08-11T00:01:36.259967Z","iopub.status.idle":"2023-08-11T00:01:36.370176Z","shell.execute_reply.started":"2023-08-11T00:01:36.259934Z","shell.execute_reply":"2023-08-11T00:01:36.369194Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"req_file_names = []\n\nfor i in sound_files:\n      req_file_names.append([i])\n\nreq_file_names","metadata":{"id":"jNTE66gVvVEg","execution":{"iopub.status.busy":"2023-08-11T00:01:36.372644Z","iopub.execute_input":"2023-08-11T00:01:36.373590Z","iopub.status.idle":"2023-08-11T00:01:36.408014Z","shell.execute_reply.started":"2023-08-11T00:01:36.373551Z","shell.execute_reply":"2023-08-11T00:01:36.406969Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[['176_2b3_Lr_mc_AKGC417L.png'],\n ['112_1p1_Pr_sc_Litt3200.png'],\n ['130_2b2_Pr_mc_AKGC417L.png'],\n ['193_7b3_Ll_mc_AKGC417L.png'],\n ['156_5b3_Pl_mc_AKGC417L.png'],\n ['162_2b2_Tc_mc_AKGC417L.png'],\n ['134_2b3_Ar_mc_LittC2SE.png'],\n ['160_1b4_Tc_mc_AKGC417L.png'],\n ['200_2p4_Pl_mc_AKGC417L.png'],\n ['169_1b2_Ll_sc_Meditron.png'],\n ['144_1b1_Tc_sc_Meditron.png'],\n ['160_2b4_Pl_mc_AKGC417L.png'],\n ['133_2p3_Pr_mc_AKGC417L.png'],\n ['205_1b3_Al_mc_AKGC417L.png'],\n ['130_3p4_Tc_mc_AKGC417L.png'],\n ['130_1p4_Lr_mc_AKGC417L.png'],\n ['200_3p4_Pl_mc_AKGC417L.png'],\n ['107_2b4_Ar_mc_AKGC417L.png'],\n ['203_2p3_Al_mc_AKGC417L.png'],\n ['113_1b1_Ar_sc_Litt3200.png'],\n ['174_2p3_Al_mc_AKGC417L.png'],\n ['178_1b2_Lr_mc_AKGC417L.png'],\n ['172_1b5_Ll_mc_AKGC417L.png'],\n ['216_1b1_Al_sc_Meditron.png'],\n ['205_4b2_Pl_mc_AKGC417L.png'],\n ['177_1b2_Lr_mc_AKGC417L.png'],\n ['151_2p4_Ll_mc_AKGC417L.png'],\n ['141_1b1_Pr_mc_LittC2SE.png'],\n ['162_1b2_Lr_mc_AKGC417L.png'],\n ['133_3p4_Tc_mc_AKGC417L.png'],\n ['147_2b3_Ll_mc_AKGC417L.png'],\n ['143_1b1_Al_sc_Meditron.png'],\n ['218_1p1_Pr_sc_Litt3200.png'],\n ['138_2p2_Al_mc_AKGC417L.png'],\n ['113_1b1_Al_sc_Litt3200.png'],\n ['144_1b1_Al_sc_Meditron.png'],\n ['130_1p4_Pl_mc_AKGC417L.png'],\n ['185_1b1_Ar_sc_Litt3200.png'],\n ['138_1p3_Pl_mc_AKGC417L.png'],\n ['122_2b2_Ar_mc_LittC2SE.png'],\n ['126_1b1_Al_sc_Meditron.png'],\n ['140_2b3_Ll_mc_LittC2SE.png'],\n ['160_1b3_Al_mc_AKGC417L.png'],\n ['186_2b4_Pr_mc_AKGC417L.png'],\n ['176_2b3_Pr_mc_AKGC417L.png'],\n ['160_1b2_Al_mc_AKGC417L.png'],\n ['136_1b1_Ar_sc_Meditron.png'],\n ['172_2b5_Tc_mc_AKGC417L.png'],\n ['176_2b3_Pl_mc_AKGC417L.png'],\n ['178_2b2_Lr_mc_AKGC417L.png'],\n ['162_1b2_Al_mc_AKGC417L.png'],\n ['133_2p2_Tc_mc_AKGC417L.png'],\n ['205_4b2_Al_mc_AKGC417L.png'],\n ['113_1b1_Pl_sc_Litt3200.png'],\n ['178_2b2_Ar_mc_AKGC417L.png'],\n ['156_5b3_Pr_mc_AKGC417L.png'],\n ['198_6p1_Ar_mc_AKGC417L.png'],\n ['213_1p3_Pr_mc_AKGC417L.png'],\n ['170_1b2_Ar_mc_AKGC417L.png'],\n ['204_7p5_Lr_mc_AKGC417L.png'],\n ['107_2b3_Pl_mc_AKGC417L.png'],\n ['176_2b3_Tc_mc_AKGC417L.png'],\n ['197_1b1_Tc_sc_Meditron.png'],\n ['196_1b1_Pr_sc_Meditron.png'],\n ['130_1p2_Pr_mc_AKGC417L.png'],\n ['146_8p3_Ar_mc_AKGC417L.png'],\n ['151_3p2_Ar_mc_AKGC417L.png'],\n ['141_1b2_Tc_mc_LittC2SE.png'],\n ['103_2b2_Ar_mc_LittC2SE.png'],\n ['211_2p4_Tc_mc_AKGC417L.png'],\n ['160_1b4_Pr_mc_AKGC417L.png'],\n ['176_1b4_Lr_mc_AKGC417L.png'],\n ['156_8b3_Ll_mc_AKGC417L.png'],\n ['205_4b2_Pr_mc_AKGC417L.png'],\n ['172_1b3_Tc_mc_AKGC417L.png'],\n ['133_2p3_Pl_mc_AKGC417L.png'],\n ['154_4b4_Pl_mc_AKGC417L.png'],\n ['176_1b4_Tc_mc_AKGC417L.png'],\n ['107_3p2_Tc_mc_AKGC417L.png'],\n ['114_1b4_Al_mc_AKGC417L.png'],\n ['207_2b4_Tc_mc_AKGC417L.png'],\n ['130_2p5_Lr_mc_AKGC417L.png'],\n ['198_6p1_Pl_mc_AKGC417L.png'],\n ['138_1p4_Ar_mc_AKGC417L.png'],\n ['151_2p3_Ar_mc_AKGC417L.png'],\n ['147_2b4_Pl_mc_AKGC417L.png'],\n ['198_1b5_Lr_mc_AKGC417L.png'],\n ['135_2b1_Tc_mc_LittC2SE.png'],\n ['200_2p2_Tc_mc_AKGC417L.png'],\n ['159_1b1_Pr_sc_Meditron.png'],\n ['186_2b4_Ar_mc_AKGC417L.png'],\n ['156_2b3_Ar_mc_AKGC417L.png'],\n ['116_1b2_Tc_sc_Meditron.png'],\n ['156_2b3_Pl_mc_AKGC417L.png'],\n ['213_2p2_Ar_mc_AKGC417L.png'],\n ['213_1p3_Ar_mc_AKGC417L.png'],\n ['120_1b1_Al_sc_Meditron.png'],\n ['160_1b3_Lr_mc_AKGC417L.png'],\n ['207_2b2_Pr_mc_AKGC417L.png'],\n ['177_1b2_Al_mc_AKGC417L.png'],\n ['221_2b2_Al_mc_LittC2SE.png'],\n ['133_2p4_Al_mc_AKGC417L.png'],\n ['154_2b4_Tc_mc_AKGC417L.png'],\n ['205_2b3_Ll_mc_AKGC417L.png'],\n ['178_1b3_Tc_mc_AKGC417L.png'],\n ['158_1p4_Al_mc_AKGC417L.png'],\n ['205_3b4_Ar_mc_AKGC417L.png'],\n ['159_1b1_Ll_sc_Meditron.png'],\n ['138_2p2_Ll_mc_AKGC417L.png'],\n ['205_1b3_Ll_mc_AKGC417L.png'],\n ['176_1b4_Pl_mc_AKGC417L.png'],\n ['162_2b4_Ar_mc_AKGC417L.png'],\n ['151_2p4_Lr_mc_AKGC417L.png'],\n ['207_2b3_Ar_mc_AKGC417L.png'],\n ['135_2b3_Al_mc_LittC2SE.png'],\n ['151_2p3_Ll_mc_AKGC417L.png'],\n ['101_1b1_Pr_sc_Meditron.png'],\n ['104_1b1_Ar_sc_Litt3200.png'],\n ['135_2b3_Pr_mc_LittC2SE.png'],\n ['151_3p2_Tc_mc_AKGC417L.png'],\n ['170_2b2_Lr_mc_AKGC417L.png'],\n ['140_2b2_Tc_mc_LittC2SE.png'],\n ['218_1p1_Pl_sc_Litt3200.png'],\n ['170_1b4_Tc_mc_AKGC417L.png'],\n ['192_2b3_Ar_mc_LittC2SE.png'],\n ['200_2p4_Al_mc_AKGC417L.png'],\n ['204_7p5_Ar_mc_AKGC417L.png'],\n ['178_2b2_Tc_mc_AKGC417L.png'],\n ['135_2b3_Tc_mc_LittC2SE.png'],\n ['221_2b2_Lr_mc_LittC2SE.png'],\n ['130_3b4_Pr_mc_AKGC417L.png'],\n ['162_2b4_Pl_mc_AKGC417L.png'],\n ['138_1p2_Ll_mc_AKGC417L.png'],\n ['109_1b1_Lr_sc_Litt3200.png'],\n ['213_1p2_Tc_mc_AKGC417L.png'],\n ['122_2b2_Tc_mc_LittC2SE.png'],\n ['174_1p4_Tc_mc_AKGC417L.png'],\n ['122_2b1_Tc_mc_LittC2SE.png'],\n ['141_1b2_Ar_mc_LittC2SE.png'],\n ['198_6p1_Lr_mc_AKGC417L.png'],\n ['149_1b1_Al_sc_Meditron.png'],\n ['176_2b3_Al_mc_AKGC417L.png'],\n ['107_2b5_Tc_mc_AKGC417L.png'],\n ['109_1b1_Al_sc_Litt3200.png'],\n ['213_1p5_Pl_mc_AKGC417L.png'],\n ['158_1p4_Tc_mc_AKGC417L.png'],\n ['200_2p3_Pl_mc_AKGC417L.png'],\n ['177_1b2_Pl_mc_AKGC417L.png'],\n ['151_2p3_Al_mc_AKGC417L.png'],\n ['147_2b2_Pl_mc_AKGC417L.png'],\n ['175_1b1_Pr_sc_Litt3200.png'],\n ['157_1b1_Ar_sc_Meditron.png'],\n ['122_2b3_Tc_mc_LittC2SE.png'],\n ['203_1p3_Tc_mc_AKGC417L.png'],\n ['166_1p1_Pl_sc_Meditron.png'],\n ['213_1p2_Al_mc_AKGC417L.png'],\n ['215_1b3_Tc_sc_Meditron.png'],\n ['110_1p1_Ll_sc_Meditron.png'],\n ['200_2p2_Ar_mc_AKGC417L.png'],\n ['202_1b1_Ar_sc_Meditron.png'],\n ['158_1p2_Lr_mc_AKGC417L.png'],\n ['147_1b2_Tc_mc_AKGC417L.png'],\n ['147_2b3_Ar_mc_AKGC417L.png'],\n ['174_2p3_Tc_mc_AKGC417L.png'],\n ['200_3p4_Al_mc_AKGC417L.png'],\n ['213_2p2_Pl_mc_AKGC417L.png'],\n ['177_1b2_Pr_mc_AKGC417L.png'],\n ['204_7p5_Ll_mc_AKGC417L.png'],\n ['162_2b3_Pr_mc_AKGC417L.png'],\n ['117_1b2_Tc_mc_LittC2SE.png'],\n ['140_2b2_Ll_mc_LittC2SE.png'],\n ['222_1b1_Lr_sc_Meditron.png'],\n ['130_2b2_Ll_mc_AKGC417L.png'],\n ['130_2p5_Pl_mc_AKGC417L.png'],\n ['172_2b5_Al_mc_AKGC417L.png'],\n ['147_2b4_Lr_mc_AKGC417L.png'],\n ['138_1p3_Ll_mc_AKGC417L.png'],\n ['138_1p4_Ll_mc_AKGC417L.png'],\n ['160_2b4_Ar_mc_AKGC417L.png'],\n ['147_2b2_Ar_mc_AKGC417L.png'],\n ['141_1b3_Ar_mc_LittC2SE.png'],\n ['124_1b1_Ll_sc_Litt3200.png'],\n ['178_1b3_Pl_mc_AKGC417L.png'],\n ['107_3p2_Ll_mc_AKGC417L.png'],\n ['130_2p5_Tc_mc_AKGC417L.png'],\n ['106_2b1_Pl_mc_LittC2SE.png'],\n ['198_1b5_Ar_mc_AKGC417L.png'],\n ['193_7b3_Pr_mc_AKGC417L.png'],\n ['198_1b5_Pr_mc_AKGC417L.png'],\n ['203_1p4_Al_mc_AKGC417L.png'],\n ['201_1b3_Ar_sc_Meditron.png'],\n ['146_2b4_Ll_mc_AKGC417L.png'],\n ['208_1b1_Ll_sc_Meditron.png'],\n ['138_2p2_Tc_mc_AKGC417L.png'],\n ['158_1p3_Ll_mc_AKGC417L.png'],\n ['178_1b6_Ll_mc_AKGC417L.png'],\n ['130_2p5_Pr_mc_AKGC417L.png'],\n ['133_2p4_Pr_mc_AKGC417L.png'],\n ['195_1b1_Pr_sc_Litt3200.png'],\n ['170_2b2_Pl_mc_AKGC417L.png'],\n ['107_2b5_Lr_mc_AKGC417L.png'],\n ['170_1b3_Lr_mc_AKGC417L.png'],\n ['174_1p3_Pl_mc_AKGC417L.png'],\n ['200_3p4_Ar_mc_AKGC417L.png'],\n ['178_1b6_Pr_mc_AKGC417L.png'],\n ['205_1b3_Ar_mc_AKGC417L.png'],\n ['198_6p1_Tc_mc_AKGC417L.png'],\n ['107_3p2_Pr_mc_AKGC417L.png'],\n ['174_1p2_Pr_mc_AKGC417L.png'],\n ['205_2b3_Ar_mc_AKGC417L.png'],\n ['188_1b1_Ar_sc_Meditron.png'],\n ['151_2p4_Pr_mc_AKGC417L.png'],\n ['176_1b3_Tc_mc_AKGC417L.png'],\n ['138_1p2_Pr_mc_AKGC417L.png'],\n ['174_1p4_Ar_mc_AKGC417L.png'],\n ['158_1p4_Pl_mc_AKGC417L.png'],\n ['158_1p3_Pl_mc_AKGC417L.png'],\n ['205_2b2_Pr_mc_AKGC417L.png'],\n ['198_6p1_Al_mc_AKGC417L.png'],\n ['170_1b2_Pl_mc_AKGC417L.png'],\n ['203_2p3_Tc_mc_AKGC417L.png'],\n ['130_3p2_Ar_mc_AKGC417L.png'],\n ['178_1b3_Al_mc_AKGC417L.png'],\n ['188_1b1_Tc_sc_Meditron.png'],\n ['147_2b2_Al_mc_AKGC417L.png'],\n ['218_1b1_Ar_sc_Meditron.png'],\n ['130_2b2_Pl_mc_AKGC417L.png'],\n ['205_1b3_Pr_mc_AKGC417L.png'],\n ['130_2p3_Pl_mc_AKGC417L.png'],\n ['172_1b3_Pr_mc_AKGC417L.png'],\n ['200_2p2_Pr_mc_AKGC417L.png'],\n ['205_1b3_Lr_mc_AKGC417L.png'],\n ['156_8b3_Lr_mc_AKGC417L.png'],\n ['200_2p2_Al_mc_AKGC417L.png'],\n ['133_3p2_Pr_mc_AKGC417L.png'],\n ['176_1b3_Lr_mc_AKGC417L.png'],\n ['135_2b2_Tc_mc_LittC2SE.png'],\n ['207_2b2_Tc_mc_AKGC417L.png'],\n ['180_1b4_Al_mc_AKGC417L.png'],\n ['120_1b1_Lr_sc_Meditron.png'],\n ['158_1p3_Pr_mc_AKGC417L.png'],\n ['154_2b4_Ar_mc_AKGC417L.png'],\n ['130_3b4_Pl_mc_AKGC417L.png'],\n ['107_2b3_Lr_mc_AKGC417L.png'],\n ['107_2b5_Ll_mc_AKGC417L.png'],\n ['211_1p2_Pr_mc_AKGC417L.png'],\n ['225_1b1_Pl_sc_Meditron.png'],\n ['207_2b4_Al_mc_AKGC417L.png'],\n ['154_3b3_Ar_mc_AKGC417L.png'],\n ['113_1b1_Pr_sc_Litt3200.png'],\n ['135_2b2_Al_mc_LittC2SE.png'],\n ['213_1p2_Pr_mc_AKGC417L.png'],\n ['207_2b3_Pr_mc_AKGC417L.png'],\n ['172_2b5_Lr_mc_AKGC417L.png'],\n ['191_2b2_Tc_mc_LittC2SE.png'],\n ['130_1p3_Ar_mc_AKGC417L.png'],\n ['162_1b2_Ll_mc_AKGC417L.png'],\n ['201_1b3_Al_sc_Meditron.png'],\n ['201_1b1_Ar_sc_Meditron.png'],\n ['213_2p2_Pr_mc_AKGC417L.png'],\n ['206_1b1_Ar_sc_Meditron.png'],\n ['178_1b3_Lr_mc_AKGC417L.png'],\n ['221_2b3_Lr_mc_LittC2SE.png'],\n ['200_2p3_Lr_mc_AKGC417L.png'],\n ['129_1b1_Ar_sc_Meditron.png'],\n ['192_2b3_Al_mc_LittC2SE.png'],\n ['221_2b3_Pr_mc_LittC2SE.png'],\n ['160_1b3_Pr_mc_AKGC417L.png'],\n ['130_2b3_Pl_mc_AKGC417L.png'],\n ['170_1b3_Al_mc_AKGC417L.png'],\n ['181_1b3_Tc_mc_LittC2SE.png'],\n ['141_1b3_Al_mc_LittC2SE.png'],\n ['186_3b3_Ar_mc_AKGC417L.png'],\n ['133_3p2_Ar_mc_AKGC417L.png'],\n ['162_1b2_Ar_mc_AKGC417L.png'],\n ['198_6p1_Ll_mc_AKGC417L.png'],\n ['130_3p2_Al_mc_AKGC417L.png'],\n ['203_2p3_Pl_mc_AKGC417L.png'],\n ['118_1b1_Al_sc_Litt3200.png'],\n ['162_2b2_Pl_mc_AKGC417L.png'],\n ['130_1p2_Tc_mc_AKGC417L.png'],\n ['104_1b1_Al_sc_Litt3200.png'],\n ['151_3p2_Lr_mc_AKGC417L.png'],\n ['205_3b4_Pr_mc_AKGC417L.png'],\n ['213_1p2_Pl_mc_AKGC417L.png'],\n ['158_1p4_Lr_mc_AKGC417L.png'],\n ['124_1b1_Lr_sc_Litt3200.png'],\n ['193_7b3_Lr_mc_AKGC417L.png'],\n ['192_2b1_Al_mc_LittC2SE.png'],\n ['220_1b1_Tc_mc_LittC2SE.png'],\n ['164_1b1_Ll_sc_Meditron.png'],\n ['154_4b4_Al_mc_AKGC417L.png'],\n ['198_1b5_Ll_mc_AKGC417L.png'],\n ['147_1b4_Tc_mc_AKGC417L.png'],\n ['130_3p3_Al_mc_AKGC417L.png'],\n ['170_1b2_Lr_mc_AKGC417L.png'],\n ['200_2p3_Tc_mc_AKGC417L.png'],\n ['181_1b2_Ar_mc_LittC2SE.png'],\n ['124_1b1_Ar_sc_Litt3200.png'],\n ['130_3p3_Pr_mc_AKGC417L.png'],\n ['166_1p1_Ar_sc_Meditron.png'],\n ['224_1b1_Tc_sc_Meditron.png'],\n ['130_3p4_Pl_mc_AKGC417L.png'],\n ['203_2p3_Ar_mc_AKGC417L.png'],\n ['215_1b2_Ar_sc_Meditron.png'],\n ['211_1p2_Pl_mc_AKGC417L.png'],\n ['172_2b5_Ar_mc_AKGC417L.png'],\n ['147_1b3_Tc_mc_AKGC417L.png'],\n ['176_1b3_Ar_mc_AKGC417L.png'],\n ['154_3b3_Ll_mc_AKGC417L.png'],\n ['122_2b1_Ar_mc_LittC2SE.png'],\n ['192_2b2_Al_mc_LittC2SE.png'],\n ['172_1b3_Lr_mc_AKGC417L.png'],\n ['130_2b3_Al_mc_AKGC417L.png'],\n ['207_2b2_Al_mc_AKGC417L.png'],\n ['112_1p1_Ll_sc_Litt3200.png'],\n ['117_1b3_Tc_mc_LittC2SE.png'],\n ['203_1p4_Tc_mc_AKGC417L.png'],\n ['135_2b2_Pl_mc_LittC2SE.png'],\n ['156_8b3_Pl_mc_AKGC417L.png'],\n ['133_3p2_Al_mc_AKGC417L.png'],\n ['130_2p5_Al_mc_AKGC417L.png'],\n ['162_2b2_Al_mc_AKGC417L.png'],\n ['141_1b3_Pr_mc_LittC2SE.png'],\n ['195_1b1_Ll_sc_Litt3200.png'],\n ['199_2b3_Ll_mc_LittC2SE.png'],\n ['108_1b1_Al_sc_Meditron.png'],\n ['138_1p3_Lr_mc_AKGC417L.png'],\n ['122_2b1_Al_mc_LittC2SE.png'],\n ['130_1p3_Tc_mc_AKGC417L.png'],\n ['163_2b2_Pl_mc_AKGC417L.png'],\n ['158_1p2_Ll_mc_AKGC417L.png'],\n ['163_2b2_Ar_mc_AKGC417L.png'],\n ['133_2p4_Pl_mc_AKGC417L.png'],\n ['174_1p3_Ll_mc_AKGC417L.png'],\n ['162_1b2_Pl_mc_AKGC417L.png'],\n ['162_1b2_Tc_mc_AKGC417L.png'],\n ['172_1b4_Ll_mc_AKGC417L.png'],\n ['191_2b1_Pr_mc_LittC2SE.png'],\n ['204_7p5_Pr_mc_AKGC417L.png'],\n ['193_1b2_Al_mc_AKGC417L.png'],\n ['135_2b1_Al_mc_LittC2SE.png'],\n ['107_2b4_Lr_mc_AKGC417L.png'],\n ['154_1b3_Lr_mc_AKGC417L.png'],\n ['107_3p2_Pl_mc_AKGC417L.png'],\n ['219_2b2_Tc_mc_LittC2SE.png'],\n ['170_1b4_Lr_mc_AKGC417L.png'],\n ['158_1p4_Ar_mc_AKGC417L.png'],\n ['135_2b2_Ar_mc_LittC2SE.png'],\n ['207_2b3_Tc_mc_AKGC417L.png'],\n ['163_2b2_Ll_mc_AKGC417L.png'],\n ['130_2b3_Tc_mc_AKGC417L.png'],\n ['123_1b1_Al_sc_Meditron.png'],\n ['145_2b2_Pr_mc_AKGC417L.png'],\n ['145_3b4_Pl_mc_AKGC417L.png'],\n ['160_1b3_Pl_mc_AKGC417L.png'],\n ['150_1b2_Al_sc_Meditron.png'],\n ['151_2p3_Tc_mc_AKGC417L.png'],\n ['187_1b1_Ll_sc_Meditron.png'],\n ['204_2b5_Ll_mc_AKGC417L.png'],\n ['138_1p3_Tc_mc_AKGC417L.png'],\n ['133_2p4_Tc_mc_AKGC417L.png'],\n ['160_2b4_Tc_mc_AKGC417L.png'],\n ['156_2b3_Pr_mc_AKGC417L.png'],\n ['160_1b4_Al_mc_AKGC417L.png'],\n ['176_1b4_Pr_mc_AKGC417L.png'],\n ['207_3b2_Ar_mc_AKGC417L.png'],\n ['176_1b3_Pr_mc_AKGC417L.png'],\n ['176_2b3_Ar_mc_AKGC417L.png'],\n ['186_3b3_Pl_mc_AKGC417L.png'],\n ['148_1b1_Al_sc_Meditron.png'],\n ['167_1b1_Al_sc_Meditron.png'],\n ['176_1b4_Al_mc_AKGC417L.png'],\n ['141_1b2_Pr_mc_LittC2SE.png'],\n ['170_2b2_Pr_mc_AKGC417L.png'],\n ['139_1b1_Al_sc_Litt3200.png'],\n ['178_1b2_Ar_mc_AKGC417L.png'],\n ['151_2p2_Ll_mc_AKGC417L.png'],\n ['200_2p3_Pr_mc_AKGC417L.png'],\n ['221_2b2_Pl_mc_LittC2SE.png'],\n ['154_4b4_Ar_mc_AKGC417L.png'],\n ['138_1p2_Lr_mc_AKGC417L.png'],\n ['133_2p4_Ar_mc_AKGC417L.png'],\n ['172_1b4_Pl_mc_AKGC417L.png'],\n ['217_1b1_Tc_sc_Meditron.png'],\n ['222_1b1_Ar_sc_Meditron.png'],\n ['162_2b4_Al_mc_AKGC417L.png'],\n ['199_2b1_Ll_mc_LittC2SE.png'],\n ['130_1p4_Al_mc_AKGC417L.png'],\n ['193_1b2_Pr_mc_AKGC417L.png'],\n ['166_1p1_Ll_sc_Meditron.png'],\n ['174_1p2_Ar_mc_AKGC417L.png'],\n ['153_1b1_Al_sc_Meditron.png'],\n ['101_1b1_Al_sc_Meditron.png'],\n ['130_3b4_Ar_mc_AKGC417L.png'],\n ['146_2b4_Al_mc_AKGC417L.png'],\n ['130_2b3_Lr_mc_AKGC417L.png'],\n ['120_1b1_Ar_sc_Meditron.png'],\n ['177_1b2_Tc_mc_AKGC417L.png'],\n ['178_1b6_Tc_mc_AKGC417L.png'],\n ['207_3b2_Tc_mc_AKGC417L.png'],\n ['197_1b1_Al_sc_Meditron.png'],\n ['207_2b4_Pl_mc_AKGC417L.png'],\n ['200_2p4_Pr_mc_AKGC417L.png'],\n ['174_1p2_Lr_mc_AKGC417L.png'],\n ['130_2b4_Al_mc_AKGC417L.png'],\n ['107_2b3_Ar_mc_AKGC417L.png'],\n ['122_2b3_Al_mc_LittC2SE.png'],\n ['213_1p5_Ar_mc_AKGC417L.png'],\n ['138_1p4_Tc_mc_AKGC417L.png'],\n ['203_1p4_Pl_mc_AKGC417L.png'],\n ['177_1b4_Ar_mc_AKGC417L.png'],\n ['163_2b2_Lr_mc_AKGC417L.png'],\n ['130_1p4_Ll_mc_AKGC417L.png'],\n ['146_8p3_Lr_mc_AKGC417L.png'],\n ['122_2b2_Al_mc_LittC2SE.png'],\n ['151_2p4_Tc_mc_AKGC417L.png'],\n ['146_2b4_Pr_mc_AKGC417L.png'],\n ['107_3p2_Ar_mc_AKGC417L.png'],\n ['206_1b1_Lr_sc_Meditron.png'],\n ['176_1b3_Ll_mc_AKGC417L.png'],\n ['158_1p2_Al_mc_AKGC417L.png'],\n ['213_1p5_Tc_mc_AKGC417L.png'],\n ['157_1b1_Lr_sc_Meditron.png'],\n ['170_1b2_Tc_mc_AKGC417L.png'],\n ['198_1b5_Tc_mc_AKGC417L.png'],\n ['172_1b4_Pr_mc_AKGC417L.png'],\n ['130_3p2_Pl_mc_AKGC417L.png'],\n ['161_1b1_Al_sc_Meditron.png'],\n ['172_1b4_Lr_mc_AKGC417L.png'],\n ['213_1p2_Ar_mc_AKGC417L.png'],\n ['151_3p2_Pl_mc_AKGC417L.png'],\n ['204_7p5_Tc_mc_AKGC417L.png'],\n ['165_1b1_Pl_sc_Meditron.png'],\n ['170_1b4_Al_mc_AKGC417L.png'],\n ['211_1p2_Ar_mc_AKGC417L.png'],\n ['178_1b2_Tc_mc_AKGC417L.png'],\n ['139_1b1_Ll_sc_Litt3200.png'],\n ['151_2p2_Pl_mc_AKGC417L.png'],\n ['177_1b2_Ar_mc_AKGC417L.png'],\n ['130_2b2_Ar_mc_AKGC417L.png'],\n ['160_2b4_Pr_mc_AKGC417L.png'],\n ['174_1p3_Pr_mc_AKGC417L.png'],\n ['160_1b2_Ar_mc_AKGC417L.png'],\n ['201_1b2_Ar_sc_Meditron.png'],\n ['172_1b5_Al_mc_AKGC417L.png'],\n ['114_1b4_Pr_mc_AKGC417L.png'],\n ['161_1b1_Pl_sc_Meditron.png'],\n ['107_2b5_Pl_mc_AKGC417L.png'],\n ['200_2p4_Lr_mc_AKGC417L.png'],\n ['205_3b4_Pl_mc_AKGC417L.png'],\n ['195_1b1_Ar_sc_Litt3200.png'],\n ['130_1p2_Ll_mc_AKGC417L.png'],\n ['104_1b1_Pl_sc_Litt3200.png'],\n ['114_1b4_Lr_mc_AKGC417L.png'],\n ['203_1p2_Al_mc_AKGC417L.png'],\n ['211_2p2_Tc_mc_AKGC417L.png'],\n ['223_1b1_Pl_sc_Meditron.png'],\n ['218_1b1_Pr_sc_Meditron.png'],\n ['158_1p2_Pr_mc_AKGC417L.png'],\n ['158_1b3_Ar_mc_LittC2SE.png'],\n ['172_1b5_Lr_mc_AKGC417L.png'],\n ['151_2p2_Lr_mc_AKGC417L.png'],\n ['163_2b2_Tc_mc_AKGC417L.png'],\n ['114_1b4_Ar_mc_AKGC417L.png'],\n ['176_1b3_Pl_mc_AKGC417L.png'],\n ['130_1p4_Tc_mc_AKGC417L.png'],\n ['193_7b3_Ar_mc_AKGC417L.png'],\n ['194_1b1_Pr_sc_Meditron.png'],\n ['186_2b2_Tc_mc_AKGC417L.png'],\n ['172_1b5_Tc_mc_AKGC417L.png'],\n ['211_2p3_Tc_mc_AKGC417L.png'],\n ['167_1b1_Pr_sc_Meditron.png'],\n ['174_2p3_Ar_mc_AKGC417L.png'],\n ['156_5b3_Al_mc_AKGC417L.png'],\n ['130_1p3_Ll_mc_AKGC417L.png'],\n ['205_2b4_Pl_mc_AKGC417L.png'],\n ['146_8p3_Pr_mc_AKGC417L.png'],\n ['124_1b1_Al_sc_Litt3200.png'],\n ['162_2b3_Lr_mc_AKGC417L.png'],\n ['119_1b1_Ar_sc_Meditron.png'],\n ['121_1p1_Tc_sc_Meditron.png'],\n ['178_1b6_Lr_mc_AKGC417L.png'],\n ['174_1p4_Ll_mc_AKGC417L.png'],\n ['138_1p3_Pr_mc_AKGC417L.png'],\n ['170_1b3_Ll_mc_AKGC417L.png'],\n ['179_1b1_Al_sc_Meditron.png'],\n ['139_1b1_Pl_sc_Litt3200.png'],\n ['130_2p5_Ar_mc_AKGC417L.png'],\n ['186_2b3_Lr_mc_AKGC417L.png'],\n ['154_1b3_Tc_mc_AKGC417L.png'],\n ['130_1p3_Lr_mc_AKGC417L.png'],\n ['180_1b4_Pl_mc_AKGC417L.png'],\n ['222_1b1_Pr_sc_Meditron.png'],\n ['212_2b2_Tc_mc_LittC2SE.png'],\n ['133_2p3_Al_mc_AKGC417L.png'],\n ['130_3b4_Lr_mc_AKGC417L.png'],\n ['195_1b1_Al_sc_Litt3200.png'],\n ['111_1b2_Tc_sc_Meditron.png'],\n ['200_2p4_Ar_mc_AKGC417L.png'],\n ['204_2b5_Ar_mc_AKGC417L.png'],\n ['186_2b2_Pl_mc_AKGC417L.png'],\n ['220_1b2_Al_mc_LittC2SE.png'],\n ['151_3p2_Pr_mc_AKGC417L.png'],\n ['162_2b3_Tc_mc_AKGC417L.png'],\n ['118_1b1_Lr_sc_Litt3200.png'],\n ['219_2b1_Ar_mc_LittC2SE.png'],\n ['200_2p3_Ar_mc_AKGC417L.png'],\n ['221_2b1_Al_mc_LittC2SE.png'],\n ['177_1b4_Pl_mc_AKGC417L.png'],\n ['207_2b4_Pr_mc_AKGC417L.png'],\n ['213_1p5_Pr_mc_AKGC417L.png'],\n ['137_1b1_Ar_sc_Meditron.png'],\n ['193_1b2_Ar_mc_AKGC417L.png'],\n ['130_1p3_Pl_mc_AKGC417L.png'],\n ['207_3b2_Pr_mc_AKGC417L.png'],\n ['107_2b4_Pr_mc_AKGC417L.png'],\n ['203_1p3_Ar_mc_AKGC417L.png'],\n ['178_1b2_Pl_mc_AKGC417L.png'],\n ['107_3p2_Lr_mc_AKGC417L.png'],\n ['154_1b3_Al_mc_AKGC417L.png'],\n ['162_2b3_Pl_mc_AKGC417L.png'],\n ['207_2b3_Al_mc_AKGC417L.png'],\n ['174_2p3_Pr_mc_AKGC417L.png'],\n ['172_1b3_Al_mc_AKGC417L.png'],\n ['166_1p1_Pr_sc_Meditron.png'],\n ['186_3b3_Al_mc_AKGC417L.png'],\n ['154_1b3_Pl_mc_AKGC417L.png'],\n ['107_3p2_Al_mc_AKGC417L.png'],\n ['191_2b1_Pl_mc_LittC2SE.png'],\n ['180_1b4_Ar_mc_AKGC417L.png'],\n ['213_1p5_Al_mc_AKGC417L.png'],\n ['176_2b3_Ll_mc_AKGC417L.png'],\n ['130_2b2_Al_mc_AKGC417L.png'],\n ['138_1p4_Lr_mc_AKGC417L.png'],\n ['107_2b5_Al_mc_AKGC417L.png'],\n ['151_2p2_Ar_mc_AKGC417L.png'],\n ['163_8b3_Al_mc_AKGC417L.png'],\n ['163_8b3_Pl_mc_AKGC417L.png'],\n ['145_2b2_Al_mc_AKGC417L.png'],\n ['121_1b1_Tc_sc_Meditron.png'],\n ['118_1b1_Ar_sc_Litt3200.png'],\n ['130_1p3_Al_mc_AKGC417L.png'],\n ['112_1p1_Pl_sc_Litt3200.png'],\n ['138_1p2_Pl_mc_AKGC417L.png'],\n ['152_1b1_Al_sc_Meditron.png'],\n ['201_1b1_Al_sc_Meditron.png'],\n ['219_2b1_Tc_mc_LittC2SE.png'],\n ['147_2b3_Al_mc_AKGC417L.png'],\n ['130_2b3_Pr_mc_AKGC417L.png'],\n ['146_8p3_Pl_mc_AKGC417L.png'],\n ['221_2b1_Lr_mc_LittC2SE.png'],\n ['170_2b2_Tc_mc_AKGC417L.png'],\n ['162_2b3_Al_mc_AKGC417L.png'],\n ['156_5b3_Ar_mc_AKGC417L.png'],\n ['154_1b3_Ll_mc_AKGC417L.png'],\n ['158_1p2_Ar_mc_AKGC417L.png'],\n ['205_4b2_Lr_mc_AKGC417L.png'],\n ['201_1b2_Al_sc_Meditron.png'],\n ['203_1p2_Lr_mc_AKGC417L.png'],\n ['162_2b2_Pr_mc_AKGC417L.png'],\n ['174_1p2_Pl_mc_AKGC417L.png'],\n ['158_1p4_Pr_mc_AKGC417L.png'],\n ['171_1b1_Al_sc_Meditron.png'],\n ['186_2b4_Tc_mc_AKGC417L.png'],\n ['118_1b1_Ll_sc_Litt3200.png'],\n ['159_1b1_Al_sc_Meditron.png'],\n ['188_1b1_Pl_sc_Meditron.png'],\n ['163_8b3_Pr_mc_AKGC417L.png'],\n ['151_2p3_Lr_mc_AKGC417L.png'],\n ['133_2p3_Ar_mc_AKGC417L.png'],\n ['226_1b1_Pl_sc_LittC2SE.png'],\n ['133_2p2_Ar_mc_AKGC417L.png'],\n ['188_1b1_Al_sc_Meditron.png'],\n ['213_1p3_Al_mc_AKGC417L.png'],\n ['110_1b1_Pr_sc_Meditron.png'],\n ['175_1b1_Pl_sc_Litt3200.png'],\n ['213_1p2_Lr_mc_AKGC417L.png'],\n ['145_3b2_Lr_mc_AKGC417L.png'],\n ['193_1b2_Pl_mc_AKGC417L.png'],\n ['213_1p3_Pl_mc_AKGC417L.png'],\n ['109_1b1_Pl_sc_Litt3200.png'],\n ['186_2b4_Lr_mc_AKGC417L.png'],\n ['186_3b3_Lr_mc_AKGC417L.png'],\n ['130_3b3_Ll_mc_AKGC417L.png'],\n ['207_2b4_Ar_mc_AKGC417L.png'],\n ['154_2b4_Pl_mc_AKGC417L.png'],\n ['190_1b1_Tc_sc_Meditron.png'],\n ['168_1b1_Al_sc_Meditron.png'],\n ['158_1p2_Pl_mc_AKGC417L.png'],\n ['138_1p2_Ar_mc_AKGC417L.png'],\n ['145_2b2_Ar_mc_AKGC417L.png'],\n ['203_1p3_Pl_mc_AKGC417L.png'],\n ['107_2b4_Tc_mc_AKGC417L.png'],\n ['130_2b3_Ar_mc_AKGC417L.png'],\n ['193_7b3_Tc_mc_AKGC417L.png'],\n ['207_3b2_Al_mc_AKGC417L.png'],\n ['151_2p4_Ar_mc_AKGC417L.png'],\n ['109_1b1_Pr_sc_Litt3200.png'],\n ['130_2b3_Ll_mc_AKGC417L.png'],\n ['154_4b4_Pr_mc_AKGC417L.png'],\n ['139_1b1_Lr_sc_Litt3200.png'],\n ['160_2b3_Lr_mc_AKGC417L.png'],\n ['151_3p3_Ll_mc_AKGC417L.png'],\n ['145_3b2_Ar_mc_AKGC417L.png'],\n ['170_1b4_Pr_mc_AKGC417L.png'],\n ['104_1b1_Pr_sc_Litt3200.png'],\n ['203_1p2_Tc_mc_AKGC417L.png'],\n ['162_2b4_Pr_mc_AKGC417L.png'],\n ['134_2b2_Ar_mc_LittC2SE.png'],\n ['172_1b4_Ar_mc_AKGC417L.png'],\n ['186_2b3_Pr_mc_AKGC417L.png'],\n ['106_2b1_Pr_mc_LittC2SE.png'],\n ['206_1b1_Pl_sc_Meditron.png'],\n ['154_2b4_Pr_mc_AKGC417L.png'],\n ['193_1b2_Ll_mc_AKGC417L.png'],\n ['102_1b1_Ar_sc_Meditron.png'],\n ['113_1b1_Ll_sc_Litt3200.png'],\n ['156_8b3_Al_mc_AKGC417L.png'],\n ['125_1b1_Tc_sc_Meditron.png'],\n ['200_2p4_Tc_mc_AKGC417L.png'],\n ['109_1b1_Ar_sc_Litt3200.png'],\n ['138_1p3_Al_mc_AKGC417L.png'],\n ['178_1b6_Ar_mc_AKGC417L.png'],\n ['147_2b4_Al_mc_AKGC417L.png'],\n ['156_2b3_Al_mc_AKGC417L.png'],\n ['163_8b3_Ll_mc_AKGC417L.png'],\n ['158_2p2_Ar_mc_AKGC417L.png'],\n ['151_2p4_Al_mc_AKGC417L.png'],\n ['210_1b1_Al_sc_Meditron.png'],\n ['107_2b3_Tc_mc_AKGC417L.png'],\n ['186_2b4_Al_mc_AKGC417L.png'],\n ['177_2b4_Al_mc_AKGC417L.png'],\n ['142_1b1_Pl_mc_LittC2SE.png'],\n ['111_1b3_Tc_sc_Meditron.png'],\n ['154_3b3_Al_mc_AKGC417L.png'],\n ['133_2p2_Al_mc_AKGC417L.png'],\n ['192_2b1_Ar_mc_LittC2SE.png'],\n ['177_1b4_Pr_mc_AKGC417L.png'],\n ['154_1b3_Pr_mc_AKGC417L.png'],\n ['170_2b2_Ar_mc_AKGC417L.png'],\n ['157_1b1_Pr_sc_Meditron.png'],\n ['216_1b1_Pl_sc_Meditron.png'],\n ['193_7b3_Pl_mc_AKGC417L.png'],\n ['172_1b5_Pl_mc_AKGC417L.png'],\n ['174_2p3_Pl_mc_AKGC417L.png'],\n ['183_1b1_Tc_sc_Meditron.png'],\n ['179_1b1_Tc_sc_Meditron.png'],\n ['170_2b2_Al_mc_AKGC417L.png'],\n ['130_2b4_Ar_mc_AKGC417L.png'],\n ['203_1p2_Ar_mc_AKGC417L.png'],\n ['128_1b3_Tc_mc_LittC2SE.png'],\n ['145_2b2_Lr_mc_AKGC417L.png'],\n ['165_1b1_Pr_sc_Meditron.png'],\n ['118_1b1_Pl_sc_Litt3200.png'],\n ['170_1b3_Tc_mc_AKGC417L.png'],\n ['130_1p2_Al_mc_AKGC417L.png'],\n ['147_2b3_Pl_mc_AKGC417L.png'],\n ['205_1b3_Pl_mc_AKGC417L.png'],\n ['219_2b2_Ar_mc_LittC2SE.png'],\n ['154_4b4_Ll_mc_AKGC417L.png'],\n ['154_2b4_Ll_mc_AKGC417L.png'],\n ['172_1b5_Ar_mc_AKGC417L.png'],\n ['185_1b1_Ll_sc_Litt3200.png'],\n ['176_1b4_Ll_mc_AKGC417L.png'],\n ['182_1b1_Tc_sc_Meditron.png'],\n ['156_2b3_Ll_mc_AKGC417L.png'],\n ['122_2b3_Ar_mc_LittC2SE.png'],\n ['175_1b1_Ll_sc_Litt3200.png'],\n ['170_1b4_Pl_mc_AKGC417L.png'],\n ['160_1b2_Pr_mc_AKGC417L.png'],\n ['176_1b3_Al_mc_AKGC417L.png'],\n ['147_2b4_Ll_mc_AKGC417L.png'],\n ['149_1b1_Pl_sc_Meditron.png'],\n ['178_1b2_Pr_mc_AKGC417L.png'],\n ['170_1b3_Pl_mc_AKGC417L.png'],\n ['174_1p3_Tc_mc_AKGC417L.png'],\n ['158_1p3_Al_mc_AKGC417L.png'],\n ['186_2b3_Pl_mc_AKGC417L.png'],\n ['130_3p4_Al_mc_AKGC417L.png'],\n ['130_3p2_Pr_mc_AKGC417L.png'],\n ['133_2p3_Tc_mc_AKGC417L.png'],\n ['133_3p2_Pl_mc_AKGC417L.png'],\n ['207_2b2_Ar_mc_AKGC417L.png'],\n ['151_2p3_Pr_mc_AKGC417L.png'],\n ['154_2b4_Al_mc_AKGC417L.png'],\n ['116_1b2_Pl_sc_Meditron.png'],\n ['210_1b1_Ar_sc_Meditron.png'],\n ['137_1b1_Ll_sc_Meditron.png'],\n ['177_2b4_Lr_mc_AKGC417L.png'],\n ['151_3p2_Al_mc_AKGC417L.png'],\n ['131_1b1_Al_sc_Meditron.png'],\n ['151_2p2_Al_mc_AKGC417L.png'],\n ['226_1b1_Ll_sc_Meditron.png'],\n ['178_1b3_Ar_mc_AKGC417L.png'],\n ['219_2b3_Tc_mc_LittC2SE.png'],\n ['186_2b2_Ar_mc_AKGC417L.png'],\n ['157_1b1_Al_sc_Meditron.png'],\n ['203_2p3_Pr_mc_AKGC417L.png'],\n ['213_2p2_Tc_mc_AKGC417L.png'],\n ['218_1b1_Pl_sc_Meditron.png'],\n ['151_2p3_Pl_mc_AKGC417L.png'],\n ['172_1b3_Ll_mc_AKGC417L.png'],\n ['132_2b2_Lr_mc_LittC2SE.png'],\n ['218_1b1_Al_sc_Meditron.png'],\n ['180_1b4_Lr_mc_AKGC417L.png'],\n ['185_1b1_Pl_sc_Litt3200.png'],\n ['138_1p4_Pr_mc_AKGC417L.png'],\n ['110_1p1_Al_sc_Meditron.png'],\n ['170_1b3_Pr_mc_AKGC417L.png'],\n ['221_2b3_Al_mc_LittC2SE.png'],\n ['130_3p3_Pl_mc_AKGC417L.png'],\n ['214_1b1_Ar_sc_Meditron.png'],\n ['130_1p2_Ar_mc_AKGC417L.png'],\n ['107_2b3_Pr_mc_AKGC417L.png'],\n ['186_3b3_Tc_mc_AKGC417L.png'],\n ['127_1b1_Ar_sc_Meditron.png'],\n ['120_1b1_Pr_sc_Meditron.png'],\n ['107_2b4_Al_mc_AKGC417L.png'],\n ['162_2b4_Tc_mc_AKGC417L.png'],\n ['107_2b4_Ll_mc_AKGC417L.png'],\n ['107_2b3_Ll_mc_AKGC417L.png'],\n ['218_1p1_Ar_sc_Litt3200.png'],\n ['138_2p2_Lr_mc_AKGC417L.png'],\n ['178_1b3_Pr_mc_AKGC417L.png'],\n ['130_3b4_Al_mc_AKGC417L.png'],\n ['112_1b1_Ar_sc_Meditron.png'],\n ['160_1b2_Lr_mc_AKGC417L.png'],\n ['195_1b1_Pl_sc_Litt3200.png'],\n ['177_1b4_Al_mc_AKGC417L.png'],\n ['115_1b1_Ar_sc_Meditron.png'],\n ['204_2b5_Al_mc_AKGC417L.png'],\n ['186_2b3_Tc_mc_AKGC417L.png'],\n ['183_1b1_Pl_sc_Meditron.png'],\n ['147_2b3_Lr_mc_AKGC417L.png'],\n ['200_3p4_Tc_mc_AKGC417L.png'],\n ['203_1p3_Al_mc_AKGC417L.png'],\n ['104_1b1_Ll_sc_Litt3200.png'],\n ['110_1p1_Lr_sc_Meditron.png'],\n ['172_1b4_Tc_mc_AKGC417L.png'],\n ['170_1b2_Al_mc_AKGC417L.png'],\n ['157_1b1_Pl_sc_Meditron.png'],\n ['172_2b5_Pl_mc_AKGC417L.png'],\n ['163_8b3_Lr_mc_AKGC417L.png'],\n ['174_1p3_Ar_mc_AKGC417L.png'],\n ['177_1b4_Lr_mc_AKGC417L.png'],\n ['120_1b1_Pl_sc_Meditron.png'],\n ['193_1b4_Lr_mc_AKGC417L.png'],\n ['186_2b3_Ar_mc_AKGC417L.png'],\n ['107_2b5_Pr_mc_AKGC417L.png'],\n ['175_1b1_Al_sc_Litt3200.png'],\n ['140_2b3_Tc_mc_LittC2SE.png'],\n ['200_2p2_Pl_mc_AKGC417L.png'],\n ['162_2b3_Ar_mc_AKGC417L.png'],\n ['158_1p3_Ar_mc_AKGC417L.png'],\n ['205_3b4_Al_mc_AKGC417L.png'],\n ['130_2b4_Ll_mc_AKGC417L.png'],\n ['130_3p3_Tc_mc_AKGC417L.png'],\n ['130_3p2_Tc_mc_AKGC417L.png'],\n ['203_1p3_Pr_mc_AKGC417L.png'],\n ['172_1b5_Pr_mc_AKGC417L.png'],\n ['130_1p2_Pl_mc_AKGC417L.png'],\n ['151_2p2_Tc_mc_AKGC417L.png'],\n ['193_7b3_Al_mc_AKGC417L.png'],\n ['207_2b2_Pl_mc_AKGC417L.png'],\n ['118_1b1_Pr_sc_Litt3200.png'],\n ['107_2b3_Al_mc_AKGC417L.png'],\n ['170_1b3_Ar_mc_AKGC417L.png'],\n ['174_1p4_Pl_mc_AKGC417L.png'],\n ['178_1b6_Pl_mc_AKGC417L.png'],\n ['223_1b1_Lr_sc_Meditron.png'],\n ['138_2p2_Ar_mc_AKGC417L.png'],\n ['130_1p4_Pr_mc_AKGC417L.png'],\n ['186_2b3_Al_mc_AKGC417L.png'],\n ['178_2b2_Pr_mc_AKGC417L.png'],\n ['172_1b4_Al_mc_AKGC417L.png'],\n ['223_1b1_Ll_sc_Meditron.png'],\n ['186_3b3_Pr_mc_AKGC417L.png'],\n ['170_1b2_Pr_mc_AKGC417L.png'],\n ['221_2b2_Ar_mc_LittC2SE.png'],\n ['135_2b1_Pl_mc_LittC2SE.png'],\n ['211_1p5_Ar_mc_AKGC417L.png'],\n ['221_2b1_Ar_mc_LittC2SE.png'],\n ['162_2b2_Ar_mc_AKGC417L.png'],\n ['204_7p5_Al_mc_AKGC417L.png'],\n ['107_2b4_Pl_mc_AKGC417L.png'],\n ['135_2b3_Pl_mc_LittC2SE.png'],\n ['147_2b4_Ar_mc_AKGC417L.png'],\n ['223_1b1_Pr_sc_Meditron.png'],\n ['209_1b1_Tc_sc_Meditron.png'],\n ['224_1b2_Al_sc_Meditron.png'],\n ['203_1p4_Pr_mc_AKGC417L.png'],\n ['163_2b2_Al_mc_AKGC417L.png'],\n ['169_1b1_Lr_sc_Meditron.png'],\n ['160_1b3_Tc_mc_AKGC417L.png'],\n ['178_2b2_Al_mc_AKGC417L.png'],\n ['207_2b3_Pl_mc_AKGC417L.png'],\n ['218_1b1_Lr_sc_Meditron.png'],\n ['154_2b4_Lr_mc_AKGC417L.png'],\n ['207_3b2_Pl_mc_AKGC417L.png'],\n ['135_2b3_Ar_mc_LittC2SE.png'],\n ['195_1b1_Lr_sc_Litt3200.png'],\n ['138_1p3_Ar_mc_AKGC417L.png'],\n ['200_2p3_Al_mc_AKGC417L.png'],\n ['149_1b1_Lr_sc_Meditron.png'],\n ['172_1b3_Pl_mc_AKGC417L.png'],\n ['159_1b1_Ar_sc_Meditron.png'],\n ['130_2b4_Lr_mc_AKGC417L.png'],\n ['105_1b1_Tc_sc_Meditron.png'],\n ['189_1b2_Lr_mc_LittC2SE.png'],\n ['193_1b2_Tc_mc_AKGC417L.png'],\n ['160_1b2_Tc_mc_AKGC417L.png'],\n ['156_8b3_Ar_mc_AKGC417L.png'],\n ['130_1p2_Lr_mc_AKGC417L.png'],\n ['174_1p4_Pr_mc_AKGC417L.png'],\n ['180_1b4_Pr_mc_AKGC417L.png'],\n ['160_1b4_Pl_mc_AKGC417L.png'],\n ['110_1p1_Pr_sc_Meditron.png'],\n ['185_1b1_Al_sc_Litt3200.png'],\n ['194_1b1_Lr_sc_Meditron.png'],\n ['163_2b2_Pr_mc_AKGC417L.png'],\n ['198_1b5_Al_mc_AKGC417L.png'],\n ['200_2p2_Lr_mc_AKGC417L.png'],\n ['203_1p2_Pl_mc_AKGC417L.png'],\n ['186_2b2_Pr_mc_AKGC417L.png'],\n ['151_2p4_Pl_mc_AKGC417L.png'],\n ['154_4b4_Lr_mc_AKGC417L.png'],\n ['177_1b4_Tc_mc_AKGC417L.png'],\n ['205_4b2_Ar_mc_AKGC417L.png'],\n ['172_2b5_Pr_mc_AKGC417L.png'],\n ['176_1b4_Ar_mc_AKGC417L.png'],\n ['163_8b3_Ar_mc_AKGC417L.png'],\n ['223_1b1_Al_sc_Meditron.png'],\n ['205_2b3_Al_mc_AKGC417L.png'],\n ['221_2b3_Ar_mc_LittC2SE.png'],\n ['198_6p1_Pr_mc_AKGC417L.png'],\n ['221_2b1_Pl_mc_LittC2SE.png'],\n ['134_2b1_Ar_mc_LittC2SE.png'],\n ['186_2b4_Pl_mc_AKGC417L.png'],\n ['160_1b4_Lr_mc_AKGC417L.png'],\n ['146_8p3_Al_mc_AKGC417L.png'],\n ['139_1b1_Pr_sc_Litt3200.png'],\n ['155_2b1_Al_mc_LittC2SE.png'],\n ['154_1b3_Ar_mc_AKGC417L.png'],\n ['156_5b3_Ll_mc_AKGC417L.png'],\n ['113_1b1_Lr_sc_Litt3200.png'],\n ['124_1b1_Pl_sc_Litt3200.png'],\n ['177_2b4_Pl_mc_AKGC417L.png'],\n ['104_1b1_Lr_sc_Litt3200.png'],\n ['162_2b4_Lr_mc_AKGC417L.png'],\n ['160_1b3_Ar_mc_AKGC417L.png'],\n ['226_1b1_Al_sc_Meditron.png'],\n ['207_3b2_Lr_mc_AKGC417L.png'],\n ['130_2b2_Tc_mc_AKGC417L.png'],\n ['192_2b2_Ar_mc_LittC2SE.png'],\n ['200_3p4_Pr_mc_AKGC417L.png'],\n ['156_2b3_Lr_mc_AKGC417L.png'],\n ['133_2p2_Pl_mc_AKGC417L.png'],\n ['178_1b2_Al_mc_AKGC417L.png'],\n ['177_2b4_Tc_mc_AKGC417L.png'],\n ['223_1b1_Ar_sc_Meditron.png'],\n ['135_2b1_Ar_mc_LittC2SE.png'],\n ['138_1p4_Pl_mc_AKGC417L.png'],\n ['178_1b6_Al_mc_AKGC417L.png'],\n ['130_2b2_Lr_mc_AKGC417L.png'],\n ['158_1p3_Lr_mc_AKGC417L.png'],\n ['138_1p2_Tc_mc_AKGC417L.png'],\n ['130_1p4_Ar_mc_AKGC417L.png'],\n ['141_1b2_Lr_mc_LittC2SE.png'],\n ['146_2b4_Ar_mc_AKGC417L.png'],\n ['177_2b4_Pr_mc_AKGC417L.png'],\n ['198_1b5_Pl_mc_AKGC417L.png'],\n ['175_1b1_Ar_sc_Litt3200.png'],\n ['134_2b1_Al_mc_LittC2SE.png'],\n ['114_1b4_Pl_mc_AKGC417L.png'],\n ['170_1b4_Ar_mc_AKGC417L.png'],\n ['139_1b1_Ar_sc_Litt3200.png'],\n ['158_2p3_Tc_mc_AKGC417L.png'],\n ['185_1b1_Lr_sc_Litt3200.png'],\n ['165_1b1_Ar_sc_Meditron.png'],\n ['174_1p2_Ll_mc_AKGC417L.png'],\n ['203_1p4_Ar_mc_AKGC417L.png'],\n ['112_1b1_Lr_sc_Meditron.png'],\n ['158_2p3_Lr_mc_AKGC417L.png'],\n ['130_3p4_Pr_mc_AKGC417L.png'],\n ['151_2p2_Pr_mc_AKGC417L.png'],\n ['146_2b2_Pl_mc_AKGC417L.png'],\n ['158_1p2_Tc_mc_AKGC417L.png'],\n ['181_1b1_Ar_mc_LittC2SE.png'],\n ['132_2b1_Lr_mc_LittC2SE.png'],\n ['130_1p3_Pr_mc_AKGC417L.png'],\n ['130_2b4_Pl_mc_AKGC417L.png'],\n ['160_1b4_Ar_mc_AKGC417L.png'],\n ['138_2p2_Pl_mc_AKGC417L.png'],\n ['162_1b2_Pr_mc_AKGC417L.png'],\n ['138_2p2_Pr_mc_AKGC417L.png'],\n ['138_1p2_Al_mc_AKGC417L.png'],\n ['146_2b4_Lr_mc_AKGC417L.png'],\n ['109_1b1_Ll_sc_Litt3200.png'],\n ['158_1p3_Tc_mc_AKGC417L.png'],\n ['186_2b2_Al_mc_AKGC417L.png'],\n ['173_1b1_Al_sc_Meditron.png'],\n ['181_1b1_Tc_mc_LittC2SE.png'],\n ['124_1b1_Pr_sc_Litt3200.png'],\n ['174_1p3_Lr_mc_AKGC417L.png'],\n ['156_5b3_Lr_mc_AKGC417L.png'],\n ['185_1b1_Pr_sc_Litt3200.png'],\n ['134_2b2_Al_mc_LittC2SE.png'],\n ['172_1b3_Ar_mc_AKGC417L.png'],\n ['174_1p4_Lr_mc_AKGC417L.png'],\n ['175_1b1_Lr_sc_Litt3200.png'],\n ['107_2b5_Ar_mc_AKGC417L.png'],\n ['174_1p2_Tc_mc_AKGC417L.png'],\n ['211_1p3_Ar_mc_AKGC417L.png'],\n ['166_1p1_Al_sc_Meditron.png'],\n ['186_2b2_Lr_mc_AKGC417L.png'],\n ['184_1b1_Ar_sc_Meditron.png'],\n ['203_1p2_Pr_mc_AKGC417L.png'],\n ['160_1b2_Pl_mc_AKGC417L.png'],\n ['213_2p2_Al_mc_AKGC417L.png']]"},"metadata":{}}]},{"cell_type":"code","source":"labels = []\nfor i in range(len(req_file_names)):\n    req_file_names[i].append(sr_no[req_file_names[i][0][:3]])\n    labels.append(sr_no[req_file_names[i][0][:3]])","metadata":{"id":"LCKsXMpUvggI","execution":{"iopub.status.busy":"2023-08-11T00:01:36.409383Z","iopub.execute_input":"2023-08-11T00:01:36.410349Z","iopub.status.idle":"2023-08-11T00:01:36.417640Z","shell.execute_reply.started":"2023-08-11T00:01:36.410311Z","shell.execute_reply":"2023-08-11T00:01:36.416581Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"labels *= 3","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:01:36.419122Z","iopub.execute_input":"2023-08-11T00:01:36.419455Z","iopub.status.idle":"2023-08-11T00:01:36.429524Z","shell.execute_reply.started":"2023-08-11T00:01:36.419420Z","shell.execute_reply":"2023-08-11T00:01:36.428572Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"x = []\n\nfor i in req_file_names:\n    img = cv2.imread('/kaggle/input/chromagrams-lung-sound/Chromagrams/Chromagrams/Time Stretch/'+i[0])\n    img = cv2.resize(img, (350, 350))\n    x.append(img)\n\nfor i in req_file_names:\n    img = cv2.imread('/kaggle/input/chromagrams-lung-sound/Chromagrams/Chromagrams/Pitch Shift/'+i[0])\n    img = cv2.resize(img, (350, 350))\n    x.append(img)\n    \nfor i in req_file_names:\n    img = cv2.imread('/kaggle/input/chromagrams-lung-sound/Chromagrams/Chromagrams/Audio Shift/'+i[0])\n    img = cv2.resize(img, (350, 350))\n    x.append(img)\n\nx = np.array(x)\nprint(x.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PoMb8etvpAk","outputId":"65cd04d4-ba35-460e-b497-d9b5ac091122","execution":{"iopub.status.busy":"2023-08-11T00:01:36.431205Z","iopub.execute_input":"2023-08-11T00:01:36.431695Z","iopub.status.idle":"2023-08-11T00:02:12.722113Z","shell.execute_reply.started":"2023-08-11T00:01:36.431664Z","shell.execute_reply":"2023-08-11T00:02:12.720089Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(2760, 350, 350, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"req_file_names *= 3","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:02:12.726715Z","iopub.execute_input":"2023-08-11T00:02:12.727022Z","iopub.status.idle":"2023-08-11T00:02:12.731535Z","shell.execute_reply.started":"2023-08-11T00:02:12.726996Z","shell.execute_reply":"2023-08-11T00:02:12.730277Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"y = np.array(labels)\ny.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbwY828LxkMZ","outputId":"54c8937f-563d-41af-c159-3bd798c5cdf0","execution":{"iopub.status.busy":"2023-08-11T00:02:12.733087Z","iopub.execute_input":"2023-08-11T00:02:12.733468Z","iopub.status.idle":"2023-08-11T00:02:12.748010Z","shell.execute_reply.started":"2023-08-11T00:02:12.733435Z","shell.execute_reply":"2023-08-11T00:02:12.746984Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(2760,)"},"metadata":{}}]},{"cell_type":"code","source":"one_hot_y = np.array(pd.get_dummies(labels))","metadata":{"id":"bTiogsRk3ujL","execution":{"iopub.status.busy":"2023-08-11T00:02:12.749637Z","iopub.execute_input":"2023-08-11T00:02:12.750378Z","iopub.status.idle":"2023-08-11T00:02:12.763103Z","shell.execute_reply.started":"2023-08-11T00:02:12.750343Z","shell.execute_reply":"2023-08-11T00:02:12.762235Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, one_hot_y, test_size=0.4, random_state=33, stratify=y)\nprint(x_train.shape, y_train.shape, x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:02:12.765753Z","iopub.execute_input":"2023-08-11T00:02:12.766579Z","iopub.status.idle":"2023-08-11T00:02:13.023331Z","shell.execute_reply.started":"2023-08-11T00:02:12.766547Z","shell.execute_reply":"2023-08-11T00:02:13.022130Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(1656, 350, 350, 3) (1656, 8) (1104, 350, 350, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"model = keras.Sequential()\nmodel.add(keras.layers.Conv2D(256, (7,7), activation='relu', input_shape=(350, 350, 3)))\nmodel.add(keras.layers.MaxPool2D((3,3)))\nmodel.add(keras.layers.Conv2D(64, (5,5), activation='relu'))\nmodel.add(keras.layers.MaxPool2D((3,3)))\nmodel.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(128, activation='relu'))\nmodel.add(keras.layers.Dense(64, activation='relu'))\nmodel.add(keras.layers.Dense(8, activation='softmax'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:02:13.025228Z","iopub.execute_input":"2023-08-11T00:02:13.025624Z","iopub.status.idle":"2023-08-11T00:02:15.945235Z","shell.execute_reply.started":"2023-08-11T00:02:13.025584Z","shell.execute_reply":"2023-08-11T00:02:15.944460Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 344, 344, 256)     37888     \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 114, 114, 256)    0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 110, 110, 64)      409664    \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n 2D)                                                             \n                                                                 \n conv2d_2 (Conv2D)           (None, 34, 34, 32)        18464     \n                                                                 \n flatten (Flatten)           (None, 36992)             0         \n                                                                 \n dense (Dense)               (None, 128)               4735104   \n                                                                 \n dense_1 (Dense)             (None, 64)                8256      \n                                                                 \n dense_2 (Dense)             (None, 8)                 520       \n                                                                 \n=================================================================\nTotal params: 5,209,896\nTrainable params: 5,209,896\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:02:15.946272Z","iopub.execute_input":"2023-08-11T00:02:15.946603Z","iopub.status.idle":"2023-08-11T00:02:15.975894Z","shell.execute_reply.started":"2023-08-11T00:02:15.946570Z","shell.execute_reply":"2023-08-11T00:02:15.974897Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:02:15.977198Z","iopub.execute_input":"2023-08-11T00:02:15.977622Z","iopub.status.idle":"2023-08-11T00:15:50.260054Z","shell.execute_reply.started":"2023-08-11T00:02:15.977587Z","shell.execute_reply":"2023-08-11T00:15:50.258800Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/60\n52/52 [==============================] - 35s 379ms/step - loss: 373.2521 - accuracy: 0.6987 - val_loss: 11.2743 - val_accuracy: 0.8478\nEpoch 2/60\n52/52 [==============================] - 13s 258ms/step - loss: 2.7797 - accuracy: 0.7403 - val_loss: 1.2288 - val_accuracy: 0.8623\nEpoch 3/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.8850 - accuracy: 0.8563 - val_loss: 0.6565 - val_accuracy: 0.8614\nEpoch 4/60\n52/52 [==============================] - 13s 258ms/step - loss: 0.6403 - accuracy: 0.8617 - val_loss: 0.6152 - val_accuracy: 0.8623\nEpoch 5/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5761 - accuracy: 0.8647 - val_loss: 0.5918 - val_accuracy: 0.8596\nEpoch 6/60\n52/52 [==============================] - 13s 251ms/step - loss: 0.8590 - accuracy: 0.8611 - val_loss: 0.6821 - val_accuracy: 0.8623\nEpoch 7/60\n52/52 [==============================] - 13s 258ms/step - loss: 0.7349 - accuracy: 0.8611 - val_loss: 0.6758 - val_accuracy: 0.8587\nEpoch 8/60\n52/52 [==============================] - 13s 258ms/step - loss: 0.6251 - accuracy: 0.8599 - val_loss: 0.6154 - val_accuracy: 0.8596\nEpoch 9/60\n52/52 [==============================] - 13s 252ms/step - loss: 0.6068 - accuracy: 0.8617 - val_loss: 0.6041 - val_accuracy: 0.8623\nEpoch 10/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5965 - accuracy: 0.8617 - val_loss: 0.5838 - val_accuracy: 0.8623\nEpoch 11/60\n52/52 [==============================] - 13s 252ms/step - loss: 0.5875 - accuracy: 0.8617 - val_loss: 0.5910 - val_accuracy: 0.8614\nEpoch 12/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5807 - accuracy: 0.8623 - val_loss: 0.6391 - val_accuracy: 0.8596\nEpoch 13/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5847 - accuracy: 0.8629 - val_loss: 0.5936 - val_accuracy: 0.8614\nEpoch 14/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5796 - accuracy: 0.8635 - val_loss: 0.5876 - val_accuracy: 0.8614\nEpoch 15/60\n52/52 [==============================] - 13s 251ms/step - loss: 0.5762 - accuracy: 0.8641 - val_loss: 0.5819 - val_accuracy: 0.8623\nEpoch 16/60\n52/52 [==============================] - 13s 258ms/step - loss: 0.5735 - accuracy: 0.8641 - val_loss: 0.5903 - val_accuracy: 0.8623\nEpoch 17/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5789 - accuracy: 0.8647 - val_loss: 0.5872 - val_accuracy: 0.8614\nEpoch 18/60\n52/52 [==============================] - 13s 251ms/step - loss: 0.5663 - accuracy: 0.8653 - val_loss: 0.5850 - val_accuracy: 0.8623\nEpoch 19/60\n52/52 [==============================] - 13s 258ms/step - loss: 0.5603 - accuracy: 0.8641 - val_loss: 0.6003 - val_accuracy: 0.8605\nEpoch 20/60\n52/52 [==============================] - 13s 252ms/step - loss: 0.5577 - accuracy: 0.8653 - val_loss: 0.5959 - val_accuracy: 0.8614\nEpoch 21/60\n52/52 [==============================] - 13s 258ms/step - loss: 0.5559 - accuracy: 0.8665 - val_loss: 0.5899 - val_accuracy: 0.8614\nEpoch 22/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5507 - accuracy: 0.8659 - val_loss: 0.6216 - val_accuracy: 0.8587\nEpoch 23/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5507 - accuracy: 0.8684 - val_loss: 0.6028 - val_accuracy: 0.8614\nEpoch 24/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5628 - accuracy: 0.8671 - val_loss: 0.6044 - val_accuracy: 0.8614\nEpoch 25/60\n52/52 [==============================] - 13s 257ms/step - loss: 116.9794 - accuracy: 0.7971 - val_loss: 4143.9126 - val_accuracy: 0.0254\nEpoch 26/60\n52/52 [==============================] - 13s 252ms/step - loss: 116.6160 - accuracy: 0.8068 - val_loss: 0.6981 - val_accuracy: 0.8478\nEpoch 27/60\n52/52 [==============================] - 13s 251ms/step - loss: 0.7043 - accuracy: 0.8502 - val_loss: 0.6333 - val_accuracy: 0.8478\nEpoch 28/60\n52/52 [==============================] - 13s 258ms/step - loss: 0.6606 - accuracy: 0.8617 - val_loss: 0.5863 - val_accuracy: 0.8623\nEpoch 29/60\n52/52 [==============================] - 13s 251ms/step - loss: 0.5987 - accuracy: 0.8623 - val_loss: 0.6062 - val_accuracy: 0.8623\nEpoch 30/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5892 - accuracy: 0.8635 - val_loss: 0.5640 - val_accuracy: 0.8623\nEpoch 31/60\n52/52 [==============================] - 13s 252ms/step - loss: 0.5720 - accuracy: 0.8623 - val_loss: 0.5581 - val_accuracy: 0.8623\nEpoch 32/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5672 - accuracy: 0.8635 - val_loss: 0.5953 - val_accuracy: 0.8623\nEpoch 33/60\n52/52 [==============================] - 13s 252ms/step - loss: 0.5747 - accuracy: 0.8641 - val_loss: 0.5689 - val_accuracy: 0.8614\nEpoch 34/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5666 - accuracy: 0.8641 - val_loss: 0.5647 - val_accuracy: 0.8623\nEpoch 35/60\n52/52 [==============================] - 13s 258ms/step - loss: 0.5659 - accuracy: 0.8659 - val_loss: 0.5863 - val_accuracy: 0.8614\nEpoch 36/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5951 - accuracy: 0.8617 - val_loss: 0.5659 - val_accuracy: 0.8614\nEpoch 37/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5590 - accuracy: 0.8659 - val_loss: 0.5975 - val_accuracy: 0.8596\nEpoch 38/60\n52/52 [==============================] - 13s 252ms/step - loss: 0.5542 - accuracy: 0.8665 - val_loss: 0.5608 - val_accuracy: 0.8650\nEpoch 39/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5544 - accuracy: 0.8653 - val_loss: 0.5877 - val_accuracy: 0.8623\nEpoch 40/60\n52/52 [==============================] - 13s 252ms/step - loss: 0.5304 - accuracy: 0.8678 - val_loss: 0.5972 - val_accuracy: 0.8650\nEpoch 41/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5766 - accuracy: 0.8641 - val_loss: 0.5500 - val_accuracy: 0.8641\nEpoch 42/60\n52/52 [==============================] - 13s 251ms/step - loss: 0.5407 - accuracy: 0.8665 - val_loss: 0.6233 - val_accuracy: 0.8514\nEpoch 43/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.5605 - accuracy: 0.8647 - val_loss: 0.6250 - val_accuracy: 0.8632\nEpoch 44/60\n52/52 [==============================] - 13s 251ms/step - loss: 0.5502 - accuracy: 0.8653 - val_loss: 0.5853 - val_accuracy: 0.8623\nEpoch 45/60\n52/52 [==============================] - 13s 252ms/step - loss: 0.5179 - accuracy: 0.8738 - val_loss: 0.6071 - val_accuracy: 0.8587\nEpoch 46/60\n52/52 [==============================] - 13s 251ms/step - loss: 0.6241 - accuracy: 0.8659 - val_loss: 1.0483 - val_accuracy: 0.8270\nEpoch 47/60\n52/52 [==============================] - 13s 252ms/step - loss: 0.7520 - accuracy: 0.8388 - val_loss: 0.8413 - val_accuracy: 0.8623\nEpoch 48/60\n52/52 [==============================] - 13s 257ms/step - loss: 0.6490 - accuracy: 0.8605 - val_loss: 0.7311 - val_accuracy: 0.8614\nEpoch 49/60\n52/52 [==============================] - 13s 251ms/step - loss: 155.5401 - accuracy: 0.7729 - val_loss: 12.5274 - val_accuracy: 0.8623\nEpoch 50/60\n52/52 [==============================] - 13s 252ms/step - loss: 8918.1768 - accuracy: 0.7083 - val_loss: 188.6255 - val_accuracy: 0.8478\nEpoch 51/60\n52/52 [==============================] - 13s 251ms/step - loss: 34.7415 - accuracy: 0.7615 - val_loss: 7.7514 - val_accuracy: 0.8170\nEpoch 52/60\n52/52 [==============================] - 13s 251ms/step - loss: 4.7867 - accuracy: 0.7772 - val_loss: 2.5938 - val_accuracy: 0.8551\nEpoch 53/60\n52/52 [==============================] - 13s 257ms/step - loss: 2.2867 - accuracy: 0.8068 - val_loss: 1.6105 - val_accuracy: 0.8596\nEpoch 54/60\n52/52 [==============================] - 13s 251ms/step - loss: 1.7806 - accuracy: 0.8092 - val_loss: 1.2339 - val_accuracy: 0.7518\nEpoch 55/60\n52/52 [==============================] - 13s 252ms/step - loss: 1.0855 - accuracy: 0.8255 - val_loss: 0.9899 - val_accuracy: 0.8288\nEpoch 56/60\n52/52 [==============================] - 13s 251ms/step - loss: 1.0421 - accuracy: 0.8303 - val_loss: 0.9041 - val_accuracy: 0.8207\nEpoch 57/60\n52/52 [==============================] - 13s 252ms/step - loss: 0.8907 - accuracy: 0.8521 - val_loss: 0.7012 - val_accuracy: 0.8605\nEpoch 58/60\n52/52 [==============================] - 13s 251ms/step - loss: 0.7401 - accuracy: 0.8454 - val_loss: 0.7226 - val_accuracy: 0.8578\nEpoch 59/60\n52/52 [==============================] - 13s 252ms/step - loss: 0.7929 - accuracy: 0.8351 - val_loss: 1.0684 - val_accuracy: 0.8614\nEpoch 60/60\n52/52 [==============================] - 13s 251ms/step - loss: 0.7181 - accuracy: 0.8569 - val_loss: 0.9466 - val_accuracy: 0.8007\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f586c2c6f20>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Transfer Learning","metadata":{}},{"cell_type":"markdown","source":"### Xception model","metadata":{}},{"cell_type":"code","source":"xception_wo_top = keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(350, 350, 3))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:15:50.261465Z","iopub.execute_input":"2023-08-11T00:15:50.261920Z","iopub.status.idle":"2023-08-11T00:15:52.250946Z","shell.execute_reply.started":"2023-08-11T00:15:50.261868Z","shell.execute_reply":"2023-08-11T00:15:52.249905Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83683744/83683744 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"xception_wo_top.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:15:52.252521Z","iopub.execute_input":"2023-08-11T00:15:52.252915Z","iopub.status.idle":"2023-08-11T00:15:52.262198Z","shell.execute_reply.started":"2023-08-11T00:15:52.252862Z","shell.execute_reply":"2023-08-11T00:15:52.261187Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"xception_model = keras.models.Sequential()\nxception_model.add(xception_wo_top)\nxception_model.add(keras.layers.Flatten())\nxception_model.add(keras.layers.Dense(128, activation='relu'))\nxception_model.add(keras.layers.Dense(64, activation='relu'))\nxception_model.add(keras.layers.Dense(8, activation='softmax'))\n\nxception_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:15:52.263643Z","iopub.execute_input":"2023-08-11T00:15:52.264282Z","iopub.status.idle":"2023-08-11T00:15:52.725533Z","shell.execute_reply.started":"2023-08-11T00:15:52.264248Z","shell.execute_reply":"2023-08-11T00:15:52.724590Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n xception (Functional)       (None, 11, 11, 2048)      20861480  \n                                                                 \n flatten_1 (Flatten)         (None, 247808)            0         \n                                                                 \n dense_3 (Dense)             (None, 128)               31719552  \n                                                                 \n dense_4 (Dense)             (None, 64)                8256      \n                                                                 \n dense_5 (Dense)             (None, 8)                 520       \n                                                                 \n=================================================================\nTotal params: 52,589,808\nTrainable params: 31,728,328\nNon-trainable params: 20,861,480\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"xception_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:15:52.727232Z","iopub.execute_input":"2023-08-11T00:15:52.727572Z","iopub.status.idle":"2023-08-11T00:15:52.743274Z","shell.execute_reply.started":"2023-08-11T00:15:52.727539Z","shell.execute_reply":"2023-08-11T00:15:52.742409Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"xception_model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:15:52.744660Z","iopub.execute_input":"2023-08-11T00:15:52.745025Z","iopub.status.idle":"2023-08-11T00:34:11.343886Z","shell.execute_reply.started":"2023-08-11T00:15:52.744992Z","shell.execute_reply":"2023-08-11T00:34:11.342786Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch 1/60\n52/52 [==============================] - 27s 427ms/step - loss: 219.3725 - accuracy: 0.7120 - val_loss: 182.8433 - val_accuracy: 0.8623\nEpoch 2/60\n52/52 [==============================] - 19s 371ms/step - loss: 127.1371 - accuracy: 0.7663 - val_loss: 108.2621 - val_accuracy: 0.8623\nEpoch 3/60\n52/52 [==============================] - 19s 372ms/step - loss: 84.3976 - accuracy: 0.7723 - val_loss: 19.3259 - val_accuracy: 0.7681\nEpoch 4/60\n52/52 [==============================] - 15s 283ms/step - loss: 60.3694 - accuracy: 0.7609 - val_loss: 33.4426 - val_accuracy: 0.8623\nEpoch 5/60\n52/52 [==============================] - 19s 371ms/step - loss: 48.9516 - accuracy: 0.7705 - val_loss: 36.1336 - val_accuracy: 0.8062\nEpoch 6/60\n52/52 [==============================] - 19s 371ms/step - loss: 30.2562 - accuracy: 0.8001 - val_loss: 19.3639 - val_accuracy: 0.8605\nEpoch 7/60\n52/52 [==============================] - 19s 372ms/step - loss: 16.3241 - accuracy: 0.7953 - val_loss: 21.2927 - val_accuracy: 0.4239\nEpoch 8/60\n52/52 [==============================] - 19s 372ms/step - loss: 18.8216 - accuracy: 0.8074 - val_loss: 13.7067 - val_accuracy: 0.8668\nEpoch 9/60\n52/52 [==============================] - 15s 283ms/step - loss: 11.5245 - accuracy: 0.8188 - val_loss: 21.5008 - val_accuracy: 0.8641\nEpoch 10/60\n52/52 [==============================] - 19s 372ms/step - loss: 12.4696 - accuracy: 0.8303 - val_loss: 12.6971 - val_accuracy: 0.8605\nEpoch 11/60\n52/52 [==============================] - 19s 371ms/step - loss: 17.5315 - accuracy: 0.8158 - val_loss: 27.7307 - val_accuracy: 0.8623\nEpoch 12/60\n52/52 [==============================] - 15s 283ms/step - loss: 19.7882 - accuracy: 0.8025 - val_loss: 14.5534 - val_accuracy: 0.8632\nEpoch 13/60\n52/52 [==============================] - 19s 372ms/step - loss: 6.8852 - accuracy: 0.8611 - val_loss: 13.2063 - val_accuracy: 0.8578\nEpoch 14/60\n52/52 [==============================] - 19s 372ms/step - loss: 5.5880 - accuracy: 0.8424 - val_loss: 14.5874 - val_accuracy: 0.8641\nEpoch 15/60\n52/52 [==============================] - 19s 373ms/step - loss: 12.2724 - accuracy: 0.8376 - val_loss: 16.6028 - val_accuracy: 0.7591\nEpoch 16/60\n52/52 [==============================] - 15s 283ms/step - loss: 12.9352 - accuracy: 0.8430 - val_loss: 25.3207 - val_accuracy: 0.8623\nEpoch 17/60\n52/52 [==============================] - 19s 372ms/step - loss: 12.2522 - accuracy: 0.8327 - val_loss: 14.8054 - val_accuracy: 0.8505\nEpoch 18/60\n52/52 [==============================] - 19s 371ms/step - loss: 7.0484 - accuracy: 0.8430 - val_loss: 11.2939 - val_accuracy: 0.7998\nEpoch 19/60\n52/52 [==============================] - 19s 372ms/step - loss: 7.0278 - accuracy: 0.8339 - val_loss: 20.0140 - val_accuracy: 0.4611\nEpoch 20/60\n52/52 [==============================] - 19s 372ms/step - loss: 6.9051 - accuracy: 0.8176 - val_loss: 6.9489 - val_accuracy: 0.8587\nEpoch 21/60\n52/52 [==============================] - 19s 371ms/step - loss: 6.2024 - accuracy: 0.8472 - val_loss: 7.7811 - val_accuracy: 0.6893\nEpoch 22/60\n52/52 [==============================] - 15s 283ms/step - loss: 5.2736 - accuracy: 0.8533 - val_loss: 6.9571 - val_accuracy: 0.8614\nEpoch 23/60\n52/52 [==============================] - 19s 371ms/step - loss: 7.3769 - accuracy: 0.8545 - val_loss: 6.7265 - val_accuracy: 0.8306\nEpoch 24/60\n52/52 [==============================] - 15s 283ms/step - loss: 1.6927 - accuracy: 0.8925 - val_loss: 4.6299 - val_accuracy: 0.8034\nEpoch 25/60\n52/52 [==============================] - 19s 371ms/step - loss: 1.9807 - accuracy: 0.8877 - val_loss: 6.1621 - val_accuracy: 0.7328\nEpoch 26/60\n52/52 [==============================] - 19s 372ms/step - loss: 3.1386 - accuracy: 0.8774 - val_loss: 3.7749 - val_accuracy: 0.8578\nEpoch 27/60\n52/52 [==============================] - 19s 373ms/step - loss: 1.9964 - accuracy: 0.9010 - val_loss: 8.1894 - val_accuracy: 0.8569\nEpoch 28/60\n52/52 [==============================] - 19s 372ms/step - loss: 3.5765 - accuracy: 0.8671 - val_loss: 6.1680 - val_accuracy: 0.8406\nEpoch 29/60\n52/52 [==============================] - 19s 372ms/step - loss: 2.7499 - accuracy: 0.8877 - val_loss: 10.8085 - val_accuracy: 0.8623\nEpoch 30/60\n52/52 [==============================] - 19s 372ms/step - loss: 5.5108 - accuracy: 0.8442 - val_loss: 8.4408 - val_accuracy: 0.7210\nEpoch 31/60\n52/52 [==============================] - 19s 372ms/step - loss: 2.4065 - accuracy: 0.8949 - val_loss: 7.9913 - val_accuracy: 0.8641\nEpoch 32/60\n52/52 [==============================] - 19s 372ms/step - loss: 1.7838 - accuracy: 0.8998 - val_loss: 6.1651 - val_accuracy: 0.8605\nEpoch 33/60\n52/52 [==============================] - 19s 372ms/step - loss: 3.1703 - accuracy: 0.8829 - val_loss: 12.4946 - val_accuracy: 0.6250\nEpoch 34/60\n52/52 [==============================] - 19s 372ms/step - loss: 5.7281 - accuracy: 0.8454 - val_loss: 17.8693 - val_accuracy: 0.7437\nEpoch 35/60\n52/52 [==============================] - 15s 283ms/step - loss: 9.5589 - accuracy: 0.8255 - val_loss: 17.2204 - val_accuracy: 0.8632\nEpoch 36/60\n52/52 [==============================] - 15s 283ms/step - loss: 6.2073 - accuracy: 0.8454 - val_loss: 10.4508 - val_accuracy: 0.8623\nEpoch 37/60\n52/52 [==============================] - 19s 371ms/step - loss: 4.1929 - accuracy: 0.8623 - val_loss: 2.7694 - val_accuracy: 0.8324\nEpoch 38/60\n52/52 [==============================] - 19s 372ms/step - loss: 1.1028 - accuracy: 0.8998 - val_loss: 3.4808 - val_accuracy: 0.8125\nEpoch 39/60\n52/52 [==============================] - 19s 373ms/step - loss: 2.4217 - accuracy: 0.8883 - val_loss: 7.0626 - val_accuracy: 0.8388\nEpoch 40/60\n52/52 [==============================] - 19s 372ms/step - loss: 1.0662 - accuracy: 0.8194 - val_loss: 0.7999 - val_accuracy: 0.8623\nEpoch 41/60\n52/52 [==============================] - 15s 284ms/step - loss: 0.4054 - accuracy: 0.8720 - val_loss: 0.6980 - val_accuracy: 0.8569\nEpoch 42/60\n52/52 [==============================] - 19s 371ms/step - loss: 0.3794 - accuracy: 0.8756 - val_loss: 0.6601 - val_accuracy: 0.8478\nEpoch 43/60\n52/52 [==============================] - 19s 372ms/step - loss: 0.3666 - accuracy: 0.8810 - val_loss: 0.6483 - val_accuracy: 0.8496\nEpoch 44/60\n52/52 [==============================] - 15s 283ms/step - loss: 0.3575 - accuracy: 0.8810 - val_loss: 0.6461 - val_accuracy: 0.8533\nEpoch 45/60\n52/52 [==============================] - 19s 371ms/step - loss: 0.3555 - accuracy: 0.8786 - val_loss: 0.7273 - val_accuracy: 0.8605\nEpoch 46/60\n52/52 [==============================] - 19s 372ms/step - loss: 0.3562 - accuracy: 0.8804 - val_loss: 0.7280 - val_accuracy: 0.8614\nEpoch 47/60\n52/52 [==============================] - 19s 371ms/step - loss: 0.3300 - accuracy: 0.8841 - val_loss: 0.6527 - val_accuracy: 0.8542\nEpoch 48/60\n52/52 [==============================] - 19s 372ms/step - loss: 0.3245 - accuracy: 0.8847 - val_loss: 0.6384 - val_accuracy: 0.8487\nEpoch 49/60\n52/52 [==============================] - 19s 372ms/step - loss: 0.3259 - accuracy: 0.8847 - val_loss: 0.8539 - val_accuracy: 0.8632\nEpoch 50/60\n52/52 [==============================] - 15s 283ms/step - loss: 0.3325 - accuracy: 0.8829 - val_loss: 0.6464 - val_accuracy: 0.8170\nEpoch 51/60\n52/52 [==============================] - 19s 371ms/step - loss: 0.3659 - accuracy: 0.8780 - val_loss: 0.6928 - val_accuracy: 0.8614\nEpoch 52/60\n52/52 [==============================] - 19s 371ms/step - loss: 0.3111 - accuracy: 0.8822 - val_loss: 0.6992 - val_accuracy: 0.8614\nEpoch 53/60\n52/52 [==============================] - 19s 372ms/step - loss: 0.3124 - accuracy: 0.8883 - val_loss: 0.6522 - val_accuracy: 0.8514\nEpoch 54/60\n52/52 [==============================] - 19s 371ms/step - loss: 0.3409 - accuracy: 0.8901 - val_loss: 0.6327 - val_accuracy: 0.8306\nEpoch 55/60\n52/52 [==============================] - 19s 372ms/step - loss: 0.3073 - accuracy: 0.8973 - val_loss: 0.6881 - val_accuracy: 0.8578\nEpoch 56/60\n52/52 [==============================] - 19s 371ms/step - loss: 0.2852 - accuracy: 0.8943 - val_loss: 0.7200 - val_accuracy: 0.8605\nEpoch 57/60\n52/52 [==============================] - 15s 282ms/step - loss: 0.2819 - accuracy: 0.8979 - val_loss: 0.7290 - val_accuracy: 0.8578\nEpoch 58/60\n52/52 [==============================] - 19s 372ms/step - loss: 0.2868 - accuracy: 0.8949 - val_loss: 0.8962 - val_accuracy: 0.8641\nEpoch 59/60\n52/52 [==============================] - 15s 283ms/step - loss: 0.3426 - accuracy: 0.8913 - val_loss: 0.9830 - val_accuracy: 0.7455\nEpoch 60/60\n52/52 [==============================] - 19s 372ms/step - loss: 0.3255 - accuracy: 0.8877 - val_loss: 0.6641 - val_accuracy: 0.8406\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f58001523e0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### VGG19","metadata":{}},{"cell_type":"code","source":"vgg_wo_top = keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', input_shape=(350, 350, 3))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:34:11.345577Z","iopub.execute_input":"2023-08-11T00:34:11.346037Z","iopub.status.idle":"2023-08-11T00:34:12.229963Z","shell.execute_reply.started":"2023-08-11T00:34:11.346001Z","shell.execute_reply":"2023-08-11T00:34:12.228782Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80134624/80134624 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"vgg_wo_top.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:34:12.231364Z","iopub.execute_input":"2023-08-11T00:34:12.231706Z","iopub.status.idle":"2023-08-11T00:34:12.239121Z","shell.execute_reply.started":"2023-08-11T00:34:12.231674Z","shell.execute_reply":"2023-08-11T00:34:12.237831Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"vgg_model = keras.models.Sequential()\nvgg_model.add(vgg_wo_top)\nvgg_model.add(keras.layers.Flatten())\nvgg_model.add(keras.layers.Dense(128, activation='relu'))\nvgg_model.add(keras.layers.Dense(64, activation='relu'))\nvgg_model.add(keras.layers.Dense(8, activation='softmax'))\n\nvgg_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:34:12.240713Z","iopub.execute_input":"2023-08-11T00:34:12.241112Z","iopub.status.idle":"2023-08-11T00:34:12.387953Z","shell.execute_reply.started":"2023-08-11T00:34:12.241079Z","shell.execute_reply":"2023-08-11T00:34:12.387051Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n vgg19 (Functional)          (None, 10, 10, 512)       20024384  \n                                                                 \n flatten_2 (Flatten)         (None, 51200)             0         \n                                                                 \n dense_6 (Dense)             (None, 128)               6553728   \n                                                                 \n dense_7 (Dense)             (None, 64)                8256      \n                                                                 \n dense_8 (Dense)             (None, 8)                 520       \n                                                                 \n=================================================================\nTotal params: 26,586,888\nTrainable params: 6,562,504\nNon-trainable params: 20,024,384\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"vgg_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:34:12.389240Z","iopub.execute_input":"2023-08-11T00:34:12.389668Z","iopub.status.idle":"2023-08-11T00:34:12.411807Z","shell.execute_reply.started":"2023-08-11T00:34:12.389629Z","shell.execute_reply":"2023-08-11T00:34:12.411082Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"vgg_model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:34:12.414995Z","iopub.execute_input":"2023-08-11T00:34:12.415399Z","iopub.status.idle":"2023-08-11T00:53:36.424703Z","shell.execute_reply.started":"2023-08-11T00:34:12.415373Z","shell.execute_reply":"2023-08-11T00:53:36.423695Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1/60\n52/52 [==============================] - 31s 473ms/step - loss: 83.5359 - accuracy: 0.7283 - val_loss: 24.8992 - val_accuracy: 0.8234\nEpoch 2/60\n52/52 [==============================] - 20s 379ms/step - loss: 16.5184 - accuracy: 0.8001 - val_loss: 14.7604 - val_accuracy: 0.8614\nEpoch 3/60\n52/52 [==============================] - 20s 379ms/step - loss: 5.6240 - accuracy: 0.8424 - val_loss: 8.7591 - val_accuracy: 0.8614\nEpoch 4/60\n52/52 [==============================] - 15s 297ms/step - loss: 8.6482 - accuracy: 0.8351 - val_loss: 20.1698 - val_accuracy: 0.8668\nEpoch 5/60\n52/52 [==============================] - 20s 379ms/step - loss: 6.8103 - accuracy: 0.8714 - val_loss: 6.4002 - val_accuracy: 0.7871\nEpoch 6/60\n52/52 [==============================] - 15s 297ms/step - loss: 2.2941 - accuracy: 0.8889 - val_loss: 5.5686 - val_accuracy: 0.7491\nEpoch 7/60\n52/52 [==============================] - 15s 296ms/step - loss: 1.5250 - accuracy: 0.9112 - val_loss: 4.8150 - val_accuracy: 0.7953\nEpoch 8/60\n52/52 [==============================] - 15s 298ms/step - loss: 0.8388 - accuracy: 0.9414 - val_loss: 5.3657 - val_accuracy: 0.8659\nEpoch 9/60\n52/52 [==============================] - 15s 297ms/step - loss: 3.0802 - accuracy: 0.8961 - val_loss: 5.9610 - val_accuracy: 0.7627\nEpoch 10/60\n52/52 [==============================] - 20s 380ms/step - loss: 0.8230 - accuracy: 0.9450 - val_loss: 5.1688 - val_accuracy: 0.7129\nEpoch 11/60\n52/52 [==============================] - 20s 379ms/step - loss: 0.2816 - accuracy: 0.9614 - val_loss: 4.2136 - val_accuracy: 0.8578\nEpoch 12/60\n52/52 [==============================] - 20s 380ms/step - loss: 2.0861 - accuracy: 0.8979 - val_loss: 11.5453 - val_accuracy: 0.8696\nEpoch 13/60\n52/52 [==============================] - 20s 379ms/step - loss: 0.9831 - accuracy: 0.9372 - val_loss: 6.0504 - val_accuracy: 0.8596\nEpoch 14/60\n52/52 [==============================] - 20s 379ms/step - loss: 0.4273 - accuracy: 0.9620 - val_loss: 6.4665 - val_accuracy: 0.7609\nEpoch 15/60\n52/52 [==============================] - 20s 380ms/step - loss: 0.2723 - accuracy: 0.9716 - val_loss: 5.6110 - val_accuracy: 0.8714\nEpoch 16/60\n52/52 [==============================] - 20s 379ms/step - loss: 0.4528 - accuracy: 0.9764 - val_loss: 7.4335 - val_accuracy: 0.8098\nEpoch 17/60\n52/52 [==============================] - 15s 297ms/step - loss: 0.5986 - accuracy: 0.9511 - val_loss: 9.7545 - val_accuracy: 0.8596\nEpoch 18/60\n52/52 [==============================] - 20s 379ms/step - loss: 2.6873 - accuracy: 0.9064 - val_loss: 8.6727 - val_accuracy: 0.8678\nEpoch 19/60\n52/52 [==============================] - 20s 379ms/step - loss: 0.5156 - accuracy: 0.9626 - val_loss: 5.8919 - val_accuracy: 0.7962\nEpoch 20/60\n52/52 [==============================] - 20s 380ms/step - loss: 0.6022 - accuracy: 0.9583 - val_loss: 5.9178 - val_accuracy: 0.8560\nEpoch 21/60\n52/52 [==============================] - 20s 379ms/step - loss: 0.0186 - accuracy: 0.9970 - val_loss: 4.8567 - val_accuracy: 0.8696\nEpoch 22/60\n52/52 [==============================] - 15s 297ms/step - loss: 0.0435 - accuracy: 0.9940 - val_loss: 5.5434 - val_accuracy: 0.8596\nEpoch 23/60\n52/52 [==============================] - 20s 379ms/step - loss: 0.2727 - accuracy: 0.9764 - val_loss: 5.3310 - val_accuracy: 0.8723\nEpoch 24/60\n52/52 [==============================] - 20s 379ms/step - loss: 0.1338 - accuracy: 0.9873 - val_loss: 6.7811 - val_accuracy: 0.8632\nEpoch 25/60\n52/52 [==============================] - 20s 380ms/step - loss: 0.0873 - accuracy: 0.9873 - val_loss: 4.6836 - val_accuracy: 0.8252\nEpoch 26/60\n52/52 [==============================] - 20s 379ms/step - loss: 0.0476 - accuracy: 0.9928 - val_loss: 8.8318 - val_accuracy: 0.8659\nEpoch 27/60\n52/52 [==============================] - 20s 379ms/step - loss: 0.0956 - accuracy: 0.9885 - val_loss: 5.6865 - val_accuracy: 0.8569\nEpoch 28/60\n52/52 [==============================] - 15s 297ms/step - loss: 0.5886 - accuracy: 0.9638 - val_loss: 8.6110 - val_accuracy: 0.8687\nEpoch 29/60\n52/52 [==============================] - 19s 379ms/step - loss: 0.1519 - accuracy: 0.9849 - val_loss: 7.3854 - val_accuracy: 0.8741\nEpoch 30/60\n52/52 [==============================] - 20s 379ms/step - loss: 1.7664 - accuracy: 0.9463 - val_loss: 9.3928 - val_accuracy: 0.8632\nEpoch 31/60\n52/52 [==============================] - 20s 379ms/step - loss: 2.2438 - accuracy: 0.9185 - val_loss: 7.2941 - val_accuracy: 0.8197\nEpoch 32/60\n52/52 [==============================] - 20s 380ms/step - loss: 0.4848 - accuracy: 0.9601 - val_loss: 10.8842 - val_accuracy: 0.8668\nEpoch 33/60\n52/52 [==============================] - 15s 297ms/step - loss: 4.5970 - accuracy: 0.8804 - val_loss: 7.9000 - val_accuracy: 0.8524\nEpoch 34/60\n52/52 [==============================] - 20s 379ms/step - loss: 0.2160 - accuracy: 0.9819 - val_loss: 6.9832 - val_accuracy: 0.8415\nEpoch 35/60\n52/52 [==============================] - 20s 380ms/step - loss: 0.0768 - accuracy: 0.9921 - val_loss: 5.5864 - val_accuracy: 0.8505\nEpoch 36/60\n52/52 [==============================] - 20s 379ms/step - loss: 0.0412 - accuracy: 0.9964 - val_loss: 5.7107 - val_accuracy: 0.8714\nEpoch 37/60\n52/52 [==============================] - 15s 297ms/step - loss: 2.8979e-04 - accuracy: 1.0000 - val_loss: 5.9007 - val_accuracy: 0.8732\nEpoch 38/60\n52/52 [==============================] - 20s 379ms/step - loss: 4.7809e-06 - accuracy: 1.0000 - val_loss: 5.9273 - val_accuracy: 0.8723\nEpoch 39/60\n52/52 [==============================] - 20s 379ms/step - loss: 1.9236e-06 - accuracy: 1.0000 - val_loss: 5.9379 - val_accuracy: 0.8723\nEpoch 40/60\n52/52 [==============================] - 20s 379ms/step - loss: 1.3421e-06 - accuracy: 1.0000 - val_loss: 5.9427 - val_accuracy: 0.8723\nEpoch 41/60\n52/52 [==============================] - 20s 379ms/step - loss: 1.1022e-06 - accuracy: 1.0000 - val_loss: 5.9520 - val_accuracy: 0.8723\nEpoch 42/60\n52/52 [==============================] - 20s 379ms/step - loss: 8.4298e-07 - accuracy: 1.0000 - val_loss: 5.9566 - val_accuracy: 0.8732\nEpoch 43/60\n52/52 [==============================] - 20s 379ms/step - loss: 7.1659e-07 - accuracy: 1.0000 - val_loss: 5.9592 - val_accuracy: 0.8732\nEpoch 44/60\n52/52 [==============================] - 15s 297ms/step - loss: 6.4216e-07 - accuracy: 1.0000 - val_loss: 5.9649 - val_accuracy: 0.8723\nEpoch 45/60\n52/52 [==============================] - 20s 379ms/step - loss: 5.4810e-07 - accuracy: 1.0000 - val_loss: 5.9680 - val_accuracy: 0.8723\nEpoch 46/60\n52/52 [==============================] - 20s 379ms/step - loss: 4.9408e-07 - accuracy: 1.0000 - val_loss: 5.9712 - val_accuracy: 0.8723\nEpoch 47/60\n52/52 [==============================] - 15s 298ms/step - loss: 4.4524e-07 - accuracy: 1.0000 - val_loss: 5.9736 - val_accuracy: 0.8723\nEpoch 48/60\n52/52 [==============================] - 20s 379ms/step - loss: 4.1085e-07 - accuracy: 1.0000 - val_loss: 5.9767 - val_accuracy: 0.8723\nEpoch 49/60\n52/52 [==============================] - 15s 297ms/step - loss: 3.7416e-07 - accuracy: 1.0000 - val_loss: 5.9788 - val_accuracy: 0.8723\nEpoch 50/60\n52/52 [==============================] - 20s 379ms/step - loss: 3.4639e-07 - accuracy: 1.0000 - val_loss: 5.9813 - val_accuracy: 0.8723\nEpoch 51/60\n52/52 [==============================] - 20s 379ms/step - loss: 3.2286e-07 - accuracy: 1.0000 - val_loss: 5.9836 - val_accuracy: 0.8723\nEpoch 52/60\n52/52 [==============================] - 15s 297ms/step - loss: 3.0163e-07 - accuracy: 1.0000 - val_loss: 5.9851 - val_accuracy: 0.8723\nEpoch 53/60\n52/52 [==============================] - 20s 379ms/step - loss: 2.8336e-07 - accuracy: 1.0000 - val_loss: 5.9866 - val_accuracy: 0.8723\nEpoch 54/60\n52/52 [==============================] - 15s 298ms/step - loss: 2.6695e-07 - accuracy: 1.0000 - val_loss: 5.9879 - val_accuracy: 0.8723\nEpoch 55/60\n52/52 [==============================] - 15s 296ms/step - loss: 2.4918e-07 - accuracy: 1.0000 - val_loss: 5.9920 - val_accuracy: 0.8723\nEpoch 56/60\n52/52 [==============================] - 20s 379ms/step - loss: 2.3500e-07 - accuracy: 1.0000 - val_loss: 5.9937 - val_accuracy: 0.8723\nEpoch 57/60\n52/52 [==============================] - 20s 379ms/step - loss: 2.2392e-07 - accuracy: 1.0000 - val_loss: 5.9938 - val_accuracy: 0.8723\nEpoch 58/60\n52/52 [==============================] - 20s 379ms/step - loss: 2.1025e-07 - accuracy: 1.0000 - val_loss: 5.9970 - val_accuracy: 0.8714\nEpoch 59/60\n52/52 [==============================] - 15s 297ms/step - loss: 2.0168e-07 - accuracy: 1.0000 - val_loss: 5.9989 - val_accuracy: 0.8714\nEpoch 60/60\n52/52 [==============================] - 19s 379ms/step - loss: 1.9333e-07 - accuracy: 1.0000 - val_loss: 6.0003 - val_accuracy: 0.8714\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f57a026d120>"},"metadata":{}}]},{"cell_type":"markdown","source":"### EfficientNet B0","metadata":{}},{"cell_type":"code","source":"enb0_wo_top = keras.applications.efficientnet.EfficientNetB0(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n\nenb0_wo_top.trainable = False\n\nenb0_model = keras.models.Sequential()\nenb0_model.add(enb0_wo_top)\nenb0_model.add(keras.layers.Flatten())\nenb0_model.add(keras.layers.Dense(128, activation='relu'))\nenb0_model.add(keras.layers.Dense(64, activation='relu'))\nenb0_model.add(keras.layers.Dense(8, activation='softmax'))\n\nenb0_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n\nenb0_model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T00:53:36.425892Z","iopub.execute_input":"2023-08-11T00:53:36.426255Z","iopub.status.idle":"2023-08-11T01:03:09.712535Z","shell.execute_reply.started":"2023-08-11T00:53:36.426226Z","shell.execute_reply":"2023-08-11T01:03:09.711369Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n16705208/16705208 [==============================] - 0s 0us/step\nEpoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"2023-08-11 00:53:47.451571: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_3/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"52/52 [==============================] - 20s 245ms/step - loss: 12.5812 - accuracy: 0.7349 - val_loss: 5.9981 - val_accuracy: 0.8623\nEpoch 2/60\n52/52 [==============================] - 7s 143ms/step - loss: 3.4978 - accuracy: 0.7844 - val_loss: 1.5505 - val_accuracy: 0.7428\nEpoch 3/60\n52/52 [==============================] - 7s 144ms/step - loss: 2.5675 - accuracy: 0.7886 - val_loss: 2.1565 - val_accuracy: 0.8623\nEpoch 4/60\n52/52 [==============================] - 10s 190ms/step - loss: 2.2960 - accuracy: 0.7965 - val_loss: 1.2116 - val_accuracy: 0.8542\nEpoch 5/60\n52/52 [==============================] - 7s 145ms/step - loss: 0.8258 - accuracy: 0.8502 - val_loss: 0.7914 - val_accuracy: 0.8071\nEpoch 6/60\n52/52 [==============================] - 10s 190ms/step - loss: 1.3773 - accuracy: 0.8164 - val_loss: 2.0635 - val_accuracy: 0.8261\nEpoch 7/60\n52/52 [==============================] - 7s 144ms/step - loss: 1.7968 - accuracy: 0.8098 - val_loss: 1.3142 - val_accuracy: 0.8632\nEpoch 8/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.8450 - accuracy: 0.8382 - val_loss: 0.6779 - val_accuracy: 0.8207\nEpoch 9/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.5665 - accuracy: 0.8635 - val_loss: 0.9647 - val_accuracy: 0.7672\nEpoch 10/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.5277 - accuracy: 0.8702 - val_loss: 0.6248 - val_accuracy: 0.8587\nEpoch 11/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.8610 - accuracy: 0.8321 - val_loss: 0.9524 - val_accuracy: 0.7654\nEpoch 12/60\n52/52 [==============================] - 7s 145ms/step - loss: 0.4553 - accuracy: 0.8877 - val_loss: 0.7321 - val_accuracy: 0.8650\nEpoch 13/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.6960 - accuracy: 0.8593 - val_loss: 0.9638 - val_accuracy: 0.7826\nEpoch 14/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.5124 - accuracy: 0.8786 - val_loss: 0.8946 - val_accuracy: 0.8623\nEpoch 15/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.6647 - accuracy: 0.8647 - val_loss: 1.0585 - val_accuracy: 0.8678\nEpoch 16/60\n52/52 [==============================] - 10s 192ms/step - loss: 0.4579 - accuracy: 0.8877 - val_loss: 0.6494 - val_accuracy: 0.8696\nEpoch 17/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.3756 - accuracy: 0.8986 - val_loss: 0.9730 - val_accuracy: 0.7020\nEpoch 18/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.3101 - accuracy: 0.9130 - val_loss: 0.8455 - val_accuracy: 0.8487\nEpoch 19/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.6036 - accuracy: 0.8720 - val_loss: 0.6630 - val_accuracy: 0.8650\nEpoch 20/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.3219 - accuracy: 0.9136 - val_loss: 0.8913 - val_accuracy: 0.7627\nEpoch 21/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.3364 - accuracy: 0.8949 - val_loss: 0.6758 - val_accuracy: 0.8053\nEpoch 22/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.3387 - accuracy: 0.8992 - val_loss: 0.7043 - val_accuracy: 0.8668\nEpoch 23/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.3931 - accuracy: 0.8925 - val_loss: 0.7319 - val_accuracy: 0.8705\nEpoch 24/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.2815 - accuracy: 0.9106 - val_loss: 0.8182 - val_accuracy: 0.8406\nEpoch 25/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.3135 - accuracy: 0.9155 - val_loss: 0.8512 - val_accuracy: 0.8696\nEpoch 26/60\n52/52 [==============================] - 10s 193ms/step - loss: 0.3235 - accuracy: 0.9136 - val_loss: 1.1066 - val_accuracy: 0.7482\nEpoch 27/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.4723 - accuracy: 0.8792 - val_loss: 1.0082 - val_accuracy: 0.7065\nEpoch 28/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.2772 - accuracy: 0.9227 - val_loss: 0.9453 - val_accuracy: 0.7880\nEpoch 29/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.2646 - accuracy: 0.9215 - val_loss: 0.6099 - val_accuracy: 0.8678\nEpoch 30/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.1797 - accuracy: 0.9414 - val_loss: 0.6259 - val_accuracy: 0.8714\nEpoch 31/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.3863 - accuracy: 0.9136 - val_loss: 0.9441 - val_accuracy: 0.8569\nEpoch 32/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.3864 - accuracy: 0.8937 - val_loss: 1.0123 - val_accuracy: 0.7210\nEpoch 33/60\n52/52 [==============================] - 10s 192ms/step - loss: 0.1900 - accuracy: 0.9450 - val_loss: 0.5991 - val_accuracy: 0.8668\nEpoch 34/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.1878 - accuracy: 0.9444 - val_loss: 1.3704 - val_accuracy: 0.5824\nEpoch 35/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.2785 - accuracy: 0.9227 - val_loss: 0.7956 - val_accuracy: 0.8306\nEpoch 36/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.2330 - accuracy: 0.9233 - val_loss: 0.8299 - val_accuracy: 0.7382\nEpoch 37/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.1615 - accuracy: 0.9511 - val_loss: 0.7837 - val_accuracy: 0.7636\nEpoch 38/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.1879 - accuracy: 0.9384 - val_loss: 0.6670 - val_accuracy: 0.8451\nEpoch 39/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.1627 - accuracy: 0.9450 - val_loss: 0.6835 - val_accuracy: 0.8569\nEpoch 40/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.2334 - accuracy: 0.9348 - val_loss: 0.7590 - val_accuracy: 0.8614\nEpoch 41/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.2141 - accuracy: 0.9384 - val_loss: 1.0296 - val_accuracy: 0.7726\nEpoch 42/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.2167 - accuracy: 0.9378 - val_loss: 0.8486 - val_accuracy: 0.7681\nEpoch 43/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.1913 - accuracy: 0.9396 - val_loss: 0.8339 - val_accuracy: 0.8361\nEpoch 44/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.1723 - accuracy: 0.9420 - val_loss: 0.7509 - val_accuracy: 0.8306\nEpoch 45/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.2003 - accuracy: 0.9342 - val_loss: 0.6302 - val_accuracy: 0.8623\nEpoch 46/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.1449 - accuracy: 0.9535 - val_loss: 0.6565 - val_accuracy: 0.8306\nEpoch 47/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.0935 - accuracy: 0.9686 - val_loss: 0.6716 - val_accuracy: 0.8596\nEpoch 48/60\n52/52 [==============================] - 7s 145ms/step - loss: 0.0900 - accuracy: 0.9698 - val_loss: 0.7063 - val_accuracy: 0.8288\nEpoch 49/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.1272 - accuracy: 0.9595 - val_loss: 0.6722 - val_accuracy: 0.8668\nEpoch 50/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.1233 - accuracy: 0.9656 - val_loss: 0.8969 - val_accuracy: 0.8225\nEpoch 51/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.2243 - accuracy: 0.9396 - val_loss: 0.7433 - val_accuracy: 0.8533\nEpoch 52/60\n52/52 [==============================] - 10s 192ms/step - loss: 0.4188 - accuracy: 0.9022 - val_loss: 0.9197 - val_accuracy: 0.8388\nEpoch 53/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.2757 - accuracy: 0.9287 - val_loss: 0.7341 - val_accuracy: 0.8306\nEpoch 54/60\n52/52 [==============================] - 7s 142ms/step - loss: 0.1932 - accuracy: 0.9432 - val_loss: 0.7356 - val_accuracy: 0.8696\nEpoch 55/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.1219 - accuracy: 0.9571 - val_loss: 0.6577 - val_accuracy: 0.8732\nEpoch 56/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.3323 - accuracy: 0.9221 - val_loss: 1.1661 - val_accuracy: 0.8678\nEpoch 57/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.4486 - accuracy: 0.8967 - val_loss: 0.8869 - val_accuracy: 0.8641\nEpoch 58/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.3587 - accuracy: 0.9191 - val_loss: 0.8122 - val_accuracy: 0.8379\nEpoch 59/60\n52/52 [==============================] - 10s 192ms/step - loss: 0.3870 - accuracy: 0.9124 - val_loss: 0.9927 - val_accuracy: 0.7518\nEpoch 60/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.3268 - accuracy: 0.9136 - val_loss: 0.7941 - val_accuracy: 0.8696\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f57984f0d00>"},"metadata":{}}]},{"cell_type":"markdown","source":"### EfficientNet B1","metadata":{}},{"cell_type":"code","source":"enb1_wo_top = keras.applications.efficientnet.EfficientNetB1(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n\nenb1_wo_top.trainable = False\n\nenb1_model = keras.models.Sequential()\nenb1_model.add(enb1_wo_top)\nenb1_model.add(keras.layers.Flatten())\nenb1_model.add(keras.layers.Dense(128, activation='relu'))\nenb1_model.add(keras.layers.Dense(64, activation='relu'))\nenb1_model.add(keras.layers.Dense(8, activation='softmax'))\n\nenb1_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n\nenb1_model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T01:03:09.718544Z","iopub.execute_input":"2023-08-11T01:03:09.718844Z","iopub.status.idle":"2023-08-11T01:14:47.153740Z","shell.execute_reply.started":"2023-08-11T01:03:09.718817Z","shell.execute_reply":"2023-08-11T01:14:47.152673Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n27018416/27018416 [==============================] - 0s 0us/step\nEpoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"2023-08-11 01:03:24.740633: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_4/efficientnetb1/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"52/52 [==============================] - 25s 280ms/step - loss: 9.2369 - accuracy: 0.7530 - val_loss: 3.4439 - val_accuracy: 0.8623\nEpoch 2/60\n52/52 [==============================] - 12s 224ms/step - loss: 1.9396 - accuracy: 0.7880 - val_loss: 1.5327 - val_accuracy: 0.8623\nEpoch 3/60\n52/52 [==============================] - 12s 226ms/step - loss: 1.3527 - accuracy: 0.8116 - val_loss: 0.8456 - val_accuracy: 0.8659\nEpoch 4/60\n52/52 [==============================] - 10s 196ms/step - loss: 1.6695 - accuracy: 0.8098 - val_loss: 1.1626 - val_accuracy: 0.8505\nEpoch 5/60\n52/52 [==============================] - 12s 223ms/step - loss: 1.6285 - accuracy: 0.7965 - val_loss: 1.7323 - val_accuracy: 0.8614\nEpoch 6/60\n52/52 [==============================] - 12s 224ms/step - loss: 2.1768 - accuracy: 0.7893 - val_loss: 2.2541 - val_accuracy: 0.5797\nEpoch 7/60\n52/52 [==============================] - 12s 224ms/step - loss: 1.6400 - accuracy: 0.8116 - val_loss: 1.0898 - val_accuracy: 0.8614\nEpoch 8/60\n52/52 [==============================] - 10s 197ms/step - loss: 0.7120 - accuracy: 0.8448 - val_loss: 1.5570 - val_accuracy: 0.6431\nEpoch 9/60\n52/52 [==============================] - 12s 224ms/step - loss: 0.8300 - accuracy: 0.8490 - val_loss: 0.7401 - val_accuracy: 0.8659\nEpoch 10/60\n52/52 [==============================] - 12s 224ms/step - loss: 0.9633 - accuracy: 0.8243 - val_loss: 0.5441 - val_accuracy: 0.8650\nEpoch 11/60\n52/52 [==============================] - 10s 197ms/step - loss: 0.5158 - accuracy: 0.8665 - val_loss: 0.6123 - val_accuracy: 0.8668\nEpoch 12/60\n52/52 [==============================] - 10s 196ms/step - loss: 0.5534 - accuracy: 0.8569 - val_loss: 1.0241 - val_accuracy: 0.8424\nEpoch 13/60\n52/52 [==============================] - 12s 223ms/step - loss: 0.5560 - accuracy: 0.8581 - val_loss: 0.9939 - val_accuracy: 0.8659\nEpoch 14/60\n52/52 [==============================] - 10s 197ms/step - loss: 0.7019 - accuracy: 0.8514 - val_loss: 0.6159 - val_accuracy: 0.8641\nEpoch 15/60\n52/52 [==============================] - 12s 223ms/step - loss: 0.5133 - accuracy: 0.8665 - val_loss: 0.7050 - val_accuracy: 0.8668\nEpoch 16/60\n52/52 [==============================] - 12s 224ms/step - loss: 0.5000 - accuracy: 0.8647 - val_loss: 0.7008 - val_accuracy: 0.8279\nEpoch 17/60\n52/52 [==============================] - 12s 225ms/step - loss: 0.5637 - accuracy: 0.8671 - val_loss: 0.7767 - val_accuracy: 0.8705\nEpoch 18/60\n52/52 [==============================] - 12s 224ms/step - loss: 0.4680 - accuracy: 0.8768 - val_loss: 0.6935 - val_accuracy: 0.7880\nEpoch 19/60\n52/52 [==============================] - 12s 224ms/step - loss: 0.4378 - accuracy: 0.8822 - val_loss: 1.1415 - val_accuracy: 0.8641\nEpoch 20/60\n52/52 [==============================] - 12s 225ms/step - loss: 0.5255 - accuracy: 0.8762 - val_loss: 0.5897 - val_accuracy: 0.8687\nEpoch 21/60\n52/52 [==============================] - 10s 196ms/step - loss: 0.4198 - accuracy: 0.8877 - val_loss: 1.9424 - val_accuracy: 0.4230\nEpoch 22/60\n52/52 [==============================] - 12s 224ms/step - loss: 0.6175 - accuracy: 0.8641 - val_loss: 0.5728 - val_accuracy: 0.8514\nEpoch 23/60\n52/52 [==============================] - 12s 224ms/step - loss: 0.3538 - accuracy: 0.8955 - val_loss: 0.6565 - val_accuracy: 0.8641\nEpoch 24/60\n52/52 [==============================] - 12s 223ms/step - loss: 0.3258 - accuracy: 0.9016 - val_loss: 0.5687 - val_accuracy: 0.8678\nEpoch 25/60\n52/52 [==============================] - 12s 224ms/step - loss: 0.3736 - accuracy: 0.8847 - val_loss: 0.8306 - val_accuracy: 0.7591\nEpoch 26/60\n52/52 [==============================] - 10s 195ms/step - loss: 0.3713 - accuracy: 0.8937 - val_loss: 0.5780 - val_accuracy: 0.8225\nEpoch 27/60\n52/52 [==============================] - 10s 195ms/step - loss: 0.3447 - accuracy: 0.8967 - val_loss: 0.7393 - val_accuracy: 0.7464\nEpoch 28/60\n52/52 [==============================] - 10s 196ms/step - loss: 0.4756 - accuracy: 0.8635 - val_loss: 1.0107 - val_accuracy: 0.8650\nEpoch 29/60\n52/52 [==============================] - 12s 224ms/step - loss: 0.3290 - accuracy: 0.8949 - val_loss: 0.5568 - val_accuracy: 0.8496\nEpoch 30/60\n52/52 [==============================] - 10s 196ms/step - loss: 0.2815 - accuracy: 0.9191 - val_loss: 0.5570 - val_accuracy: 0.8650\nEpoch 31/60\n52/52 [==============================] - 10s 197ms/step - loss: 0.3142 - accuracy: 0.9082 - val_loss: 0.5118 - val_accuracy: 0.8569\nEpoch 32/60\n52/52 [==============================] - 12s 223ms/step - loss: 0.3552 - accuracy: 0.8973 - val_loss: 0.8151 - val_accuracy: 0.8668\nEpoch 33/60\n52/52 [==============================] - 12s 224ms/step - loss: 0.3407 - accuracy: 0.9022 - val_loss: 0.5770 - val_accuracy: 0.8659\nEpoch 34/60\n52/52 [==============================] - 12s 224ms/step - loss: 0.2879 - accuracy: 0.9094 - val_loss: 0.5630 - val_accuracy: 0.8424\nEpoch 35/60\n52/52 [==============================] - 12s 223ms/step - loss: 0.3070 - accuracy: 0.9010 - val_loss: 0.5943 - val_accuracy: 0.8514\nEpoch 36/60\n52/52 [==============================] - 12s 223ms/step - loss: 0.2975 - accuracy: 0.8943 - val_loss: 0.7254 - val_accuracy: 0.8668\nEpoch 37/60\n52/52 [==============================] - 12s 225ms/step - loss: 0.3174 - accuracy: 0.9106 - val_loss: 0.5915 - val_accuracy: 0.8732\nEpoch 38/60\n52/52 [==============================] - 10s 196ms/step - loss: 0.2955 - accuracy: 0.9106 - val_loss: 0.5511 - val_accuracy: 0.8632\nEpoch 39/60\n52/52 [==============================] - 12s 223ms/step - loss: 0.2926 - accuracy: 0.9106 - val_loss: 0.5400 - val_accuracy: 0.8696\nEpoch 40/60\n52/52 [==============================] - 12s 225ms/step - loss: 0.4074 - accuracy: 0.8961 - val_loss: 1.1228 - val_accuracy: 0.6812\nEpoch 41/60\n52/52 [==============================] - 10s 195ms/step - loss: 0.4643 - accuracy: 0.8829 - val_loss: 0.6278 - val_accuracy: 0.8759\nEpoch 42/60\n52/52 [==============================] - 10s 196ms/step - loss: 0.2696 - accuracy: 0.9143 - val_loss: 0.5741 - val_accuracy: 0.8442\nEpoch 43/60\n52/52 [==============================] - 10s 197ms/step - loss: 0.3180 - accuracy: 0.9028 - val_loss: 0.4972 - val_accuracy: 0.8668\nEpoch 44/60\n52/52 [==============================] - 10s 195ms/step - loss: 0.2304 - accuracy: 0.9287 - val_loss: 0.7916 - val_accuracy: 0.8650\nEpoch 45/60\n52/52 [==============================] - 10s 196ms/step - loss: 0.3489 - accuracy: 0.9028 - val_loss: 0.7331 - val_accuracy: 0.8641\nEpoch 46/60\n52/52 [==============================] - 10s 197ms/step - loss: 0.3872 - accuracy: 0.8949 - val_loss: 0.4979 - val_accuracy: 0.8641\nEpoch 47/60\n52/52 [==============================] - 12s 223ms/step - loss: 0.2326 - accuracy: 0.9263 - val_loss: 0.5431 - val_accuracy: 0.8750\nEpoch 48/60\n52/52 [==============================] - 10s 196ms/step - loss: 0.2806 - accuracy: 0.9143 - val_loss: 0.5832 - val_accuracy: 0.8062\nEpoch 49/60\n52/52 [==============================] - 10s 197ms/step - loss: 0.2525 - accuracy: 0.9197 - val_loss: 0.6057 - val_accuracy: 0.8098\nEpoch 50/60\n52/52 [==============================] - 10s 196ms/step - loss: 0.1989 - accuracy: 0.9414 - val_loss: 0.5123 - val_accuracy: 0.8668\nEpoch 51/60\n52/52 [==============================] - 10s 195ms/step - loss: 0.2360 - accuracy: 0.9185 - val_loss: 0.4826 - val_accuracy: 0.8587\nEpoch 52/60\n52/52 [==============================] - 10s 198ms/step - loss: 0.3287 - accuracy: 0.9058 - val_loss: 0.6167 - val_accuracy: 0.8678\nEpoch 53/60\n52/52 [==============================] - 10s 196ms/step - loss: 0.2788 - accuracy: 0.9136 - val_loss: 0.5063 - val_accuracy: 0.8659\nEpoch 54/60\n52/52 [==============================] - 12s 224ms/step - loss: 0.2922 - accuracy: 0.9106 - val_loss: 0.7076 - val_accuracy: 0.8361\nEpoch 55/60\n52/52 [==============================] - 10s 197ms/step - loss: 0.3034 - accuracy: 0.9046 - val_loss: 0.5815 - val_accuracy: 0.8723\nEpoch 56/60\n52/52 [==============================] - 10s 195ms/step - loss: 0.2841 - accuracy: 0.9149 - val_loss: 0.5394 - val_accuracy: 0.8705\nEpoch 57/60\n52/52 [==============================] - 10s 195ms/step - loss: 0.2874 - accuracy: 0.8992 - val_loss: 0.6161 - val_accuracy: 0.8569\nEpoch 58/60\n52/52 [==============================] - 12s 225ms/step - loss: 0.1970 - accuracy: 0.9360 - val_loss: 0.4948 - val_accuracy: 0.8632\nEpoch 59/60\n52/52 [==============================] - 10s 195ms/step - loss: 0.1907 - accuracy: 0.9384 - val_loss: 0.4759 - val_accuracy: 0.8678\nEpoch 60/60\n52/52 [==============================] - 11s 223ms/step - loss: 0.2213 - accuracy: 0.9293 - val_loss: 0.7020 - val_accuracy: 0.8261\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f57999bda20>"},"metadata":{}}]},{"cell_type":"markdown","source":"### EfficientNet B2","metadata":{}},{"cell_type":"code","source":"enb2_wo_top = keras.applications.efficientnet.EfficientNetB2(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n\nenb2_wo_top.trainable = False\n\nenb2_model = keras.models.Sequential()\nenb2_model.add(enb0_wo_top)\nenb2_model.add(keras.layers.Flatten())\nenb2_model.add(keras.layers.Dense(128, activation='relu'))\nenb2_model.add(keras.layers.Dense(64, activation='relu'))\nenb2_model.add(keras.layers.Dense(8, activation='softmax'))\n\nenb2_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n\nenb2_model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T01:14:47.155569Z","iopub.execute_input":"2023-08-11T01:14:47.156298Z","iopub.status.idle":"2023-08-11T01:24:21.949295Z","shell.execute_reply.started":"2023-08-11T01:14:47.156246Z","shell.execute_reply":"2023-08-11T01:24:21.948154Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n31790344/31790344 [==============================] - 0s 0us/step\nEpoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"2023-08-11 01:14:59.692404: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_5/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"52/52 [==============================] - 17s 188ms/step - loss: 10.8253 - accuracy: 0.7289 - val_loss: 5.1288 - val_accuracy: 0.8614\nEpoch 2/60\n52/52 [==============================] - 7s 143ms/step - loss: 2.5622 - accuracy: 0.7947 - val_loss: 1.5437 - val_accuracy: 0.8623\nEpoch 3/60\n52/52 [==============================] - 7s 144ms/step - loss: 2.3465 - accuracy: 0.7953 - val_loss: 1.2708 - val_accuracy: 0.8569\nEpoch 4/60\n52/52 [==============================] - 10s 192ms/step - loss: 1.0498 - accuracy: 0.8382 - val_loss: 0.7056 - val_accuracy: 0.8623\nEpoch 5/60\n52/52 [==============================] - 7s 143ms/step - loss: 1.1153 - accuracy: 0.8134 - val_loss: 0.7852 - val_accuracy: 0.8659\nEpoch 6/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.6018 - accuracy: 0.8460 - val_loss: 0.6923 - val_accuracy: 0.8505\nEpoch 7/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.6081 - accuracy: 0.8502 - val_loss: 0.8580 - val_accuracy: 0.8623\nEpoch 8/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.5680 - accuracy: 0.8521 - val_loss: 0.7995 - val_accuracy: 0.7980\nEpoch 9/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.6410 - accuracy: 0.8702 - val_loss: 1.7135 - val_accuracy: 0.5643\nEpoch 10/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.5287 - accuracy: 0.8750 - val_loss: 0.7154 - val_accuracy: 0.8505\nEpoch 11/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.5464 - accuracy: 0.8720 - val_loss: 0.5762 - val_accuracy: 0.8623\nEpoch 12/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.6848 - accuracy: 0.8569 - val_loss: 0.5603 - val_accuracy: 0.8641\nEpoch 13/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.5163 - accuracy: 0.8732 - val_loss: 0.5736 - val_accuracy: 0.8578\nEpoch 14/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.3720 - accuracy: 0.8901 - val_loss: 0.5551 - val_accuracy: 0.8623\nEpoch 15/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.3850 - accuracy: 0.8877 - val_loss: 0.5228 - val_accuracy: 0.8560\nEpoch 16/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.3878 - accuracy: 0.8955 - val_loss: 0.6225 - val_accuracy: 0.8514\nEpoch 17/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.4075 - accuracy: 0.8859 - val_loss: 0.7001 - val_accuracy: 0.8107\nEpoch 18/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.4196 - accuracy: 0.8865 - val_loss: 0.5464 - val_accuracy: 0.8514\nEpoch 19/60\n52/52 [==============================] - 10s 192ms/step - loss: 0.3786 - accuracy: 0.8865 - val_loss: 0.5702 - val_accuracy: 0.8587\nEpoch 20/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.3295 - accuracy: 0.9070 - val_loss: 0.6828 - val_accuracy: 0.8632\nEpoch 21/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.3085 - accuracy: 0.9100 - val_loss: 0.5336 - val_accuracy: 0.8678\nEpoch 22/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.3353 - accuracy: 0.9010 - val_loss: 0.7243 - val_accuracy: 0.8623\nEpoch 23/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.2827 - accuracy: 0.9082 - val_loss: 0.5323 - val_accuracy: 0.8496\nEpoch 24/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.3316 - accuracy: 0.8992 - val_loss: 0.7949 - val_accuracy: 0.8659\nEpoch 25/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.4512 - accuracy: 0.8871 - val_loss: 0.9610 - val_accuracy: 0.7219\nEpoch 26/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.3820 - accuracy: 0.8949 - val_loss: 1.1485 - val_accuracy: 0.6458\nEpoch 27/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.3211 - accuracy: 0.9004 - val_loss: 0.6291 - val_accuracy: 0.8379\nEpoch 28/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.2724 - accuracy: 0.9179 - val_loss: 0.6078 - val_accuracy: 0.8596\nEpoch 29/60\n52/52 [==============================] - 10s 192ms/step - loss: 0.2390 - accuracy: 0.9269 - val_loss: 0.5513 - val_accuracy: 0.8614\nEpoch 30/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.3021 - accuracy: 0.9143 - val_loss: 0.5907 - val_accuracy: 0.8668\nEpoch 31/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.1930 - accuracy: 0.9414 - val_loss: 0.5387 - val_accuracy: 0.8496\nEpoch 32/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.2435 - accuracy: 0.9209 - val_loss: 0.5668 - val_accuracy: 0.8750\nEpoch 33/60\n52/52 [==============================] - 10s 192ms/step - loss: 0.3176 - accuracy: 0.9028 - val_loss: 0.8583 - val_accuracy: 0.7255\nEpoch 34/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.3396 - accuracy: 0.9052 - val_loss: 0.6465 - val_accuracy: 0.7880\nEpoch 35/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.2550 - accuracy: 0.9227 - val_loss: 0.6210 - val_accuracy: 0.8261\nEpoch 36/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.2633 - accuracy: 0.9179 - val_loss: 0.5846 - val_accuracy: 0.8415\nEpoch 37/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.2173 - accuracy: 0.9269 - val_loss: 0.6750 - val_accuracy: 0.8071\nEpoch 38/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.2500 - accuracy: 0.9318 - val_loss: 0.6296 - val_accuracy: 0.8361\nEpoch 39/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.2130 - accuracy: 0.9354 - val_loss: 0.5669 - val_accuracy: 0.8759\nEpoch 40/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.1586 - accuracy: 0.9499 - val_loss: 0.5879 - val_accuracy: 0.8569\nEpoch 41/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.1563 - accuracy: 0.9481 - val_loss: 0.5869 - val_accuracy: 0.8243\nEpoch 42/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.1946 - accuracy: 0.9420 - val_loss: 0.6730 - val_accuracy: 0.8234\nEpoch 43/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.1690 - accuracy: 0.9505 - val_loss: 0.5427 - val_accuracy: 0.8587\nEpoch 44/60\n52/52 [==============================] - 7s 145ms/step - loss: 0.1574 - accuracy: 0.9481 - val_loss: 0.7514 - val_accuracy: 0.8678\nEpoch 45/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.2872 - accuracy: 0.9191 - val_loss: 0.8041 - val_accuracy: 0.8125\nEpoch 46/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.1987 - accuracy: 0.9384 - val_loss: 0.5847 - val_accuracy: 0.8678\nEpoch 47/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.2156 - accuracy: 0.9318 - val_loss: 0.8122 - val_accuracy: 0.8605\nEpoch 48/60\n52/52 [==============================] - 10s 192ms/step - loss: 0.1492 - accuracy: 0.9541 - val_loss: 0.6506 - val_accuracy: 0.8705\nEpoch 49/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.1325 - accuracy: 0.9577 - val_loss: 0.5576 - val_accuracy: 0.8650\nEpoch 50/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.2460 - accuracy: 0.9318 - val_loss: 0.7768 - val_accuracy: 0.8451\nEpoch 51/60\n52/52 [==============================] - 7s 145ms/step - loss: 0.1747 - accuracy: 0.9432 - val_loss: 0.6696 - val_accuracy: 0.8696\nEpoch 52/60\n52/52 [==============================] - 10s 190ms/step - loss: 0.1682 - accuracy: 0.9487 - val_loss: 0.7622 - val_accuracy: 0.7944\nEpoch 53/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.1271 - accuracy: 0.9601 - val_loss: 0.6015 - val_accuracy: 0.8687\nEpoch 54/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.1579 - accuracy: 0.9463 - val_loss: 0.6487 - val_accuracy: 0.8533\nEpoch 55/60\n52/52 [==============================] - 7s 145ms/step - loss: 0.1552 - accuracy: 0.9499 - val_loss: 0.6148 - val_accuracy: 0.8723\nEpoch 56/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.3577 - accuracy: 0.8955 - val_loss: 0.6864 - val_accuracy: 0.8306\nEpoch 57/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.2030 - accuracy: 0.9378 - val_loss: 0.5647 - val_accuracy: 0.8650\nEpoch 58/60\n52/52 [==============================] - 7s 143ms/step - loss: 0.1633 - accuracy: 0.9481 - val_loss: 0.7668 - val_accuracy: 0.8496\nEpoch 59/60\n52/52 [==============================] - 10s 191ms/step - loss: 0.1232 - accuracy: 0.9601 - val_loss: 1.1791 - val_accuracy: 0.6975\nEpoch 60/60\n52/52 [==============================] - 7s 144ms/step - loss: 0.2627 - accuracy: 0.9233 - val_loss: 0.7856 - val_accuracy: 0.8433\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f5798961cf0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### EfficientNet B3","metadata":{}},{"cell_type":"code","source":"enb3_wo_top = keras.applications.efficientnet.EfficientNetB3(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n\nenb3_wo_top.trainable = False\n\nenb3_model = keras.models.Sequential()\nenb3_model.add(enb3_wo_top)\nenb3_model.add(keras.layers.Flatten())\nenb3_model.add(keras.layers.Dense(128, activation='relu'))\nenb3_model.add(keras.layers.Dense(64, activation='relu'))\nenb3_model.add(keras.layers.Dense(8, activation='softmax'))\n\nenb3_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n\nenb3_model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T01:24:21.951009Z","iopub.execute_input":"2023-08-11T01:24:21.951381Z","iopub.status.idle":"2023-08-11T01:39:01.522937Z","shell.execute_reply.started":"2023-08-11T01:24:21.951346Z","shell.execute_reply":"2023-08-11T01:39:01.521894Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n43941136/43941136 [==============================] - 0s 0us/step\nEpoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"2023-08-11 01:24:39.048026: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_6/efficientnetb3/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"52/52 [==============================] - 30s 360ms/step - loss: 14.8258 - accuracy: 0.7313 - val_loss: 8.7515 - val_accuracy: 0.8587\nEpoch 2/60\n52/52 [==============================] - 14s 264ms/step - loss: 6.0250 - accuracy: 0.7766 - val_loss: 4.8063 - val_accuracy: 0.8614\nEpoch 3/60\n52/52 [==============================] - 14s 267ms/step - loss: 3.1304 - accuracy: 0.8062 - val_loss: 2.6281 - val_accuracy: 0.6984\nEpoch 4/60\n52/52 [==============================] - 14s 267ms/step - loss: 2.7779 - accuracy: 0.8056 - val_loss: 2.4533 - val_accuracy: 0.8614\nEpoch 5/60\n52/52 [==============================] - 14s 266ms/step - loss: 2.6368 - accuracy: 0.7953 - val_loss: 3.2888 - val_accuracy: 0.5589\nEpoch 6/60\n52/52 [==============================] - 14s 267ms/step - loss: 1.5596 - accuracy: 0.8225 - val_loss: 3.3345 - val_accuracy: 0.8605\nEpoch 7/60\n52/52 [==============================] - 14s 264ms/step - loss: 3.9429 - accuracy: 0.7760 - val_loss: 2.1902 - val_accuracy: 0.8623\nEpoch 8/60\n52/52 [==============================] - 14s 265ms/step - loss: 1.2761 - accuracy: 0.8279 - val_loss: 3.4734 - val_accuracy: 0.3089\nEpoch 9/60\n52/52 [==============================] - 14s 264ms/step - loss: 1.1358 - accuracy: 0.8412 - val_loss: 1.2939 - val_accuracy: 0.7781\nEpoch 10/60\n52/52 [==============================] - 14s 265ms/step - loss: 0.7388 - accuracy: 0.8508 - val_loss: 1.2057 - val_accuracy: 0.8659\nEpoch 11/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.8413 - accuracy: 0.8490 - val_loss: 0.9053 - val_accuracy: 0.7654\nEpoch 12/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.9779 - accuracy: 0.8357 - val_loss: 0.7396 - val_accuracy: 0.8505\nEpoch 13/60\n52/52 [==============================] - 14s 265ms/step - loss: 0.8063 - accuracy: 0.8424 - val_loss: 0.9785 - val_accuracy: 0.8433\nEpoch 14/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.8289 - accuracy: 0.8478 - val_loss: 1.0109 - val_accuracy: 0.8696\nEpoch 15/60\n52/52 [==============================] - 14s 267ms/step - loss: 0.5641 - accuracy: 0.8671 - val_loss: 0.8635 - val_accuracy: 0.8578\nEpoch 16/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.5306 - accuracy: 0.8738 - val_loss: 0.7233 - val_accuracy: 0.8578\nEpoch 17/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.4852 - accuracy: 0.8750 - val_loss: 0.6919 - val_accuracy: 0.8587\nEpoch 18/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.6857 - accuracy: 0.8726 - val_loss: 1.0972 - val_accuracy: 0.8179\nEpoch 19/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.6935 - accuracy: 0.8496 - val_loss: 0.7042 - val_accuracy: 0.8605\nEpoch 20/60\n52/52 [==============================] - 14s 267ms/step - loss: 0.3722 - accuracy: 0.8931 - val_loss: 0.8428 - val_accuracy: 0.8361\nEpoch 21/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.4695 - accuracy: 0.8847 - val_loss: 0.9741 - val_accuracy: 0.7056\nEpoch 22/60\n52/52 [==============================] - 14s 267ms/step - loss: 0.3880 - accuracy: 0.8859 - val_loss: 1.0461 - val_accuracy: 0.6984\nEpoch 23/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.3690 - accuracy: 0.8865 - val_loss: 0.6845 - val_accuracy: 0.8424\nEpoch 24/60\n52/52 [==============================] - 14s 265ms/step - loss: 0.3383 - accuracy: 0.9034 - val_loss: 0.8229 - val_accuracy: 0.8216\nEpoch 25/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.4694 - accuracy: 0.8750 - val_loss: 0.7239 - val_accuracy: 0.8569\nEpoch 26/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.4419 - accuracy: 0.8822 - val_loss: 0.9452 - val_accuracy: 0.7174\nEpoch 27/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.3833 - accuracy: 0.8877 - val_loss: 0.6206 - val_accuracy: 0.8370\nEpoch 28/60\n52/52 [==============================] - 14s 267ms/step - loss: 0.3726 - accuracy: 0.8955 - val_loss: 0.6152 - val_accuracy: 0.8732\nEpoch 29/60\n52/52 [==============================] - 14s 268ms/step - loss: 0.2942 - accuracy: 0.9064 - val_loss: 0.7597 - val_accuracy: 0.8641\nEpoch 30/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.5040 - accuracy: 0.8738 - val_loss: 0.6536 - val_accuracy: 0.8415\nEpoch 31/60\n52/52 [==============================] - 14s 265ms/step - loss: 0.2851 - accuracy: 0.9058 - val_loss: 0.5960 - val_accuracy: 0.8207\nEpoch 32/60\n52/52 [==============================] - 14s 265ms/step - loss: 0.2033 - accuracy: 0.9306 - val_loss: 0.7324 - val_accuracy: 0.7889\nEpoch 33/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.3017 - accuracy: 0.8955 - val_loss: 0.5977 - val_accuracy: 0.8388\nEpoch 34/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.2167 - accuracy: 0.9245 - val_loss: 0.5904 - val_accuracy: 0.8587\nEpoch 35/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.5089 - accuracy: 0.8738 - val_loss: 1.9237 - val_accuracy: 0.8632\nEpoch 36/60\n52/52 [==============================] - 14s 265ms/step - loss: 0.4947 - accuracy: 0.8780 - val_loss: 0.6946 - val_accuracy: 0.8632\nEpoch 37/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.5319 - accuracy: 0.8696 - val_loss: 0.6888 - val_accuracy: 0.8623\nEpoch 38/60\n52/52 [==============================] - 14s 267ms/step - loss: 0.3403 - accuracy: 0.9016 - val_loss: 0.6771 - val_accuracy: 0.8587\nEpoch 39/60\n52/52 [==============================] - 14s 267ms/step - loss: 0.2530 - accuracy: 0.9251 - val_loss: 0.6483 - val_accuracy: 0.8197\nEpoch 40/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.2328 - accuracy: 0.9197 - val_loss: 0.7954 - val_accuracy: 0.8279\nEpoch 41/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.2147 - accuracy: 0.9324 - val_loss: 0.6453 - val_accuracy: 0.8505\nEpoch 42/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.3193 - accuracy: 0.8967 - val_loss: 0.5719 - val_accuracy: 0.8342\nEpoch 43/60\n52/52 [==============================] - 14s 265ms/step - loss: 0.2840 - accuracy: 0.9124 - val_loss: 0.8214 - val_accuracy: 0.7917\nEpoch 44/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.2645 - accuracy: 0.9112 - val_loss: 0.6664 - val_accuracy: 0.8134\nEpoch 45/60\n52/52 [==============================] - 14s 267ms/step - loss: 0.2306 - accuracy: 0.9312 - val_loss: 0.6238 - val_accuracy: 0.8188\nEpoch 46/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.3016 - accuracy: 0.9052 - val_loss: 1.0136 - val_accuracy: 0.7092\nEpoch 47/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.2617 - accuracy: 0.9100 - val_loss: 0.7996 - val_accuracy: 0.7174\nEpoch 48/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.3005 - accuracy: 0.9088 - val_loss: 0.7159 - val_accuracy: 0.7817\nEpoch 49/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.3027 - accuracy: 0.9076 - val_loss: 0.5922 - val_accuracy: 0.8333\nEpoch 50/60\n52/52 [==============================] - 14s 268ms/step - loss: 0.2448 - accuracy: 0.9257 - val_loss: 0.5573 - val_accuracy: 0.8623\nEpoch 51/60\n52/52 [==============================] - 14s 267ms/step - loss: 0.2320 - accuracy: 0.9251 - val_loss: 0.6845 - val_accuracy: 0.8705\nEpoch 52/60\n52/52 [==============================] - 14s 267ms/step - loss: 0.2548 - accuracy: 0.9130 - val_loss: 0.6422 - val_accuracy: 0.7944\nEpoch 53/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.2429 - accuracy: 0.9197 - val_loss: 0.7564 - val_accuracy: 0.8596\nEpoch 54/60\n52/52 [==============================] - 14s 265ms/step - loss: 0.2793 - accuracy: 0.9143 - val_loss: 0.5057 - val_accuracy: 0.8542\nEpoch 55/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.1882 - accuracy: 0.9384 - val_loss: 0.7259 - val_accuracy: 0.7953\nEpoch 56/60\n52/52 [==============================] - 14s 265ms/step - loss: 0.2224 - accuracy: 0.9221 - val_loss: 0.6465 - val_accuracy: 0.8759\nEpoch 57/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.2105 - accuracy: 0.9275 - val_loss: 0.5549 - val_accuracy: 0.8678\nEpoch 58/60\n52/52 [==============================] - 14s 264ms/step - loss: 0.1972 - accuracy: 0.9287 - val_loss: 0.6093 - val_accuracy: 0.8678\nEpoch 59/60\n52/52 [==============================] - 14s 267ms/step - loss: 0.2408 - accuracy: 0.9167 - val_loss: 0.5524 - val_accuracy: 0.8551\nEpoch 60/60\n52/52 [==============================] - 14s 266ms/step - loss: 0.2342 - accuracy: 0.9257 - val_loss: 0.7127 - val_accuracy: 0.7817\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f53283fd240>"},"metadata":{}}]},{"cell_type":"markdown","source":"### EfficientNet B4","metadata":{}},{"cell_type":"code","source":"enb4_wo_top = keras.applications.efficientnet.EfficientNetB4(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n\nenb4_wo_top.trainable = False\n\nenb4_model = keras.models.Sequential()\nenb4_model.add(enb4_wo_top)\nenb4_model.add(keras.layers.Flatten())\nenb4_model.add(keras.layers.Dense(128, activation='relu'))\nenb4_model.add(keras.layers.Dense(64, activation='relu'))\nenb4_model.add(keras.layers.Dense(8, activation='softmax'))\n\nenb4_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n\nenb4_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T01:39:01.524754Z","iopub.execute_input":"2023-08-11T01:39:01.525159Z","iopub.status.idle":"2023-08-11T01:49:31.289274Z","shell.execute_reply.started":"2023-08-11T01:39:01.525121Z","shell.execute_reply":"2023-08-11T01:49:31.288155Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n71686520/71686520 [==============================] - 0s 0us/step\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2023-08-11 01:39:22.014788: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_7/efficientnetb4/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"52/52 [==============================] - 40s 506ms/step - loss: 14.2301 - accuracy: 0.7240 - val_loss: 7.3414 - val_accuracy: 0.7563\nEpoch 2/30\n52/52 [==============================] - 18s 352ms/step - loss: 4.5253 - accuracy: 0.7856 - val_loss: 1.7818 - val_accuracy: 0.7772\nEpoch 3/30\n52/52 [==============================] - 22s 423ms/step - loss: 1.9387 - accuracy: 0.8056 - val_loss: 2.8051 - val_accuracy: 0.5072\nEpoch 4/30\n52/52 [==============================] - 22s 423ms/step - loss: 1.9569 - accuracy: 0.8086 - val_loss: 0.9050 - val_accuracy: 0.8514\nEpoch 5/30\n52/52 [==============================] - 18s 353ms/step - loss: 1.3939 - accuracy: 0.8170 - val_loss: 2.6769 - val_accuracy: 0.4746\nEpoch 6/30\n52/52 [==============================] - 18s 354ms/step - loss: 2.0041 - accuracy: 0.8146 - val_loss: 2.0956 - val_accuracy: 0.8623\nEpoch 7/30\n52/52 [==============================] - 22s 422ms/step - loss: 1.4459 - accuracy: 0.8243 - val_loss: 3.1708 - val_accuracy: 0.8623\nEpoch 8/30\n52/52 [==============================] - 22s 422ms/step - loss: 2.0082 - accuracy: 0.8134 - val_loss: 1.2913 - val_accuracy: 0.8433\nEpoch 9/30\n52/52 [==============================] - 18s 353ms/step - loss: 1.5316 - accuracy: 0.8225 - val_loss: 2.0302 - val_accuracy: 0.5933\nEpoch 10/30\n52/52 [==============================] - 18s 352ms/step - loss: 1.1741 - accuracy: 0.8351 - val_loss: 1.4802 - val_accuracy: 0.8632\nEpoch 11/30\n52/52 [==============================] - 22s 423ms/step - loss: 0.9850 - accuracy: 0.8629 - val_loss: 1.7730 - val_accuracy: 0.6893\nEpoch 12/30\n52/52 [==============================] - 18s 353ms/step - loss: 0.9407 - accuracy: 0.8569 - val_loss: 1.0660 - val_accuracy: 0.8342\nEpoch 13/30\n52/52 [==============================] - 22s 422ms/step - loss: 0.6667 - accuracy: 0.8678 - val_loss: 2.6019 - val_accuracy: 0.8632\nEpoch 14/30\n52/52 [==============================] - 18s 353ms/step - loss: 1.4082 - accuracy: 0.8418 - val_loss: 1.9465 - val_accuracy: 0.6377\nEpoch 15/30\n52/52 [==============================] - 22s 422ms/step - loss: 0.8136 - accuracy: 0.8593 - val_loss: 1.3388 - val_accuracy: 0.6839\nEpoch 16/30\n52/52 [==============================] - 18s 352ms/step - loss: 0.5825 - accuracy: 0.8720 - val_loss: 1.0670 - val_accuracy: 0.8542\nEpoch 17/30\n52/52 [==============================] - 18s 353ms/step - loss: 0.7051 - accuracy: 0.8738 - val_loss: 1.4729 - val_accuracy: 0.7020\nEpoch 18/30\n52/52 [==============================] - 18s 353ms/step - loss: 0.6473 - accuracy: 0.8756 - val_loss: 1.2284 - val_accuracy: 0.8605\nEpoch 19/30\n52/52 [==============================] - 22s 423ms/step - loss: 0.7474 - accuracy: 0.8744 - val_loss: 1.6586 - val_accuracy: 0.8659\nEpoch 20/30\n52/52 [==============================] - 22s 423ms/step - loss: 0.6775 - accuracy: 0.8714 - val_loss: 0.9444 - val_accuracy: 0.8007\nEpoch 21/30\n52/52 [==============================] - 18s 352ms/step - loss: 0.6805 - accuracy: 0.8659 - val_loss: 1.5361 - val_accuracy: 0.8379\nEpoch 22/30\n52/52 [==============================] - 18s 353ms/step - loss: 0.6739 - accuracy: 0.8726 - val_loss: 1.0885 - val_accuracy: 0.7935\nEpoch 23/30\n52/52 [==============================] - 22s 423ms/step - loss: 0.4720 - accuracy: 0.8961 - val_loss: 1.3158 - val_accuracy: 0.8578\nEpoch 24/30\n52/52 [==============================] - 22s 423ms/step - loss: 0.7351 - accuracy: 0.8563 - val_loss: 1.0319 - val_accuracy: 0.8551\nEpoch 25/30\n52/52 [==============================] - 22s 423ms/step - loss: 0.4751 - accuracy: 0.8816 - val_loss: 0.7988 - val_accuracy: 0.8306\nEpoch 26/30\n52/52 [==============================] - 22s 422ms/step - loss: 0.3487 - accuracy: 0.8998 - val_loss: 0.6992 - val_accuracy: 0.8668\nEpoch 27/30\n52/52 [==============================] - 18s 352ms/step - loss: 0.3234 - accuracy: 0.9022 - val_loss: 0.7977 - val_accuracy: 0.8370\nEpoch 28/30\n52/52 [==============================] - 18s 354ms/step - loss: 0.3851 - accuracy: 0.8853 - val_loss: 0.9469 - val_accuracy: 0.8678\nEpoch 29/30\n52/52 [==============================] - 22s 422ms/step - loss: 0.3273 - accuracy: 0.9004 - val_loss: 0.7099 - val_accuracy: 0.8270\nEpoch 30/30\n52/52 [==============================] - 22s 422ms/step - loss: 0.2301 - accuracy: 0.9221 - val_loss: 0.7086 - val_accuracy: 0.8560\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f539dd14c10>"},"metadata":{}}]},{"cell_type":"markdown","source":"### EfficientNet B5","metadata":{}},{"cell_type":"code","source":"enb5_wo_top = keras.applications.efficientnet.EfficientNetB5(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n\nenb5_wo_top.trainable = False\n\nenb5_model = keras.models.Sequential()\nenb5_model.add(enb5_wo_top)\nenb5_model.add(keras.layers.Flatten())\nenb5_model.add(keras.layers.Dense(128, activation='relu'))\nenb5_model.add(keras.layers.Dense(64, activation='relu'))\nenb5_model.add(keras.layers.Dense(8, activation='softmax'))\n\nenb5_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n\nenb5_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T01:49:31.290950Z","iopub.execute_input":"2023-08-11T01:49:31.291319Z","iopub.status.idle":"2023-08-11T02:03:01.810278Z","shell.execute_reply.started":"2023-08-11T01:49:31.291282Z","shell.execute_reply":"2023-08-11T02:03:01.809151Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n115263384/115263384 [==============================] - 1s 0us/step\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2023-08-11 01:49:55.781276: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_8/efficientnetb5/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"52/52 [==============================] - 48s 604ms/step - loss: 17.0723 - accuracy: 0.7500 - val_loss: 6.4804 - val_accuracy: 0.7835\nEpoch 2/30\n52/52 [==============================] - 25s 491ms/step - loss: 5.2521 - accuracy: 0.7711 - val_loss: 3.3502 - val_accuracy: 0.8623\nEpoch 3/30\n52/52 [==============================] - 26s 508ms/step - loss: 2.7265 - accuracy: 0.7766 - val_loss: 1.3552 - val_accuracy: 0.8533\nEpoch 4/30\n52/52 [==============================] - 26s 508ms/step - loss: 1.6375 - accuracy: 0.7995 - val_loss: 1.0332 - val_accuracy: 0.8415\nEpoch 5/30\n52/52 [==============================] - 25s 491ms/step - loss: 1.1626 - accuracy: 0.8170 - val_loss: 2.0158 - val_accuracy: 0.8605\nEpoch 6/30\n52/52 [==============================] - 26s 509ms/step - loss: 1.7967 - accuracy: 0.8025 - val_loss: 1.6486 - val_accuracy: 0.8605\nEpoch 7/30\n52/52 [==============================] - 26s 510ms/step - loss: 1.0046 - accuracy: 0.8182 - val_loss: 1.2864 - val_accuracy: 0.6540\nEpoch 8/30\n52/52 [==============================] - 26s 509ms/step - loss: 1.1534 - accuracy: 0.8182 - val_loss: 0.8357 - val_accuracy: 0.8270\nEpoch 9/30\n52/52 [==============================] - 26s 508ms/step - loss: 0.9187 - accuracy: 0.8273 - val_loss: 1.2420 - val_accuracy: 0.6830\nEpoch 10/30\n52/52 [==============================] - 26s 508ms/step - loss: 0.9546 - accuracy: 0.8351 - val_loss: 0.7344 - val_accuracy: 0.8542\nEpoch 11/30\n52/52 [==============================] - 25s 490ms/step - loss: 2.7502 - accuracy: 0.7893 - val_loss: 2.1473 - val_accuracy: 0.7862\nEpoch 12/30\n52/52 [==============================] - 25s 491ms/step - loss: 1.0242 - accuracy: 0.8297 - val_loss: 1.2358 - val_accuracy: 0.8623\nEpoch 13/30\n52/52 [==============================] - 26s 509ms/step - loss: 0.8477 - accuracy: 0.8303 - val_loss: 0.7762 - val_accuracy: 0.8524\nEpoch 14/30\n52/52 [==============================] - 26s 508ms/step - loss: 0.6211 - accuracy: 0.8587 - val_loss: 0.7666 - val_accuracy: 0.8650\nEpoch 15/30\n52/52 [==============================] - 25s 490ms/step - loss: 0.5913 - accuracy: 0.8472 - val_loss: 0.7786 - val_accuracy: 0.8560\nEpoch 16/30\n52/52 [==============================] - 26s 508ms/step - loss: 0.5174 - accuracy: 0.8684 - val_loss: 0.6245 - val_accuracy: 0.8632\nEpoch 17/30\n52/52 [==============================] - 26s 509ms/step - loss: 0.4867 - accuracy: 0.8647 - val_loss: 0.6943 - val_accuracy: 0.8623\nEpoch 18/30\n52/52 [==============================] - 26s 509ms/step - loss: 0.4928 - accuracy: 0.8665 - val_loss: 0.5401 - val_accuracy: 0.8605\nEpoch 19/30\n52/52 [==============================] - 25s 491ms/step - loss: 0.4430 - accuracy: 0.8738 - val_loss: 0.5855 - val_accuracy: 0.8424\nEpoch 20/30\n52/52 [==============================] - 25s 491ms/step - loss: 0.6262 - accuracy: 0.8539 - val_loss: 0.5286 - val_accuracy: 0.8569\nEpoch 21/30\n52/52 [==============================] - 26s 508ms/step - loss: 0.5884 - accuracy: 0.8581 - val_loss: 0.8201 - val_accuracy: 0.7373\nEpoch 22/30\n52/52 [==============================] - 26s 509ms/step - loss: 0.4354 - accuracy: 0.8762 - val_loss: 0.5218 - val_accuracy: 0.8614\nEpoch 23/30\n52/52 [==============================] - 26s 510ms/step - loss: 0.3931 - accuracy: 0.8822 - val_loss: 0.5193 - val_accuracy: 0.8587\nEpoch 24/30\n52/52 [==============================] - 25s 492ms/step - loss: 0.3862 - accuracy: 0.8756 - val_loss: 0.5949 - val_accuracy: 0.8306\nEpoch 25/30\n52/52 [==============================] - 26s 509ms/step - loss: 0.4215 - accuracy: 0.8744 - val_loss: 0.6558 - val_accuracy: 0.8197\nEpoch 26/30\n52/52 [==============================] - 25s 491ms/step - loss: 0.4407 - accuracy: 0.8678 - val_loss: 0.8260 - val_accuracy: 0.8632\nEpoch 27/30\n52/52 [==============================] - 26s 508ms/step - loss: 0.4098 - accuracy: 0.8774 - val_loss: 0.7306 - val_accuracy: 0.7437\nEpoch 28/30\n52/52 [==============================] - 26s 509ms/step - loss: 0.4041 - accuracy: 0.8780 - val_loss: 0.8295 - val_accuracy: 0.8668\nEpoch 29/30\n52/52 [==============================] - 26s 509ms/step - loss: 0.4390 - accuracy: 0.8750 - val_loss: 0.6897 - val_accuracy: 0.7717\nEpoch 30/30\n52/52 [==============================] - 26s 509ms/step - loss: 0.3599 - accuracy: 0.8913 - val_loss: 0.5693 - val_accuracy: 0.8388\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f539b95ba30>"},"metadata":{}}]},{"cell_type":"markdown","source":"### EfficientNet B6","metadata":{}},{"cell_type":"code","source":"enb6_wo_top = keras.applications.efficientnet.EfficientNetB6(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n\nenb6_wo_top.trainable = False\n\nenb6_model = keras.models.Sequential()\nenb6_model.add(enb6_wo_top)\nenb6_model.add(keras.layers.Flatten())\nenb6_model.add(keras.layers.Dense(128, activation='relu'))\nenb6_model.add(keras.layers.Dense(64, activation='relu'))\nenb6_model.add(keras.layers.Dense(8, activation='softmax'))\n\nenb6_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n\nenb6_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T02:03:01.812216Z","iopub.execute_input":"2023-08-11T02:03:01.812603Z","iopub.status.idle":"2023-08-11T02:21:53.595352Z","shell.execute_reply.started":"2023-08-11T02:03:01.812566Z","shell.execute_reply":"2023-08-11T02:21:53.594239Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6_notop.h5\n165234480/165234480 [==============================] - 1s 0us/step\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2023-08-11 02:03:30.729367: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_9/efficientnetb6/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"52/52 [==============================] - 59s 772ms/step - loss: 23.1721 - accuracy: 0.7343 - val_loss: 8.4451 - val_accuracy: 0.8596\nEpoch 2/30\n52/52 [==============================] - 33s 640ms/step - loss: 5.5056 - accuracy: 0.7856 - val_loss: 10.1750 - val_accuracy: 0.2672\nEpoch 3/30\n52/52 [==============================] - 33s 640ms/step - loss: 3.8476 - accuracy: 0.7923 - val_loss: 2.9699 - val_accuracy: 0.8632\nEpoch 4/30\n52/52 [==============================] - 41s 803ms/step - loss: 2.9746 - accuracy: 0.8050 - val_loss: 1.8317 - val_accuracy: 0.6730\nEpoch 5/30\n52/52 [==============================] - 33s 639ms/step - loss: 1.7800 - accuracy: 0.8128 - val_loss: 3.1667 - val_accuracy: 0.8614\nEpoch 6/30\n52/52 [==============================] - 41s 802ms/step - loss: 1.6526 - accuracy: 0.8213 - val_loss: 2.3976 - val_accuracy: 0.8614\nEpoch 7/30\n52/52 [==============================] - 41s 803ms/step - loss: 1.9287 - accuracy: 0.8086 - val_loss: 2.7395 - val_accuracy: 0.7935\nEpoch 8/30\n52/52 [==============================] - 41s 803ms/step - loss: 1.6043 - accuracy: 0.8237 - val_loss: 1.5963 - val_accuracy: 0.6630\nEpoch 9/30\n52/52 [==============================] - 33s 640ms/step - loss: 1.0209 - accuracy: 0.8430 - val_loss: 1.5192 - val_accuracy: 0.8098\nEpoch 10/30\n52/52 [==============================] - 41s 802ms/step - loss: 1.2584 - accuracy: 0.8285 - val_loss: 1.1829 - val_accuracy: 0.7871\nEpoch 11/30\n52/52 [==============================] - 33s 639ms/step - loss: 1.3581 - accuracy: 0.8249 - val_loss: 1.4530 - val_accuracy: 0.7654\nEpoch 12/30\n52/52 [==============================] - 33s 639ms/step - loss: 1.2329 - accuracy: 0.8243 - val_loss: 1.5082 - val_accuracy: 0.8623\nEpoch 13/30\n52/52 [==============================] - 41s 803ms/step - loss: 1.0697 - accuracy: 0.8478 - val_loss: 1.0884 - val_accuracy: 0.8478\nEpoch 14/30\n52/52 [==============================] - 33s 640ms/step - loss: 1.1044 - accuracy: 0.8388 - val_loss: 1.4250 - val_accuracy: 0.8016\nEpoch 15/30\n52/52 [==============================] - 33s 639ms/step - loss: 0.9482 - accuracy: 0.8490 - val_loss: 2.5346 - val_accuracy: 0.8632\nEpoch 16/30\n52/52 [==============================] - 41s 802ms/step - loss: 1.3274 - accuracy: 0.8345 - val_loss: 1.5256 - val_accuracy: 0.8306\nEpoch 17/30\n52/52 [==============================] - 41s 802ms/step - loss: 0.9613 - accuracy: 0.8545 - val_loss: 1.7962 - val_accuracy: 0.7183\nEpoch 18/30\n52/52 [==============================] - 33s 640ms/step - loss: 1.0909 - accuracy: 0.8388 - val_loss: 1.0437 - val_accuracy: 0.8524\nEpoch 19/30\n52/52 [==============================] - 41s 803ms/step - loss: 0.8338 - accuracy: 0.8521 - val_loss: 1.0652 - val_accuracy: 0.7853\nEpoch 20/30\n52/52 [==============================] - 33s 640ms/step - loss: 0.5098 - accuracy: 0.8744 - val_loss: 0.9190 - val_accuracy: 0.8641\nEpoch 21/30\n52/52 [==============================] - 33s 640ms/step - loss: 0.4786 - accuracy: 0.8816 - val_loss: 0.6881 - val_accuracy: 0.8451\nEpoch 22/30\n52/52 [==============================] - 41s 802ms/step - loss: 0.4679 - accuracy: 0.8732 - val_loss: 1.1380 - val_accuracy: 0.8650\nEpoch 23/30\n52/52 [==============================] - 41s 803ms/step - loss: 0.5572 - accuracy: 0.8726 - val_loss: 0.9767 - val_accuracy: 0.7527\nEpoch 24/30\n52/52 [==============================] - 33s 641ms/step - loss: 0.7280 - accuracy: 0.8678 - val_loss: 1.0875 - val_accuracy: 0.8152\nEpoch 25/30\n52/52 [==============================] - 33s 641ms/step - loss: 0.4834 - accuracy: 0.8829 - val_loss: 1.8423 - val_accuracy: 0.8632\nEpoch 26/30\n52/52 [==============================] - 33s 640ms/step - loss: 0.4791 - accuracy: 0.8949 - val_loss: 0.7723 - val_accuracy: 0.8560\nEpoch 27/30\n52/52 [==============================] - 33s 640ms/step - loss: 0.4846 - accuracy: 0.8859 - val_loss: 0.8947 - val_accuracy: 0.8306\nEpoch 28/30\n52/52 [==============================] - 33s 640ms/step - loss: 0.4301 - accuracy: 0.8901 - val_loss: 0.8810 - val_accuracy: 0.7582\nEpoch 29/30\n52/52 [==============================] - 41s 803ms/step - loss: 0.3125 - accuracy: 0.9076 - val_loss: 1.1208 - val_accuracy: 0.8650\nEpoch 30/30\n52/52 [==============================] - 33s 639ms/step - loss: 0.4351 - accuracy: 0.8762 - val_loss: 0.7723 - val_accuracy: 0.8406\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f539303b100>"},"metadata":{}}]},{"cell_type":"markdown","source":"### EfficientNet B7","metadata":{}},{"cell_type":"code","source":"enb7_wo_top = keras.applications.efficientnet.EfficientNetB7(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n\nenb7_wo_top.trainable = False\n\nenb7_model = keras.models.Sequential()\nenb7_model.add(enb7_wo_top)\nenb7_model.add(keras.layers.Flatten())\nenb7_model.add(keras.layers.Dense(128, activation='relu'))\nenb7_model.add(keras.layers.Dense(64, activation='relu'))\nenb7_model.add(keras.layers.Dense(8, activation='softmax'))\n\nenb7_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n\nenb7_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-11T02:21:53.597057Z","iopub.execute_input":"2023-08-11T02:21:53.597427Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n258076736/258076736 [==============================] - 2s 0us/step\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2023-08-11 02:22:28.915711: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_10/efficientnetb7/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"52/52 [==============================] - 77s 1s/step - loss: 16.5604 - accuracy: 0.7579 - val_loss: 6.9060 - val_accuracy: 0.6857\nEpoch 2/30\n52/52 [==============================] - 48s 932ms/step - loss: 4.6826 - accuracy: 0.7772 - val_loss: 3.9796 - val_accuracy: 0.4973\nEpoch 3/30\n52/52 [==============================] - 44s 852ms/step - loss: 2.3625 - accuracy: 0.7862 - val_loss: 1.7912 - val_accuracy: 0.8043\nEpoch 4/30\n52/52 [==============================] - 44s 852ms/step - loss: 2.1992 - accuracy: 0.7862 - val_loss: 2.8624 - val_accuracy: 0.7717\nEpoch 5/30\n52/52 [==============================] - 48s 933ms/step - loss: 2.3889 - accuracy: 0.7742 - val_loss: 1.4381 - val_accuracy: 0.8025\nEpoch 6/30\n52/52 [==============================] - 44s 851ms/step - loss: 1.7174 - accuracy: 0.8019 - val_loss: 1.5217 - val_accuracy: 0.8170\nEpoch 7/30\n52/52 [==============================] - 44s 852ms/step - loss: 1.1781 - accuracy: 0.8116 - val_loss: 1.6362 - val_accuracy: 0.6214\nEpoch 8/30\n52/52 [==============================] - 44s 851ms/step - loss: 2.4470 - accuracy: 0.8007 - val_loss: 2.7364 - val_accuracy: 0.5806\nEpoch 9/30\n52/52 [==============================] - 48s 933ms/step - loss: 1.8327 - accuracy: 0.8080 - val_loss: 1.1274 - val_accuracy: 0.8505\nEpoch 10/30\n52/52 [==============================] - 48s 933ms/step - loss: 0.8643 - accuracy: 0.8364 - val_loss: 0.9547 - val_accuracy: 0.7509\nEpoch 11/30\n52/52 [==============================] - 44s 852ms/step - loss: 1.1805 - accuracy: 0.8237 - val_loss: 0.9004 - val_accuracy: 0.8551\nEpoch 12/30\n52/52 [==============================] - 48s 932ms/step - loss: 1.2058 - accuracy: 0.8200 - val_loss: 0.9714 - val_accuracy: 0.7935\nEpoch 13/30\n52/52 [==============================] - 44s 853ms/step - loss: 1.0972 - accuracy: 0.8194 - val_loss: 1.1261 - val_accuracy: 0.7020\nEpoch 14/30\n52/52 [==============================] - 44s 853ms/step - loss: 0.8431 - accuracy: 0.8351 - val_loss: 1.6946 - val_accuracy: 0.8641\nEpoch 15/30\n52/52 [==============================] - 48s 932ms/step - loss: 1.1255 - accuracy: 0.8261 - val_loss: 0.7891 - val_accuracy: 0.8623\nEpoch 16/30\n52/52 [==============================] - 48s 932ms/step - loss: 0.6685 - accuracy: 0.8496 - val_loss: 0.6736 - val_accuracy: 0.8342\nEpoch 17/30\n52/52 [==============================] - 48s 932ms/step - loss: 0.5450 - accuracy: 0.8647 - val_loss: 0.6172 - val_accuracy: 0.8406\nEpoch 18/30\n52/52 [==============================] - 48s 933ms/step - loss: 0.5061 - accuracy: 0.8708 - val_loss: 0.7053 - val_accuracy: 0.8397\nEpoch 19/30\n52/52 [==============================] - 44s 852ms/step - loss: 0.5473 - accuracy: 0.8581 - val_loss: 0.6619 - val_accuracy: 0.8043\nEpoch 20/30\n52/52 [==============================] - 48s 933ms/step - loss: 0.4947 - accuracy: 0.8635 - val_loss: 0.7072 - val_accuracy: 0.8125\nEpoch 21/30\n52/52 [==============================] - 48s 932ms/step - loss: 0.5808 - accuracy: 0.8605 - val_loss: 0.7373 - val_accuracy: 0.7844\nEpoch 22/30\n52/52 [==============================] - 48s 933ms/step - loss: 0.7091 - accuracy: 0.8382 - val_loss: 0.6514 - val_accuracy: 0.8524\nEpoch 23/30\n52/52 [==============================] - 48s 931ms/step - loss: 0.5035 - accuracy: 0.8617 - val_loss: 0.6807 - val_accuracy: 0.8650\nEpoch 24/30\n52/52 [==============================] - 44s 852ms/step - loss: 0.3785 - accuracy: 0.8871 - val_loss: 0.5922 - val_accuracy: 0.8678\nEpoch 25/30\n52/52 [==============================] - 48s 932ms/step - loss: 0.4125 - accuracy: 0.8835 - val_loss: 1.2026 - val_accuracy: 0.8623\nEpoch 26/30\n52/52 [==============================] - 48s 932ms/step - loss: 0.7254 - accuracy: 0.8442 - val_loss: 0.7912 - val_accuracy: 0.7971\nEpoch 27/30\n52/52 [==============================] - 48s 933ms/step - loss: 0.5167 - accuracy: 0.8587 - val_loss: 0.5859 - val_accuracy: 0.8433\nEpoch 28/30\n52/52 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.8907","output_type":"stream"}]},{"cell_type":"markdown","source":"### ResNet50","metadata":{}},{"cell_type":"code","source":"resnet_wo_top = keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=(350, 350, 3))\n\nresnet_wo_top.trainable = False\n\nresnet_model = keras.models.Sequential()\nresnet_model.add(resnet_wo_top)\nresnet_model.add(keras.layers.Flatten())\nresnet_model.add(keras.layers.Dense(128, activation='relu'))\nresnet_model.add(keras.layers.Dense(64, activation='relu'))\nresnet_model.add(keras.layers.Dense(8, activation='softmax'))\n\nresnet_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n\nresnet_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}