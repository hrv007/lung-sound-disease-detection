{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nimport cv2","metadata":{"id":"EXy5Ggoqczap","execution":{"iopub.status.busy":"2023-08-12T03:41:19.945413Z","iopub.execute_input":"2023-08-12T03:41:19.945683Z","iopub.status.idle":"2023-08-12T03:41:29.705283Z","shell.execute_reply.started":"2023-08-12T03:41:19.945657Z","shell.execute_reply":"2023-08-12T03:41:29.704236Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/augmented-data-sequential/patient_diagnosis.csv\")\ndf.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ArtW5CVwuApp","outputId":"fe2935a3-842f-4305-996a-bb1edcb03165","execution":{"iopub.status.busy":"2023-08-12T03:46:35.122412Z","iopub.execute_input":"2023-08-12T03:46:35.123182Z","iopub.status.idle":"2023-08-12T03:46:35.155002Z","shell.execute_reply.started":"2023-08-12T03:46:35.123147Z","shell.execute_reply":"2023-08-12T03:46:35.153912Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   101     URTI\n0  102  Healthy\n1  103   Asthma\n2  104     COPD\n3  105     URTI\n4  106     COPD","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>101</th>\n      <th>URTI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>102</td>\n      <td>Healthy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>103</td>\n      <td>Asthma</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>104</td>\n      <td>COPD</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>105</td>\n      <td>URTI</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>106</td>\n      <td>COPD</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sr_no = {'101':'URTI'}\nfor i, j in zip(df['101'].unique(), df['URTI']):\n    sr_no[str(i)] = j","metadata":{"id":"eAdDHbX6u_iz","execution":{"iopub.status.busy":"2023-08-12T03:46:37.575775Z","iopub.execute_input":"2023-08-12T03:46:37.576812Z","iopub.status.idle":"2023-08-12T03:46:37.585988Z","shell.execute_reply.started":"2023-08-12T03:46:37.576769Z","shell.execute_reply":"2023-08-12T03:46:37.584881Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"sr_no.keys()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1j95yfuivIOL","outputId":"c4ce184c-bb32-43e4-acbb-ef143254077e","execution":{"iopub.status.busy":"2023-08-12T03:46:38.241213Z","iopub.execute_input":"2023-08-12T03:46:38.241558Z","iopub.status.idle":"2023-08-12T03:46:38.247822Z","shell.execute_reply.started":"2023-08-12T03:46:38.241530Z","shell.execute_reply":"2023-08-12T03:46:38.246863Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"dict_keys(['101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226'])"},"metadata":{}}]},{"cell_type":"code","source":"import os\nsound_files = os.listdir('/kaggle/input/mel-spectrogram-data/Mel Spectrogram/Original')","metadata":{"id":"k_apddzYvK_5","execution":{"iopub.status.busy":"2023-08-12T03:46:39.066056Z","iopub.execute_input":"2023-08-12T03:46:39.066396Z","iopub.status.idle":"2023-08-12T03:46:39.179799Z","shell.execute_reply.started":"2023-08-12T03:46:39.066369Z","shell.execute_reply":"2023-08-12T03:46:39.178876Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"req_file_names = []\n\nfor i in sound_files:\n      req_file_names.append([i])\n\nreq_file_names","metadata":{"id":"jNTE66gVvVEg","execution":{"iopub.status.busy":"2023-08-12T03:46:39.921592Z","iopub.execute_input":"2023-08-12T03:46:39.922365Z","iopub.status.idle":"2023-08-12T03:46:39.959633Z","shell.execute_reply.started":"2023-08-12T03:46:39.922333Z","shell.execute_reply":"2023-08-12T03:46:39.958694Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[['176_2b3_Lr_mc_AKGC417L.png'],\n ['112_1p1_Pr_sc_Litt3200.png'],\n ['130_2b2_Pr_mc_AKGC417L.png'],\n ['193_7b3_Ll_mc_AKGC417L.png'],\n ['156_5b3_Pl_mc_AKGC417L.png'],\n ['162_2b2_Tc_mc_AKGC417L.png'],\n ['134_2b3_Ar_mc_LittC2SE.png'],\n ['160_1b4_Tc_mc_AKGC417L.png'],\n ['200_2p4_Pl_mc_AKGC417L.png'],\n ['169_1b2_Ll_sc_Meditron.png'],\n ['144_1b1_Tc_sc_Meditron.png'],\n ['160_2b4_Pl_mc_AKGC417L.png'],\n ['133_2p3_Pr_mc_AKGC417L.png'],\n ['205_1b3_Al_mc_AKGC417L.png'],\n ['130_3p4_Tc_mc_AKGC417L.png'],\n ['130_1p4_Lr_mc_AKGC417L.png'],\n ['200_3p4_Pl_mc_AKGC417L.png'],\n ['107_2b4_Ar_mc_AKGC417L.png'],\n ['203_2p3_Al_mc_AKGC417L.png'],\n ['113_1b1_Ar_sc_Litt3200.png'],\n ['174_2p3_Al_mc_AKGC417L.png'],\n ['178_1b2_Lr_mc_AKGC417L.png'],\n ['172_1b5_Ll_mc_AKGC417L.png'],\n ['216_1b1_Al_sc_Meditron.png'],\n ['205_4b2_Pl_mc_AKGC417L.png'],\n ['177_1b2_Lr_mc_AKGC417L.png'],\n ['151_2p4_Ll_mc_AKGC417L.png'],\n ['141_1b1_Pr_mc_LittC2SE.png'],\n ['162_1b2_Lr_mc_AKGC417L.png'],\n ['133_3p4_Tc_mc_AKGC417L.png'],\n ['147_2b3_Ll_mc_AKGC417L.png'],\n ['143_1b1_Al_sc_Meditron.png'],\n ['218_1p1_Pr_sc_Litt3200.png'],\n ['138_2p2_Al_mc_AKGC417L.png'],\n ['113_1b1_Al_sc_Litt3200.png'],\n ['144_1b1_Al_sc_Meditron.png'],\n ['130_1p4_Pl_mc_AKGC417L.png'],\n ['185_1b1_Ar_sc_Litt3200.png'],\n ['138_1p3_Pl_mc_AKGC417L.png'],\n ['122_2b2_Ar_mc_LittC2SE.png'],\n ['126_1b1_Al_sc_Meditron.png'],\n ['140_2b3_Ll_mc_LittC2SE.png'],\n ['160_1b3_Al_mc_AKGC417L.png'],\n ['186_2b4_Pr_mc_AKGC417L.png'],\n ['176_2b3_Pr_mc_AKGC417L.png'],\n ['160_1b2_Al_mc_AKGC417L.png'],\n ['136_1b1_Ar_sc_Meditron.png'],\n ['172_2b5_Tc_mc_AKGC417L.png'],\n ['176_2b3_Pl_mc_AKGC417L.png'],\n ['178_2b2_Lr_mc_AKGC417L.png'],\n ['162_1b2_Al_mc_AKGC417L.png'],\n ['133_2p2_Tc_mc_AKGC417L.png'],\n ['205_4b2_Al_mc_AKGC417L.png'],\n ['113_1b1_Pl_sc_Litt3200.png'],\n ['178_2b2_Ar_mc_AKGC417L.png'],\n ['156_5b3_Pr_mc_AKGC417L.png'],\n ['198_6p1_Ar_mc_AKGC417L.png'],\n ['213_1p3_Pr_mc_AKGC417L.png'],\n ['170_1b2_Ar_mc_AKGC417L.png'],\n ['204_7p5_Lr_mc_AKGC417L.png'],\n ['107_2b3_Pl_mc_AKGC417L.png'],\n ['176_2b3_Tc_mc_AKGC417L.png'],\n ['197_1b1_Tc_sc_Meditron.png'],\n ['196_1b1_Pr_sc_Meditron.png'],\n ['130_1p2_Pr_mc_AKGC417L.png'],\n ['146_8p3_Ar_mc_AKGC417L.png'],\n ['151_3p2_Ar_mc_AKGC417L.png'],\n ['141_1b2_Tc_mc_LittC2SE.png'],\n ['103_2b2_Ar_mc_LittC2SE.png'],\n ['211_2p4_Tc_mc_AKGC417L.png'],\n ['160_1b4_Pr_mc_AKGC417L.png'],\n ['176_1b4_Lr_mc_AKGC417L.png'],\n ['156_8b3_Ll_mc_AKGC417L.png'],\n ['205_4b2_Pr_mc_AKGC417L.png'],\n ['172_1b3_Tc_mc_AKGC417L.png'],\n ['133_2p3_Pl_mc_AKGC417L.png'],\n ['154_4b4_Pl_mc_AKGC417L.png'],\n ['176_1b4_Tc_mc_AKGC417L.png'],\n ['107_3p2_Tc_mc_AKGC417L.png'],\n ['114_1b4_Al_mc_AKGC417L.png'],\n ['207_2b4_Tc_mc_AKGC417L.png'],\n ['130_2p5_Lr_mc_AKGC417L.png'],\n ['198_6p1_Pl_mc_AKGC417L.png'],\n ['138_1p4_Ar_mc_AKGC417L.png'],\n ['151_2p3_Ar_mc_AKGC417L.png'],\n ['147_2b4_Pl_mc_AKGC417L.png'],\n ['198_1b5_Lr_mc_AKGC417L.png'],\n ['135_2b1_Tc_mc_LittC2SE.png'],\n ['200_2p2_Tc_mc_AKGC417L.png'],\n ['159_1b1_Pr_sc_Meditron.png'],\n ['186_2b4_Ar_mc_AKGC417L.png'],\n ['156_2b3_Ar_mc_AKGC417L.png'],\n ['116_1b2_Tc_sc_Meditron.png'],\n ['156_2b3_Pl_mc_AKGC417L.png'],\n ['213_2p2_Ar_mc_AKGC417L.png'],\n ['213_1p3_Ar_mc_AKGC417L.png'],\n ['120_1b1_Al_sc_Meditron.png'],\n ['160_1b3_Lr_mc_AKGC417L.png'],\n ['207_2b2_Pr_mc_AKGC417L.png'],\n ['177_1b2_Al_mc_AKGC417L.png'],\n ['221_2b2_Al_mc_LittC2SE.png'],\n ['133_2p4_Al_mc_AKGC417L.png'],\n ['154_2b4_Tc_mc_AKGC417L.png'],\n ['205_2b3_Ll_mc_AKGC417L.png'],\n ['178_1b3_Tc_mc_AKGC417L.png'],\n ['158_1p4_Al_mc_AKGC417L.png'],\n ['205_3b4_Ar_mc_AKGC417L.png'],\n ['159_1b1_Ll_sc_Meditron.png'],\n ['138_2p2_Ll_mc_AKGC417L.png'],\n ['205_1b3_Ll_mc_AKGC417L.png'],\n ['176_1b4_Pl_mc_AKGC417L.png'],\n ['162_2b4_Ar_mc_AKGC417L.png'],\n ['151_2p4_Lr_mc_AKGC417L.png'],\n ['207_2b3_Ar_mc_AKGC417L.png'],\n ['135_2b3_Al_mc_LittC2SE.png'],\n ['151_2p3_Ll_mc_AKGC417L.png'],\n ['101_1b1_Pr_sc_Meditron.png'],\n ['104_1b1_Ar_sc_Litt3200.png'],\n ['135_2b3_Pr_mc_LittC2SE.png'],\n ['151_3p2_Tc_mc_AKGC417L.png'],\n ['170_2b2_Lr_mc_AKGC417L.png'],\n ['140_2b2_Tc_mc_LittC2SE.png'],\n ['218_1p1_Pl_sc_Litt3200.png'],\n ['170_1b4_Tc_mc_AKGC417L.png'],\n ['192_2b3_Ar_mc_LittC2SE.png'],\n ['200_2p4_Al_mc_AKGC417L.png'],\n ['204_7p5_Ar_mc_AKGC417L.png'],\n ['178_2b2_Tc_mc_AKGC417L.png'],\n ['135_2b3_Tc_mc_LittC2SE.png'],\n ['221_2b2_Lr_mc_LittC2SE.png'],\n ['130_3b4_Pr_mc_AKGC417L.png'],\n ['162_2b4_Pl_mc_AKGC417L.png'],\n ['138_1p2_Ll_mc_AKGC417L.png'],\n ['109_1b1_Lr_sc_Litt3200.png'],\n ['213_1p2_Tc_mc_AKGC417L.png'],\n ['122_2b2_Tc_mc_LittC2SE.png'],\n ['174_1p4_Tc_mc_AKGC417L.png'],\n ['122_2b1_Tc_mc_LittC2SE.png'],\n ['141_1b2_Ar_mc_LittC2SE.png'],\n ['198_6p1_Lr_mc_AKGC417L.png'],\n ['149_1b1_Al_sc_Meditron.png'],\n ['176_2b3_Al_mc_AKGC417L.png'],\n ['107_2b5_Tc_mc_AKGC417L.png'],\n ['109_1b1_Al_sc_Litt3200.png'],\n ['213_1p5_Pl_mc_AKGC417L.png'],\n ['158_1p4_Tc_mc_AKGC417L.png'],\n ['200_2p3_Pl_mc_AKGC417L.png'],\n ['177_1b2_Pl_mc_AKGC417L.png'],\n ['151_2p3_Al_mc_AKGC417L.png'],\n ['147_2b2_Pl_mc_AKGC417L.png'],\n ['175_1b1_Pr_sc_Litt3200.png'],\n ['157_1b1_Ar_sc_Meditron.png'],\n ['122_2b3_Tc_mc_LittC2SE.png'],\n ['203_1p3_Tc_mc_AKGC417L.png'],\n ['166_1p1_Pl_sc_Meditron.png'],\n ['213_1p2_Al_mc_AKGC417L.png'],\n ['215_1b3_Tc_sc_Meditron.png'],\n ['110_1p1_Ll_sc_Meditron.png'],\n ['200_2p2_Ar_mc_AKGC417L.png'],\n ['202_1b1_Ar_sc_Meditron.png'],\n ['158_1p2_Lr_mc_AKGC417L.png'],\n ['147_1b2_Tc_mc_AKGC417L.png'],\n ['147_2b3_Ar_mc_AKGC417L.png'],\n ['174_2p3_Tc_mc_AKGC417L.png'],\n ['200_3p4_Al_mc_AKGC417L.png'],\n ['213_2p2_Pl_mc_AKGC417L.png'],\n ['177_1b2_Pr_mc_AKGC417L.png'],\n ['204_7p5_Ll_mc_AKGC417L.png'],\n ['162_2b3_Pr_mc_AKGC417L.png'],\n ['117_1b2_Tc_mc_LittC2SE.png'],\n ['140_2b2_Ll_mc_LittC2SE.png'],\n ['222_1b1_Lr_sc_Meditron.png'],\n ['130_2b2_Ll_mc_AKGC417L.png'],\n ['130_2p5_Pl_mc_AKGC417L.png'],\n ['172_2b5_Al_mc_AKGC417L.png'],\n ['147_2b4_Lr_mc_AKGC417L.png'],\n ['138_1p3_Ll_mc_AKGC417L.png'],\n ['138_1p4_Ll_mc_AKGC417L.png'],\n ['160_2b4_Ar_mc_AKGC417L.png'],\n ['147_2b2_Ar_mc_AKGC417L.png'],\n ['141_1b3_Ar_mc_LittC2SE.png'],\n ['124_1b1_Ll_sc_Litt3200.png'],\n ['178_1b3_Pl_mc_AKGC417L.png'],\n ['107_3p2_Ll_mc_AKGC417L.png'],\n ['130_2p5_Tc_mc_AKGC417L.png'],\n ['106_2b1_Pl_mc_LittC2SE.png'],\n ['198_1b5_Ar_mc_AKGC417L.png'],\n ['193_7b3_Pr_mc_AKGC417L.png'],\n ['198_1b5_Pr_mc_AKGC417L.png'],\n ['203_1p4_Al_mc_AKGC417L.png'],\n ['201_1b3_Ar_sc_Meditron.png'],\n ['146_2b4_Ll_mc_AKGC417L.png'],\n ['208_1b1_Ll_sc_Meditron.png'],\n ['138_2p2_Tc_mc_AKGC417L.png'],\n ['158_1p3_Ll_mc_AKGC417L.png'],\n ['178_1b6_Ll_mc_AKGC417L.png'],\n ['130_2p5_Pr_mc_AKGC417L.png'],\n ['133_2p4_Pr_mc_AKGC417L.png'],\n ['195_1b1_Pr_sc_Litt3200.png'],\n ['170_2b2_Pl_mc_AKGC417L.png'],\n ['107_2b5_Lr_mc_AKGC417L.png'],\n ['170_1b3_Lr_mc_AKGC417L.png'],\n ['174_1p3_Pl_mc_AKGC417L.png'],\n ['200_3p4_Ar_mc_AKGC417L.png'],\n ['178_1b6_Pr_mc_AKGC417L.png'],\n ['205_1b3_Ar_mc_AKGC417L.png'],\n ['198_6p1_Tc_mc_AKGC417L.png'],\n ['107_3p2_Pr_mc_AKGC417L.png'],\n ['174_1p2_Pr_mc_AKGC417L.png'],\n ['205_2b3_Ar_mc_AKGC417L.png'],\n ['188_1b1_Ar_sc_Meditron.png'],\n ['151_2p4_Pr_mc_AKGC417L.png'],\n ['176_1b3_Tc_mc_AKGC417L.png'],\n ['138_1p2_Pr_mc_AKGC417L.png'],\n ['174_1p4_Ar_mc_AKGC417L.png'],\n ['158_1p4_Pl_mc_AKGC417L.png'],\n ['158_1p3_Pl_mc_AKGC417L.png'],\n ['205_2b2_Pr_mc_AKGC417L.png'],\n ['198_6p1_Al_mc_AKGC417L.png'],\n ['170_1b2_Pl_mc_AKGC417L.png'],\n ['203_2p3_Tc_mc_AKGC417L.png'],\n ['130_3p2_Ar_mc_AKGC417L.png'],\n ['178_1b3_Al_mc_AKGC417L.png'],\n ['188_1b1_Tc_sc_Meditron.png'],\n ['147_2b2_Al_mc_AKGC417L.png'],\n ['218_1b1_Ar_sc_Meditron.png'],\n ['130_2b2_Pl_mc_AKGC417L.png'],\n ['205_1b3_Pr_mc_AKGC417L.png'],\n ['130_2p3_Pl_mc_AKGC417L.png'],\n ['172_1b3_Pr_mc_AKGC417L.png'],\n ['200_2p2_Pr_mc_AKGC417L.png'],\n ['205_1b3_Lr_mc_AKGC417L.png'],\n ['156_8b3_Lr_mc_AKGC417L.png'],\n ['200_2p2_Al_mc_AKGC417L.png'],\n ['133_3p2_Pr_mc_AKGC417L.png'],\n ['176_1b3_Lr_mc_AKGC417L.png'],\n ['135_2b2_Tc_mc_LittC2SE.png'],\n ['207_2b2_Tc_mc_AKGC417L.png'],\n ['180_1b4_Al_mc_AKGC417L.png'],\n ['120_1b1_Lr_sc_Meditron.png'],\n ['158_1p3_Pr_mc_AKGC417L.png'],\n ['154_2b4_Ar_mc_AKGC417L.png'],\n ['130_3b4_Pl_mc_AKGC417L.png'],\n ['107_2b3_Lr_mc_AKGC417L.png'],\n ['107_2b5_Ll_mc_AKGC417L.png'],\n ['211_1p2_Pr_mc_AKGC417L.png'],\n ['225_1b1_Pl_sc_Meditron.png'],\n ['207_2b4_Al_mc_AKGC417L.png'],\n ['154_3b3_Ar_mc_AKGC417L.png'],\n ['113_1b1_Pr_sc_Litt3200.png'],\n ['135_2b2_Al_mc_LittC2SE.png'],\n ['213_1p2_Pr_mc_AKGC417L.png'],\n ['207_2b3_Pr_mc_AKGC417L.png'],\n ['172_2b5_Lr_mc_AKGC417L.png'],\n ['191_2b2_Tc_mc_LittC2SE.png'],\n ['130_1p3_Ar_mc_AKGC417L.png'],\n ['162_1b2_Ll_mc_AKGC417L.png'],\n ['201_1b3_Al_sc_Meditron.png'],\n ['201_1b1_Ar_sc_Meditron.png'],\n ['213_2p2_Pr_mc_AKGC417L.png'],\n ['206_1b1_Ar_sc_Meditron.png'],\n ['178_1b3_Lr_mc_AKGC417L.png'],\n ['221_2b3_Lr_mc_LittC2SE.png'],\n ['200_2p3_Lr_mc_AKGC417L.png'],\n ['129_1b1_Ar_sc_Meditron.png'],\n ['192_2b3_Al_mc_LittC2SE.png'],\n ['221_2b3_Pr_mc_LittC2SE.png'],\n ['160_1b3_Pr_mc_AKGC417L.png'],\n ['130_2b3_Pl_mc_AKGC417L.png'],\n ['170_1b3_Al_mc_AKGC417L.png'],\n ['181_1b3_Tc_mc_LittC2SE.png'],\n ['141_1b3_Al_mc_LittC2SE.png'],\n ['186_3b3_Ar_mc_AKGC417L.png'],\n ['133_3p2_Ar_mc_AKGC417L.png'],\n ['162_1b2_Ar_mc_AKGC417L.png'],\n ['198_6p1_Ll_mc_AKGC417L.png'],\n ['130_3p2_Al_mc_AKGC417L.png'],\n ['203_2p3_Pl_mc_AKGC417L.png'],\n ['118_1b1_Al_sc_Litt3200.png'],\n ['162_2b2_Pl_mc_AKGC417L.png'],\n ['130_1p2_Tc_mc_AKGC417L.png'],\n ['104_1b1_Al_sc_Litt3200.png'],\n ['151_3p2_Lr_mc_AKGC417L.png'],\n ['205_3b4_Pr_mc_AKGC417L.png'],\n ['213_1p2_Pl_mc_AKGC417L.png'],\n ['158_1p4_Lr_mc_AKGC417L.png'],\n ['124_1b1_Lr_sc_Litt3200.png'],\n ['193_7b3_Lr_mc_AKGC417L.png'],\n ['192_2b1_Al_mc_LittC2SE.png'],\n ['220_1b1_Tc_mc_LittC2SE.png'],\n ['164_1b1_Ll_sc_Meditron.png'],\n ['154_4b4_Al_mc_AKGC417L.png'],\n ['198_1b5_Ll_mc_AKGC417L.png'],\n ['147_1b4_Tc_mc_AKGC417L.png'],\n ['130_3p3_Al_mc_AKGC417L.png'],\n ['170_1b2_Lr_mc_AKGC417L.png'],\n ['200_2p3_Tc_mc_AKGC417L.png'],\n ['181_1b2_Ar_mc_LittC2SE.png'],\n ['124_1b1_Ar_sc_Litt3200.png'],\n ['130_3p3_Pr_mc_AKGC417L.png'],\n ['166_1p1_Ar_sc_Meditron.png'],\n ['224_1b1_Tc_sc_Meditron.png'],\n ['130_3p4_Pl_mc_AKGC417L.png'],\n ['203_2p3_Ar_mc_AKGC417L.png'],\n ['215_1b2_Ar_sc_Meditron.png'],\n ['211_1p2_Pl_mc_AKGC417L.png'],\n ['172_2b5_Ar_mc_AKGC417L.png'],\n ['147_1b3_Tc_mc_AKGC417L.png'],\n ['176_1b3_Ar_mc_AKGC417L.png'],\n ['154_3b3_Ll_mc_AKGC417L.png'],\n ['122_2b1_Ar_mc_LittC2SE.png'],\n ['192_2b2_Al_mc_LittC2SE.png'],\n ['172_1b3_Lr_mc_AKGC417L.png'],\n ['130_2b3_Al_mc_AKGC417L.png'],\n ['207_2b2_Al_mc_AKGC417L.png'],\n ['112_1p1_Ll_sc_Litt3200.png'],\n ['117_1b3_Tc_mc_LittC2SE.png'],\n ['203_1p4_Tc_mc_AKGC417L.png'],\n ['135_2b2_Pl_mc_LittC2SE.png'],\n ['156_8b3_Pl_mc_AKGC417L.png'],\n ['133_3p2_Al_mc_AKGC417L.png'],\n ['130_2p5_Al_mc_AKGC417L.png'],\n ['162_2b2_Al_mc_AKGC417L.png'],\n ['141_1b3_Pr_mc_LittC2SE.png'],\n ['195_1b1_Ll_sc_Litt3200.png'],\n ['199_2b3_Ll_mc_LittC2SE.png'],\n ['108_1b1_Al_sc_Meditron.png'],\n ['138_1p3_Lr_mc_AKGC417L.png'],\n ['122_2b1_Al_mc_LittC2SE.png'],\n ['130_1p3_Tc_mc_AKGC417L.png'],\n ['163_2b2_Pl_mc_AKGC417L.png'],\n ['158_1p2_Ll_mc_AKGC417L.png'],\n ['163_2b2_Ar_mc_AKGC417L.png'],\n ['133_2p4_Pl_mc_AKGC417L.png'],\n ['174_1p3_Ll_mc_AKGC417L.png'],\n ['162_1b2_Pl_mc_AKGC417L.png'],\n ['162_1b2_Tc_mc_AKGC417L.png'],\n ['172_1b4_Ll_mc_AKGC417L.png'],\n ['191_2b1_Pr_mc_LittC2SE.png'],\n ['204_7p5_Pr_mc_AKGC417L.png'],\n ['193_1b2_Al_mc_AKGC417L.png'],\n ['135_2b1_Al_mc_LittC2SE.png'],\n ['107_2b4_Lr_mc_AKGC417L.png'],\n ['154_1b3_Lr_mc_AKGC417L.png'],\n ['107_3p2_Pl_mc_AKGC417L.png'],\n ['219_2b2_Tc_mc_LittC2SE.png'],\n ['170_1b4_Lr_mc_AKGC417L.png'],\n ['158_1p4_Ar_mc_AKGC417L.png'],\n ['135_2b2_Ar_mc_LittC2SE.png'],\n ['207_2b3_Tc_mc_AKGC417L.png'],\n ['163_2b2_Ll_mc_AKGC417L.png'],\n ['130_2b3_Tc_mc_AKGC417L.png'],\n ['123_1b1_Al_sc_Meditron.png'],\n ['145_2b2_Pr_mc_AKGC417L.png'],\n ['145_3b4_Pl_mc_AKGC417L.png'],\n ['160_1b3_Pl_mc_AKGC417L.png'],\n ['150_1b2_Al_sc_Meditron.png'],\n ['151_2p3_Tc_mc_AKGC417L.png'],\n ['187_1b1_Ll_sc_Meditron.png'],\n ['204_2b5_Ll_mc_AKGC417L.png'],\n ['138_1p3_Tc_mc_AKGC417L.png'],\n ['133_2p4_Tc_mc_AKGC417L.png'],\n ['160_2b4_Tc_mc_AKGC417L.png'],\n ['156_2b3_Pr_mc_AKGC417L.png'],\n ['160_1b4_Al_mc_AKGC417L.png'],\n ['176_1b4_Pr_mc_AKGC417L.png'],\n ['207_3b2_Ar_mc_AKGC417L.png'],\n ['176_1b3_Pr_mc_AKGC417L.png'],\n ['176_2b3_Ar_mc_AKGC417L.png'],\n ['186_3b3_Pl_mc_AKGC417L.png'],\n ['148_1b1_Al_sc_Meditron.png'],\n ['167_1b1_Al_sc_Meditron.png'],\n ['176_1b4_Al_mc_AKGC417L.png'],\n ['141_1b2_Pr_mc_LittC2SE.png'],\n ['170_2b2_Pr_mc_AKGC417L.png'],\n ['139_1b1_Al_sc_Litt3200.png'],\n ['178_1b2_Ar_mc_AKGC417L.png'],\n ['151_2p2_Ll_mc_AKGC417L.png'],\n ['200_2p3_Pr_mc_AKGC417L.png'],\n ['221_2b2_Pl_mc_LittC2SE.png'],\n ['154_4b4_Ar_mc_AKGC417L.png'],\n ['138_1p2_Lr_mc_AKGC417L.png'],\n ['133_2p4_Ar_mc_AKGC417L.png'],\n ['172_1b4_Pl_mc_AKGC417L.png'],\n ['217_1b1_Tc_sc_Meditron.png'],\n ['222_1b1_Ar_sc_Meditron.png'],\n ['162_2b4_Al_mc_AKGC417L.png'],\n ['199_2b1_Ll_mc_LittC2SE.png'],\n ['130_1p4_Al_mc_AKGC417L.png'],\n ['193_1b2_Pr_mc_AKGC417L.png'],\n ['166_1p1_Ll_sc_Meditron.png'],\n ['174_1p2_Ar_mc_AKGC417L.png'],\n ['153_1b1_Al_sc_Meditron.png'],\n ['101_1b1_Al_sc_Meditron.png'],\n ['130_3b4_Ar_mc_AKGC417L.png'],\n ['146_2b4_Al_mc_AKGC417L.png'],\n ['130_2b3_Lr_mc_AKGC417L.png'],\n ['120_1b1_Ar_sc_Meditron.png'],\n ['177_1b2_Tc_mc_AKGC417L.png'],\n ['178_1b6_Tc_mc_AKGC417L.png'],\n ['207_3b2_Tc_mc_AKGC417L.png'],\n ['197_1b1_Al_sc_Meditron.png'],\n ['207_2b4_Pl_mc_AKGC417L.png'],\n ['200_2p4_Pr_mc_AKGC417L.png'],\n ['174_1p2_Lr_mc_AKGC417L.png'],\n ['130_2b4_Al_mc_AKGC417L.png'],\n ['107_2b3_Ar_mc_AKGC417L.png'],\n ['122_2b3_Al_mc_LittC2SE.png'],\n ['213_1p5_Ar_mc_AKGC417L.png'],\n ['138_1p4_Tc_mc_AKGC417L.png'],\n ['203_1p4_Pl_mc_AKGC417L.png'],\n ['177_1b4_Ar_mc_AKGC417L.png'],\n ['163_2b2_Lr_mc_AKGC417L.png'],\n ['130_1p4_Ll_mc_AKGC417L.png'],\n ['146_8p3_Lr_mc_AKGC417L.png'],\n ['122_2b2_Al_mc_LittC2SE.png'],\n ['151_2p4_Tc_mc_AKGC417L.png'],\n ['146_2b4_Pr_mc_AKGC417L.png'],\n ['107_3p2_Ar_mc_AKGC417L.png'],\n ['206_1b1_Lr_sc_Meditron.png'],\n ['176_1b3_Ll_mc_AKGC417L.png'],\n ['158_1p2_Al_mc_AKGC417L.png'],\n ['213_1p5_Tc_mc_AKGC417L.png'],\n ['157_1b1_Lr_sc_Meditron.png'],\n ['170_1b2_Tc_mc_AKGC417L.png'],\n ['198_1b5_Tc_mc_AKGC417L.png'],\n ['172_1b4_Pr_mc_AKGC417L.png'],\n ['130_3p2_Pl_mc_AKGC417L.png'],\n ['161_1b1_Al_sc_Meditron.png'],\n ['172_1b4_Lr_mc_AKGC417L.png'],\n ['213_1p2_Ar_mc_AKGC417L.png'],\n ['151_3p2_Pl_mc_AKGC417L.png'],\n ['204_7p5_Tc_mc_AKGC417L.png'],\n ['165_1b1_Pl_sc_Meditron.png'],\n ['170_1b4_Al_mc_AKGC417L.png'],\n ['211_1p2_Ar_mc_AKGC417L.png'],\n ['178_1b2_Tc_mc_AKGC417L.png'],\n ['139_1b1_Ll_sc_Litt3200.png'],\n ['151_2p2_Pl_mc_AKGC417L.png'],\n ['177_1b2_Ar_mc_AKGC417L.png'],\n ['130_2b2_Ar_mc_AKGC417L.png'],\n ['160_2b4_Pr_mc_AKGC417L.png'],\n ['174_1p3_Pr_mc_AKGC417L.png'],\n ['160_1b2_Ar_mc_AKGC417L.png'],\n ['201_1b2_Ar_sc_Meditron.png'],\n ['172_1b5_Al_mc_AKGC417L.png'],\n ['114_1b4_Pr_mc_AKGC417L.png'],\n ['161_1b1_Pl_sc_Meditron.png'],\n ['107_2b5_Pl_mc_AKGC417L.png'],\n ['200_2p4_Lr_mc_AKGC417L.png'],\n ['205_3b4_Pl_mc_AKGC417L.png'],\n ['195_1b1_Ar_sc_Litt3200.png'],\n ['130_1p2_Ll_mc_AKGC417L.png'],\n ['104_1b1_Pl_sc_Litt3200.png'],\n ['114_1b4_Lr_mc_AKGC417L.png'],\n ['203_1p2_Al_mc_AKGC417L.png'],\n ['211_2p2_Tc_mc_AKGC417L.png'],\n ['223_1b1_Pl_sc_Meditron.png'],\n ['218_1b1_Pr_sc_Meditron.png'],\n ['158_1p2_Pr_mc_AKGC417L.png'],\n ['158_1b3_Ar_mc_LittC2SE.png'],\n ['172_1b5_Lr_mc_AKGC417L.png'],\n ['151_2p2_Lr_mc_AKGC417L.png'],\n ['163_2b2_Tc_mc_AKGC417L.png'],\n ['114_1b4_Ar_mc_AKGC417L.png'],\n ['176_1b3_Pl_mc_AKGC417L.png'],\n ['130_1p4_Tc_mc_AKGC417L.png'],\n ['193_7b3_Ar_mc_AKGC417L.png'],\n ['194_1b1_Pr_sc_Meditron.png'],\n ['186_2b2_Tc_mc_AKGC417L.png'],\n ['172_1b5_Tc_mc_AKGC417L.png'],\n ['211_2p3_Tc_mc_AKGC417L.png'],\n ['167_1b1_Pr_sc_Meditron.png'],\n ['174_2p3_Ar_mc_AKGC417L.png'],\n ['156_5b3_Al_mc_AKGC417L.png'],\n ['130_1p3_Ll_mc_AKGC417L.png'],\n ['205_2b4_Pl_mc_AKGC417L.png'],\n ['146_8p3_Pr_mc_AKGC417L.png'],\n ['124_1b1_Al_sc_Litt3200.png'],\n ['162_2b3_Lr_mc_AKGC417L.png'],\n ['119_1b1_Ar_sc_Meditron.png'],\n ['121_1p1_Tc_sc_Meditron.png'],\n ['178_1b6_Lr_mc_AKGC417L.png'],\n ['174_1p4_Ll_mc_AKGC417L.png'],\n ['138_1p3_Pr_mc_AKGC417L.png'],\n ['170_1b3_Ll_mc_AKGC417L.png'],\n ['179_1b1_Al_sc_Meditron.png'],\n ['139_1b1_Pl_sc_Litt3200.png'],\n ['130_2p5_Ar_mc_AKGC417L.png'],\n ['186_2b3_Lr_mc_AKGC417L.png'],\n ['154_1b3_Tc_mc_AKGC417L.png'],\n ['130_1p3_Lr_mc_AKGC417L.png'],\n ['180_1b4_Pl_mc_AKGC417L.png'],\n ['222_1b1_Pr_sc_Meditron.png'],\n ['212_2b2_Tc_mc_LittC2SE.png'],\n ['133_2p3_Al_mc_AKGC417L.png'],\n ['130_3b4_Lr_mc_AKGC417L.png'],\n ['195_1b1_Al_sc_Litt3200.png'],\n ['111_1b2_Tc_sc_Meditron.png'],\n ['200_2p4_Ar_mc_AKGC417L.png'],\n ['204_2b5_Ar_mc_AKGC417L.png'],\n ['186_2b2_Pl_mc_AKGC417L.png'],\n ['220_1b2_Al_mc_LittC2SE.png'],\n ['151_3p2_Pr_mc_AKGC417L.png'],\n ['162_2b3_Tc_mc_AKGC417L.png'],\n ['118_1b1_Lr_sc_Litt3200.png'],\n ['219_2b1_Ar_mc_LittC2SE.png'],\n ['200_2p3_Ar_mc_AKGC417L.png'],\n ['221_2b1_Al_mc_LittC2SE.png'],\n ['177_1b4_Pl_mc_AKGC417L.png'],\n ['207_2b4_Pr_mc_AKGC417L.png'],\n ['213_1p5_Pr_mc_AKGC417L.png'],\n ['137_1b1_Ar_sc_Meditron.png'],\n ['193_1b2_Ar_mc_AKGC417L.png'],\n ['130_1p3_Pl_mc_AKGC417L.png'],\n ['207_3b2_Pr_mc_AKGC417L.png'],\n ['107_2b4_Pr_mc_AKGC417L.png'],\n ['203_1p3_Ar_mc_AKGC417L.png'],\n ['178_1b2_Pl_mc_AKGC417L.png'],\n ['107_3p2_Lr_mc_AKGC417L.png'],\n ['154_1b3_Al_mc_AKGC417L.png'],\n ['162_2b3_Pl_mc_AKGC417L.png'],\n ['207_2b3_Al_mc_AKGC417L.png'],\n ['174_2p3_Pr_mc_AKGC417L.png'],\n ['172_1b3_Al_mc_AKGC417L.png'],\n ['166_1p1_Pr_sc_Meditron.png'],\n ['186_3b3_Al_mc_AKGC417L.png'],\n ['154_1b3_Pl_mc_AKGC417L.png'],\n ['107_3p2_Al_mc_AKGC417L.png'],\n ['191_2b1_Pl_mc_LittC2SE.png'],\n ['180_1b4_Ar_mc_AKGC417L.png'],\n ['213_1p5_Al_mc_AKGC417L.png'],\n ['176_2b3_Ll_mc_AKGC417L.png'],\n ['130_2b2_Al_mc_AKGC417L.png'],\n ['138_1p4_Lr_mc_AKGC417L.png'],\n ['107_2b5_Al_mc_AKGC417L.png'],\n ['151_2p2_Ar_mc_AKGC417L.png'],\n ['163_8b3_Al_mc_AKGC417L.png'],\n ['163_8b3_Pl_mc_AKGC417L.png'],\n ['145_2b2_Al_mc_AKGC417L.png'],\n ['121_1b1_Tc_sc_Meditron.png'],\n ['118_1b1_Ar_sc_Litt3200.png'],\n ['130_1p3_Al_mc_AKGC417L.png'],\n ['112_1p1_Pl_sc_Litt3200.png'],\n ['138_1p2_Pl_mc_AKGC417L.png'],\n ['152_1b1_Al_sc_Meditron.png'],\n ['201_1b1_Al_sc_Meditron.png'],\n ['219_2b1_Tc_mc_LittC2SE.png'],\n ['147_2b3_Al_mc_AKGC417L.png'],\n ['130_2b3_Pr_mc_AKGC417L.png'],\n ['146_8p3_Pl_mc_AKGC417L.png'],\n ['221_2b1_Lr_mc_LittC2SE.png'],\n ['170_2b2_Tc_mc_AKGC417L.png'],\n ['162_2b3_Al_mc_AKGC417L.png'],\n ['156_5b3_Ar_mc_AKGC417L.png'],\n ['154_1b3_Ll_mc_AKGC417L.png'],\n ['158_1p2_Ar_mc_AKGC417L.png'],\n ['205_4b2_Lr_mc_AKGC417L.png'],\n ['201_1b2_Al_sc_Meditron.png'],\n ['203_1p2_Lr_mc_AKGC417L.png'],\n ['162_2b2_Pr_mc_AKGC417L.png'],\n ['174_1p2_Pl_mc_AKGC417L.png'],\n ['158_1p4_Pr_mc_AKGC417L.png'],\n ['171_1b1_Al_sc_Meditron.png'],\n ['186_2b4_Tc_mc_AKGC417L.png'],\n ['118_1b1_Ll_sc_Litt3200.png'],\n ['159_1b1_Al_sc_Meditron.png'],\n ['188_1b1_Pl_sc_Meditron.png'],\n ['163_8b3_Pr_mc_AKGC417L.png'],\n ['151_2p3_Lr_mc_AKGC417L.png'],\n ['133_2p3_Ar_mc_AKGC417L.png'],\n ['226_1b1_Pl_sc_LittC2SE.png'],\n ['133_2p2_Ar_mc_AKGC417L.png'],\n ['188_1b1_Al_sc_Meditron.png'],\n ['213_1p3_Al_mc_AKGC417L.png'],\n ['110_1b1_Pr_sc_Meditron.png'],\n ['175_1b1_Pl_sc_Litt3200.png'],\n ['213_1p2_Lr_mc_AKGC417L.png'],\n ['145_3b2_Lr_mc_AKGC417L.png'],\n ['193_1b2_Pl_mc_AKGC417L.png'],\n ['213_1p3_Pl_mc_AKGC417L.png'],\n ['109_1b1_Pl_sc_Litt3200.png'],\n ['186_2b4_Lr_mc_AKGC417L.png'],\n ['186_3b3_Lr_mc_AKGC417L.png'],\n ['130_3b3_Ll_mc_AKGC417L.png'],\n ['207_2b4_Ar_mc_AKGC417L.png'],\n ['154_2b4_Pl_mc_AKGC417L.png'],\n ['190_1b1_Tc_sc_Meditron.png'],\n ['168_1b1_Al_sc_Meditron.png'],\n ['158_1p2_Pl_mc_AKGC417L.png'],\n ['138_1p2_Ar_mc_AKGC417L.png'],\n ['145_2b2_Ar_mc_AKGC417L.png'],\n ['203_1p3_Pl_mc_AKGC417L.png'],\n ['107_2b4_Tc_mc_AKGC417L.png'],\n ['130_2b3_Ar_mc_AKGC417L.png'],\n ['193_7b3_Tc_mc_AKGC417L.png'],\n ['207_3b2_Al_mc_AKGC417L.png'],\n ['151_2p4_Ar_mc_AKGC417L.png'],\n ['109_1b1_Pr_sc_Litt3200.png'],\n ['130_2b3_Ll_mc_AKGC417L.png'],\n ['154_4b4_Pr_mc_AKGC417L.png'],\n ['139_1b1_Lr_sc_Litt3200.png'],\n ['160_2b3_Lr_mc_AKGC417L.png'],\n ['151_3p3_Ll_mc_AKGC417L.png'],\n ['145_3b2_Ar_mc_AKGC417L.png'],\n ['170_1b4_Pr_mc_AKGC417L.png'],\n ['104_1b1_Pr_sc_Litt3200.png'],\n ['203_1p2_Tc_mc_AKGC417L.png'],\n ['162_2b4_Pr_mc_AKGC417L.png'],\n ['134_2b2_Ar_mc_LittC2SE.png'],\n ['172_1b4_Ar_mc_AKGC417L.png'],\n ['186_2b3_Pr_mc_AKGC417L.png'],\n ['106_2b1_Pr_mc_LittC2SE.png'],\n ['206_1b1_Pl_sc_Meditron.png'],\n ['154_2b4_Pr_mc_AKGC417L.png'],\n ['193_1b2_Ll_mc_AKGC417L.png'],\n ['102_1b1_Ar_sc_Meditron.png'],\n ['113_1b1_Ll_sc_Litt3200.png'],\n ['156_8b3_Al_mc_AKGC417L.png'],\n ['125_1b1_Tc_sc_Meditron.png'],\n ['200_2p4_Tc_mc_AKGC417L.png'],\n ['109_1b1_Ar_sc_Litt3200.png'],\n ['138_1p3_Al_mc_AKGC417L.png'],\n ['178_1b6_Ar_mc_AKGC417L.png'],\n ['147_2b4_Al_mc_AKGC417L.png'],\n ['156_2b3_Al_mc_AKGC417L.png'],\n ['163_8b3_Ll_mc_AKGC417L.png'],\n ['158_2p2_Ar_mc_AKGC417L.png'],\n ['151_2p4_Al_mc_AKGC417L.png'],\n ['210_1b1_Al_sc_Meditron.png'],\n ['107_2b3_Tc_mc_AKGC417L.png'],\n ['186_2b4_Al_mc_AKGC417L.png'],\n ['177_2b4_Al_mc_AKGC417L.png'],\n ['142_1b1_Pl_mc_LittC2SE.png'],\n ['111_1b3_Tc_sc_Meditron.png'],\n ['154_3b3_Al_mc_AKGC417L.png'],\n ['133_2p2_Al_mc_AKGC417L.png'],\n ['192_2b1_Ar_mc_LittC2SE.png'],\n ['177_1b4_Pr_mc_AKGC417L.png'],\n ['154_1b3_Pr_mc_AKGC417L.png'],\n ['170_2b2_Ar_mc_AKGC417L.png'],\n ['157_1b1_Pr_sc_Meditron.png'],\n ['216_1b1_Pl_sc_Meditron.png'],\n ['193_7b3_Pl_mc_AKGC417L.png'],\n ['172_1b5_Pl_mc_AKGC417L.png'],\n ['174_2p3_Pl_mc_AKGC417L.png'],\n ['183_1b1_Tc_sc_Meditron.png'],\n ['179_1b1_Tc_sc_Meditron.png'],\n ['170_2b2_Al_mc_AKGC417L.png'],\n ['130_2b4_Ar_mc_AKGC417L.png'],\n ['203_1p2_Ar_mc_AKGC417L.png'],\n ['128_1b3_Tc_mc_LittC2SE.png'],\n ['145_2b2_Lr_mc_AKGC417L.png'],\n ['165_1b1_Pr_sc_Meditron.png'],\n ['118_1b1_Pl_sc_Litt3200.png'],\n ['170_1b3_Tc_mc_AKGC417L.png'],\n ['130_1p2_Al_mc_AKGC417L.png'],\n ['147_2b3_Pl_mc_AKGC417L.png'],\n ['205_1b3_Pl_mc_AKGC417L.png'],\n ['219_2b2_Ar_mc_LittC2SE.png'],\n ['154_4b4_Ll_mc_AKGC417L.png'],\n ['154_2b4_Ll_mc_AKGC417L.png'],\n ['172_1b5_Ar_mc_AKGC417L.png'],\n ['185_1b1_Ll_sc_Litt3200.png'],\n ['176_1b4_Ll_mc_AKGC417L.png'],\n ['182_1b1_Tc_sc_Meditron.png'],\n ['156_2b3_Ll_mc_AKGC417L.png'],\n ['122_2b3_Ar_mc_LittC2SE.png'],\n ['175_1b1_Ll_sc_Litt3200.png'],\n ['170_1b4_Pl_mc_AKGC417L.png'],\n ['160_1b2_Pr_mc_AKGC417L.png'],\n ['176_1b3_Al_mc_AKGC417L.png'],\n ['147_2b4_Ll_mc_AKGC417L.png'],\n ['149_1b1_Pl_sc_Meditron.png'],\n ['178_1b2_Pr_mc_AKGC417L.png'],\n ['170_1b3_Pl_mc_AKGC417L.png'],\n ['174_1p3_Tc_mc_AKGC417L.png'],\n ['158_1p3_Al_mc_AKGC417L.png'],\n ['186_2b3_Pl_mc_AKGC417L.png'],\n ['130_3p4_Al_mc_AKGC417L.png'],\n ['130_3p2_Pr_mc_AKGC417L.png'],\n ['133_2p3_Tc_mc_AKGC417L.png'],\n ['133_3p2_Pl_mc_AKGC417L.png'],\n ['207_2b2_Ar_mc_AKGC417L.png'],\n ['151_2p3_Pr_mc_AKGC417L.png'],\n ['154_2b4_Al_mc_AKGC417L.png'],\n ['116_1b2_Pl_sc_Meditron.png'],\n ['210_1b1_Ar_sc_Meditron.png'],\n ['137_1b1_Ll_sc_Meditron.png'],\n ['177_2b4_Lr_mc_AKGC417L.png'],\n ['151_3p2_Al_mc_AKGC417L.png'],\n ['131_1b1_Al_sc_Meditron.png'],\n ['151_2p2_Al_mc_AKGC417L.png'],\n ['226_1b1_Ll_sc_Meditron.png'],\n ['178_1b3_Ar_mc_AKGC417L.png'],\n ['219_2b3_Tc_mc_LittC2SE.png'],\n ['186_2b2_Ar_mc_AKGC417L.png'],\n ['157_1b1_Al_sc_Meditron.png'],\n ['203_2p3_Pr_mc_AKGC417L.png'],\n ['213_2p2_Tc_mc_AKGC417L.png'],\n ['218_1b1_Pl_sc_Meditron.png'],\n ['151_2p3_Pl_mc_AKGC417L.png'],\n ['172_1b3_Ll_mc_AKGC417L.png'],\n ['132_2b2_Lr_mc_LittC2SE.png'],\n ['218_1b1_Al_sc_Meditron.png'],\n ['180_1b4_Lr_mc_AKGC417L.png'],\n ['185_1b1_Pl_sc_Litt3200.png'],\n ['138_1p4_Pr_mc_AKGC417L.png'],\n ['110_1p1_Al_sc_Meditron.png'],\n ['170_1b3_Pr_mc_AKGC417L.png'],\n ['221_2b3_Al_mc_LittC2SE.png'],\n ['130_3p3_Pl_mc_AKGC417L.png'],\n ['214_1b1_Ar_sc_Meditron.png'],\n ['130_1p2_Ar_mc_AKGC417L.png'],\n ['107_2b3_Pr_mc_AKGC417L.png'],\n ['186_3b3_Tc_mc_AKGC417L.png'],\n ['127_1b1_Ar_sc_Meditron.png'],\n ['120_1b1_Pr_sc_Meditron.png'],\n ['107_2b4_Al_mc_AKGC417L.png'],\n ['162_2b4_Tc_mc_AKGC417L.png'],\n ['107_2b4_Ll_mc_AKGC417L.png'],\n ['107_2b3_Ll_mc_AKGC417L.png'],\n ['218_1p1_Ar_sc_Litt3200.png'],\n ['138_2p2_Lr_mc_AKGC417L.png'],\n ['178_1b3_Pr_mc_AKGC417L.png'],\n ['130_3b4_Al_mc_AKGC417L.png'],\n ['112_1b1_Ar_sc_Meditron.png'],\n ['160_1b2_Lr_mc_AKGC417L.png'],\n ['195_1b1_Pl_sc_Litt3200.png'],\n ['177_1b4_Al_mc_AKGC417L.png'],\n ['115_1b1_Ar_sc_Meditron.png'],\n ['204_2b5_Al_mc_AKGC417L.png'],\n ['186_2b3_Tc_mc_AKGC417L.png'],\n ['183_1b1_Pl_sc_Meditron.png'],\n ['147_2b3_Lr_mc_AKGC417L.png'],\n ['200_3p4_Tc_mc_AKGC417L.png'],\n ['203_1p3_Al_mc_AKGC417L.png'],\n ['104_1b1_Ll_sc_Litt3200.png'],\n ['110_1p1_Lr_sc_Meditron.png'],\n ['172_1b4_Tc_mc_AKGC417L.png'],\n ['170_1b2_Al_mc_AKGC417L.png'],\n ['157_1b1_Pl_sc_Meditron.png'],\n ['172_2b5_Pl_mc_AKGC417L.png'],\n ['163_8b3_Lr_mc_AKGC417L.png'],\n ['174_1p3_Ar_mc_AKGC417L.png'],\n ['177_1b4_Lr_mc_AKGC417L.png'],\n ['120_1b1_Pl_sc_Meditron.png'],\n ['193_1b4_Lr_mc_AKGC417L.png'],\n ['186_2b3_Ar_mc_AKGC417L.png'],\n ['107_2b5_Pr_mc_AKGC417L.png'],\n ['175_1b1_Al_sc_Litt3200.png'],\n ['140_2b3_Tc_mc_LittC2SE.png'],\n ['200_2p2_Pl_mc_AKGC417L.png'],\n ['162_2b3_Ar_mc_AKGC417L.png'],\n ['158_1p3_Ar_mc_AKGC417L.png'],\n ['205_3b4_Al_mc_AKGC417L.png'],\n ['130_2b4_Ll_mc_AKGC417L.png'],\n ['130_3p3_Tc_mc_AKGC417L.png'],\n ['130_3p2_Tc_mc_AKGC417L.png'],\n ['203_1p3_Pr_mc_AKGC417L.png'],\n ['172_1b5_Pr_mc_AKGC417L.png'],\n ['130_1p2_Pl_mc_AKGC417L.png'],\n ['151_2p2_Tc_mc_AKGC417L.png'],\n ['193_7b3_Al_mc_AKGC417L.png'],\n ['207_2b2_Pl_mc_AKGC417L.png'],\n ['118_1b1_Pr_sc_Litt3200.png'],\n ['107_2b3_Al_mc_AKGC417L.png'],\n ['170_1b3_Ar_mc_AKGC417L.png'],\n ['174_1p4_Pl_mc_AKGC417L.png'],\n ['178_1b6_Pl_mc_AKGC417L.png'],\n ['223_1b1_Lr_sc_Meditron.png'],\n ['138_2p2_Ar_mc_AKGC417L.png'],\n ['130_1p4_Pr_mc_AKGC417L.png'],\n ['186_2b3_Al_mc_AKGC417L.png'],\n ['178_2b2_Pr_mc_AKGC417L.png'],\n ['172_1b4_Al_mc_AKGC417L.png'],\n ['223_1b1_Ll_sc_Meditron.png'],\n ['186_3b3_Pr_mc_AKGC417L.png'],\n ['170_1b2_Pr_mc_AKGC417L.png'],\n ['221_2b2_Ar_mc_LittC2SE.png'],\n ['135_2b1_Pl_mc_LittC2SE.png'],\n ['211_1p5_Ar_mc_AKGC417L.png'],\n ['221_2b1_Ar_mc_LittC2SE.png'],\n ['162_2b2_Ar_mc_AKGC417L.png'],\n ['204_7p5_Al_mc_AKGC417L.png'],\n ['107_2b4_Pl_mc_AKGC417L.png'],\n ['135_2b3_Pl_mc_LittC2SE.png'],\n ['147_2b4_Ar_mc_AKGC417L.png'],\n ['223_1b1_Pr_sc_Meditron.png'],\n ['209_1b1_Tc_sc_Meditron.png'],\n ['224_1b2_Al_sc_Meditron.png'],\n ['203_1p4_Pr_mc_AKGC417L.png'],\n ['163_2b2_Al_mc_AKGC417L.png'],\n ['169_1b1_Lr_sc_Meditron.png'],\n ['160_1b3_Tc_mc_AKGC417L.png'],\n ['178_2b2_Al_mc_AKGC417L.png'],\n ['207_2b3_Pl_mc_AKGC417L.png'],\n ['218_1b1_Lr_sc_Meditron.png'],\n ['154_2b4_Lr_mc_AKGC417L.png'],\n ['207_3b2_Pl_mc_AKGC417L.png'],\n ['135_2b3_Ar_mc_LittC2SE.png'],\n ['195_1b1_Lr_sc_Litt3200.png'],\n ['138_1p3_Ar_mc_AKGC417L.png'],\n ['200_2p3_Al_mc_AKGC417L.png'],\n ['149_1b1_Lr_sc_Meditron.png'],\n ['172_1b3_Pl_mc_AKGC417L.png'],\n ['159_1b1_Ar_sc_Meditron.png'],\n ['130_2b4_Lr_mc_AKGC417L.png'],\n ['105_1b1_Tc_sc_Meditron.png'],\n ['189_1b2_Lr_mc_LittC2SE.png'],\n ['193_1b2_Tc_mc_AKGC417L.png'],\n ['160_1b2_Tc_mc_AKGC417L.png'],\n ['156_8b3_Ar_mc_AKGC417L.png'],\n ['130_1p2_Lr_mc_AKGC417L.png'],\n ['174_1p4_Pr_mc_AKGC417L.png'],\n ['180_1b4_Pr_mc_AKGC417L.png'],\n ['160_1b4_Pl_mc_AKGC417L.png'],\n ['110_1p1_Pr_sc_Meditron.png'],\n ['185_1b1_Al_sc_Litt3200.png'],\n ['194_1b1_Lr_sc_Meditron.png'],\n ['163_2b2_Pr_mc_AKGC417L.png'],\n ['198_1b5_Al_mc_AKGC417L.png'],\n ['200_2p2_Lr_mc_AKGC417L.png'],\n ['203_1p2_Pl_mc_AKGC417L.png'],\n ['186_2b2_Pr_mc_AKGC417L.png'],\n ['151_2p4_Pl_mc_AKGC417L.png'],\n ['154_4b4_Lr_mc_AKGC417L.png'],\n ['177_1b4_Tc_mc_AKGC417L.png'],\n ['205_4b2_Ar_mc_AKGC417L.png'],\n ['172_2b5_Pr_mc_AKGC417L.png'],\n ['176_1b4_Ar_mc_AKGC417L.png'],\n ['163_8b3_Ar_mc_AKGC417L.png'],\n ['223_1b1_Al_sc_Meditron.png'],\n ['205_2b3_Al_mc_AKGC417L.png'],\n ['221_2b3_Ar_mc_LittC2SE.png'],\n ['198_6p1_Pr_mc_AKGC417L.png'],\n ['221_2b1_Pl_mc_LittC2SE.png'],\n ['134_2b1_Ar_mc_LittC2SE.png'],\n ['186_2b4_Pl_mc_AKGC417L.png'],\n ['160_1b4_Lr_mc_AKGC417L.png'],\n ['146_8p3_Al_mc_AKGC417L.png'],\n ['139_1b1_Pr_sc_Litt3200.png'],\n ['155_2b1_Al_mc_LittC2SE.png'],\n ['154_1b3_Ar_mc_AKGC417L.png'],\n ['156_5b3_Ll_mc_AKGC417L.png'],\n ['113_1b1_Lr_sc_Litt3200.png'],\n ['124_1b1_Pl_sc_Litt3200.png'],\n ['177_2b4_Pl_mc_AKGC417L.png'],\n ['104_1b1_Lr_sc_Litt3200.png'],\n ['162_2b4_Lr_mc_AKGC417L.png'],\n ['160_1b3_Ar_mc_AKGC417L.png'],\n ['226_1b1_Al_sc_Meditron.png'],\n ['207_3b2_Lr_mc_AKGC417L.png'],\n ['130_2b2_Tc_mc_AKGC417L.png'],\n ['192_2b2_Ar_mc_LittC2SE.png'],\n ['200_3p4_Pr_mc_AKGC417L.png'],\n ['156_2b3_Lr_mc_AKGC417L.png'],\n ['133_2p2_Pl_mc_AKGC417L.png'],\n ['178_1b2_Al_mc_AKGC417L.png'],\n ['177_2b4_Tc_mc_AKGC417L.png'],\n ['223_1b1_Ar_sc_Meditron.png'],\n ['135_2b1_Ar_mc_LittC2SE.png'],\n ['138_1p4_Pl_mc_AKGC417L.png'],\n ['178_1b6_Al_mc_AKGC417L.png'],\n ['130_2b2_Lr_mc_AKGC417L.png'],\n ['158_1p3_Lr_mc_AKGC417L.png'],\n ['138_1p2_Tc_mc_AKGC417L.png'],\n ['130_1p4_Ar_mc_AKGC417L.png'],\n ['141_1b2_Lr_mc_LittC2SE.png'],\n ['146_2b4_Ar_mc_AKGC417L.png'],\n ['177_2b4_Pr_mc_AKGC417L.png'],\n ['198_1b5_Pl_mc_AKGC417L.png'],\n ['175_1b1_Ar_sc_Litt3200.png'],\n ['134_2b1_Al_mc_LittC2SE.png'],\n ['114_1b4_Pl_mc_AKGC417L.png'],\n ['170_1b4_Ar_mc_AKGC417L.png'],\n ['139_1b1_Ar_sc_Litt3200.png'],\n ['158_2p3_Tc_mc_AKGC417L.png'],\n ['185_1b1_Lr_sc_Litt3200.png'],\n ['165_1b1_Ar_sc_Meditron.png'],\n ['174_1p2_Ll_mc_AKGC417L.png'],\n ['203_1p4_Ar_mc_AKGC417L.png'],\n ['112_1b1_Lr_sc_Meditron.png'],\n ['158_2p3_Lr_mc_AKGC417L.png'],\n ['130_3p4_Pr_mc_AKGC417L.png'],\n ['151_2p2_Pr_mc_AKGC417L.png'],\n ['146_2b2_Pl_mc_AKGC417L.png'],\n ['158_1p2_Tc_mc_AKGC417L.png'],\n ['181_1b1_Ar_mc_LittC2SE.png'],\n ['132_2b1_Lr_mc_LittC2SE.png'],\n ['130_1p3_Pr_mc_AKGC417L.png'],\n ['130_2b4_Pl_mc_AKGC417L.png'],\n ['160_1b4_Ar_mc_AKGC417L.png'],\n ['138_2p2_Pl_mc_AKGC417L.png'],\n ['162_1b2_Pr_mc_AKGC417L.png'],\n ['138_2p2_Pr_mc_AKGC417L.png'],\n ['138_1p2_Al_mc_AKGC417L.png'],\n ['146_2b4_Lr_mc_AKGC417L.png'],\n ['109_1b1_Ll_sc_Litt3200.png'],\n ['158_1p3_Tc_mc_AKGC417L.png'],\n ['186_2b2_Al_mc_AKGC417L.png'],\n ['173_1b1_Al_sc_Meditron.png'],\n ['181_1b1_Tc_mc_LittC2SE.png'],\n ['124_1b1_Pr_sc_Litt3200.png'],\n ['174_1p3_Lr_mc_AKGC417L.png'],\n ['156_5b3_Lr_mc_AKGC417L.png'],\n ['185_1b1_Pr_sc_Litt3200.png'],\n ['134_2b2_Al_mc_LittC2SE.png'],\n ['172_1b3_Ar_mc_AKGC417L.png'],\n ['174_1p4_Lr_mc_AKGC417L.png'],\n ['175_1b1_Lr_sc_Litt3200.png'],\n ['107_2b5_Ar_mc_AKGC417L.png'],\n ['174_1p2_Tc_mc_AKGC417L.png'],\n ['211_1p3_Ar_mc_AKGC417L.png'],\n ['166_1p1_Al_sc_Meditron.png'],\n ['186_2b2_Lr_mc_AKGC417L.png'],\n ['184_1b1_Ar_sc_Meditron.png'],\n ['203_1p2_Pr_mc_AKGC417L.png'],\n ['160_1b2_Pl_mc_AKGC417L.png'],\n ['213_2p2_Al_mc_AKGC417L.png']]"},"metadata":{}}]},{"cell_type":"code","source":"labels = []\nfor i in range(len(req_file_names)):\n    req_file_names[i].append(sr_no[req_file_names[i][0][:3]])\n    labels.append(sr_no[req_file_names[i][0][:3]])","metadata":{"id":"LCKsXMpUvggI","execution":{"iopub.status.busy":"2023-08-12T03:46:46.049687Z","iopub.execute_input":"2023-08-12T03:46:46.050074Z","iopub.status.idle":"2023-08-12T03:46:46.057263Z","shell.execute_reply.started":"2023-08-12T03:46:46.050042Z","shell.execute_reply":"2023-08-12T03:46:46.056205Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"labels *= 3","metadata":{"execution":{"iopub.status.busy":"2023-08-12T03:46:46.726570Z","iopub.execute_input":"2023-08-12T03:46:46.727248Z","iopub.status.idle":"2023-08-12T03:46:46.732098Z","shell.execute_reply.started":"2023-08-12T03:46:46.727211Z","shell.execute_reply":"2023-08-12T03:46:46.731116Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"x = []\n\nfor i in req_file_names:\n    img = cv2.imread('/kaggle/input/mel-spectrogram-data/Mel Spectrogram/Time Stretch/'+i[0])\n    img = cv2.resize(img, (350, 350))\n    x.append(img)\n\nfor i in req_file_names:\n    img = cv2.imread('/kaggle/input/mel-spectrogram-data/Mel Spectrogram/Pitch Shift/'+i[0])\n    img = cv2.resize(img, (350, 350))\n    x.append(img)\n    \nfor i in req_file_names:\n    img = cv2.imread('/kaggle/input/mel-spectrogram-data/Mel Spectrogram/Audio Shift/'+i[0])\n    img = cv2.resize(img, (350, 350))\n    x.append(img)\n\nx = np.array(x)\nprint(x.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PoMb8etvpAk","outputId":"65cd04d4-ba35-460e-b497-d9b5ac091122","execution":{"iopub.status.busy":"2023-08-12T03:46:49.323638Z","iopub.execute_input":"2023-08-12T03:46:49.324328Z","iopub.status.idle":"2023-08-12T03:47:40.904263Z","shell.execute_reply.started":"2023-08-12T03:46:49.324293Z","shell.execute_reply":"2023-08-12T03:47:40.902887Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(2760, 350, 350, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"req_file_names *= 3","metadata":{"execution":{"iopub.status.busy":"2023-08-12T03:47:40.906091Z","iopub.execute_input":"2023-08-12T03:47:40.907043Z","iopub.status.idle":"2023-08-12T03:47:40.911664Z","shell.execute_reply.started":"2023-08-12T03:47:40.907007Z","shell.execute_reply":"2023-08-12T03:47:40.910388Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"y = np.array(labels)\ny.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbwY828LxkMZ","outputId":"54c8937f-563d-41af-c159-3bd798c5cdf0","execution":{"iopub.status.busy":"2023-08-12T03:47:40.913091Z","iopub.execute_input":"2023-08-12T03:47:40.913481Z","iopub.status.idle":"2023-08-12T03:47:40.936883Z","shell.execute_reply.started":"2023-08-12T03:47:40.913447Z","shell.execute_reply":"2023-08-12T03:47:40.935824Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(2760,)"},"metadata":{}}]},{"cell_type":"code","source":"one_hot_y = np.array(pd.get_dummies(labels))","metadata":{"id":"bTiogsRk3ujL","execution":{"iopub.status.busy":"2023-08-12T03:47:40.939532Z","iopub.execute_input":"2023-08-12T03:47:40.939857Z","iopub.status.idle":"2023-08-12T03:47:40.954462Z","shell.execute_reply.started":"2023-08-12T03:47:40.939826Z","shell.execute_reply":"2023-08-12T03:47:40.953510Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, one_hot_y, test_size=0.4, random_state=33, stratify=y)\nprint(x_train.shape, y_train.shape, x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T03:47:40.956841Z","iopub.execute_input":"2023-08-12T03:47:40.957109Z","iopub.status.idle":"2023-08-12T03:47:41.209314Z","shell.execute_reply.started":"2023-08-12T03:47:40.957086Z","shell.execute_reply":"2023-08-12T03:47:41.208167Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(1656, 350, 350, 3) (1656, 8) (1104, 350, 350, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"cnn = keras.models.Sequential()\ncnn.add(keras.layers.Conv2D(32, \n                              kernel_size=(3,3), \n                              activation='relu', \n                              strides=(1,1), \n                              input_shape=(350, 350, 3)))\ncnn.add(keras.layers.MaxPooling2D((2,2)))\ncnn.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\ncnn.add(keras.layers.MaxPooling2D((4,4)))\ncnn.add(keras.layers.Dropout(0.2))\ncnn.add(keras.layers.Flatten())\ncnn.add(keras.layers.Dense(128, activation='relu'))\ncnn.add(keras.layers.Dense(64, activation='relu'))\ncnn.add(keras.layers.Dense(8, activation='softmax'))\n\nprint(cnn.summary())\n\ncnn.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(1e-5), metrics=['accuracy'])\n\nhistory_cnn = cnn.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-12T03:48:01.758398Z","iopub.execute_input":"2023-08-12T03:48:01.758742Z","iopub.status.idle":"2023-08-12T03:52:53.355810Z","shell.execute_reply.started":"2023-08-12T03:48:01.758712Z","shell.execute_reply":"2023-08-12T03:52:53.354833Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 348, 348, 32)      896       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 174, 174, 32)     0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 172, 172, 64)      18496     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 43, 43, 64)       0         \n 2D)                                                             \n                                                                 \n dropout (Dropout)           (None, 43, 43, 64)        0         \n                                                                 \n flatten (Flatten)           (None, 118336)            0         \n                                                                 \n dense (Dense)               (None, 128)               15147136  \n                                                                 \n dense_1 (Dense)             (None, 64)                8256      \n                                                                 \n dense_2 (Dense)             (None, 8)                 520       \n                                                                 \n=================================================================\nTotal params: 15,175,304\nTrainable params: 15,175,304\nNon-trainable params: 0\n_________________________________________________________________\nNone\nEpoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"2023-08-12 03:48:06.267682: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"52/52 [==============================] - 17s 135ms/step - loss: 9.6286 - accuracy: 0.7512 - val_loss: 5.1447 - val_accuracy: 0.8623\nEpoch 2/60\n52/52 [==============================] - 5s 89ms/step - loss: 4.0557 - accuracy: 0.7705 - val_loss: 2.2058 - val_accuracy: 0.8098\nEpoch 3/60\n52/52 [==============================] - 5s 87ms/step - loss: 2.8920 - accuracy: 0.7893 - val_loss: 1.7787 - val_accuracy: 0.8623\nEpoch 4/60\n52/52 [==============================] - 5s 89ms/step - loss: 2.3114 - accuracy: 0.8043 - val_loss: 1.4625 - val_accuracy: 0.8632\nEpoch 5/60\n52/52 [==============================] - 5s 87ms/step - loss: 2.0671 - accuracy: 0.8062 - val_loss: 2.0019 - val_accuracy: 0.8632\nEpoch 6/60\n52/52 [==============================] - 5s 90ms/step - loss: 2.1416 - accuracy: 0.7995 - val_loss: 2.1462 - val_accuracy: 0.8623\nEpoch 7/60\n52/52 [==============================] - 5s 87ms/step - loss: 1.7696 - accuracy: 0.8267 - val_loss: 1.6384 - val_accuracy: 0.8632\nEpoch 8/60\n52/52 [==============================] - 5s 87ms/step - loss: 1.9138 - accuracy: 0.8128 - val_loss: 0.7890 - val_accuracy: 0.8777\nEpoch 9/60\n52/52 [==============================] - 5s 90ms/step - loss: 1.9356 - accuracy: 0.8231 - val_loss: 0.9548 - val_accuracy: 0.8786\nEpoch 10/60\n52/52 [==============================] - 5s 89ms/step - loss: 1.7022 - accuracy: 0.8249 - val_loss: 0.5916 - val_accuracy: 0.8859\nEpoch 11/60\n52/52 [==============================] - 5s 87ms/step - loss: 1.2963 - accuracy: 0.8490 - val_loss: 0.7443 - val_accuracy: 0.8723\nEpoch 12/60\n52/52 [==============================] - 5s 89ms/step - loss: 1.5857 - accuracy: 0.8200 - val_loss: 1.3357 - val_accuracy: 0.8623\nEpoch 13/60\n52/52 [==============================] - 5s 89ms/step - loss: 1.4302 - accuracy: 0.8478 - val_loss: 1.9618 - val_accuracy: 0.8804\nEpoch 14/60\n52/52 [==============================] - 5s 87ms/step - loss: 1.5824 - accuracy: 0.8466 - val_loss: 0.6624 - val_accuracy: 0.8813\nEpoch 15/60\n52/52 [==============================] - 5s 89ms/step - loss: 1.3255 - accuracy: 0.8388 - val_loss: 0.8615 - val_accuracy: 0.8832\nEpoch 16/60\n52/52 [==============================] - 5s 91ms/step - loss: 1.2219 - accuracy: 0.8424 - val_loss: 1.5422 - val_accuracy: 0.8623\nEpoch 17/60\n52/52 [==============================] - 5s 89ms/step - loss: 1.1243 - accuracy: 0.8545 - val_loss: 0.9223 - val_accuracy: 0.8895\nEpoch 18/60\n52/52 [==============================] - 5s 89ms/step - loss: 1.1273 - accuracy: 0.8514 - val_loss: 0.6006 - val_accuracy: 0.8868\nEpoch 19/60\n52/52 [==============================] - 5s 87ms/step - loss: 1.1081 - accuracy: 0.8611 - val_loss: 0.6818 - val_accuracy: 0.8976\nEpoch 20/60\n52/52 [==============================] - 5s 87ms/step - loss: 0.9884 - accuracy: 0.8671 - val_loss: 0.5290 - val_accuracy: 0.8949\nEpoch 21/60\n52/52 [==============================] - 5s 87ms/step - loss: 0.9198 - accuracy: 0.8714 - val_loss: 1.1022 - val_accuracy: 0.8696\nEpoch 22/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.9789 - accuracy: 0.8635 - val_loss: 0.4873 - val_accuracy: 0.9085\nEpoch 23/60\n52/52 [==============================] - 5s 88ms/step - loss: 0.8497 - accuracy: 0.8835 - val_loss: 0.8188 - val_accuracy: 0.8913\nEpoch 24/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.9621 - accuracy: 0.8665 - val_loss: 0.7255 - val_accuracy: 0.8931\nEpoch 25/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.7373 - accuracy: 0.8726 - val_loss: 0.8811 - val_accuracy: 0.8976\nEpoch 26/60\n52/52 [==============================] - 4s 86ms/step - loss: 0.9890 - accuracy: 0.8732 - val_loss: 0.4823 - val_accuracy: 0.8877\nEpoch 27/60\n52/52 [==============================] - 5s 87ms/step - loss: 0.8370 - accuracy: 0.8895 - val_loss: 0.5441 - val_accuracy: 0.9112\nEpoch 28/60\n52/52 [==============================] - 5s 90ms/step - loss: 0.6423 - accuracy: 0.9004 - val_loss: 0.4109 - val_accuracy: 0.9203\nEpoch 29/60\n52/52 [==============================] - 5s 90ms/step - loss: 0.7203 - accuracy: 0.8883 - val_loss: 0.7047 - val_accuracy: 0.8958\nEpoch 30/60\n52/52 [==============================] - 5s 90ms/step - loss: 0.8599 - accuracy: 0.8738 - val_loss: 0.6903 - val_accuracy: 0.9040\nEpoch 31/60\n52/52 [==============================] - 5s 88ms/step - loss: 0.5810 - accuracy: 0.8889 - val_loss: 0.4667 - val_accuracy: 0.9149\nEpoch 32/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.5772 - accuracy: 0.9058 - val_loss: 0.6210 - val_accuracy: 0.9049\nEpoch 33/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.5873 - accuracy: 0.8979 - val_loss: 0.6838 - val_accuracy: 0.8931\nEpoch 34/60\n52/52 [==============================] - 5s 87ms/step - loss: 0.5948 - accuracy: 0.8937 - val_loss: 0.6235 - val_accuracy: 0.9085\nEpoch 35/60\n52/52 [==============================] - 5s 87ms/step - loss: 0.6193 - accuracy: 0.8931 - val_loss: 0.6414 - val_accuracy: 0.9022\nEpoch 36/60\n52/52 [==============================] - 5s 90ms/step - loss: 0.5367 - accuracy: 0.8961 - val_loss: 0.3679 - val_accuracy: 0.9312\nEpoch 37/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.5300 - accuracy: 0.9094 - val_loss: 0.6603 - val_accuracy: 0.8976\nEpoch 38/60\n52/52 [==============================] - 5s 87ms/step - loss: 0.6031 - accuracy: 0.8961 - val_loss: 0.8605 - val_accuracy: 0.8904\nEpoch 39/60\n52/52 [==============================] - 5s 90ms/step - loss: 0.4878 - accuracy: 0.9118 - val_loss: 0.7582 - val_accuracy: 0.8931\nEpoch 40/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.5169 - accuracy: 0.9094 - val_loss: 0.6239 - val_accuracy: 0.9121\nEpoch 41/60\n52/52 [==============================] - 5s 87ms/step - loss: 0.3925 - accuracy: 0.9179 - val_loss: 0.3649 - val_accuracy: 0.9239\nEpoch 42/60\n52/52 [==============================] - 4s 87ms/step - loss: 0.4590 - accuracy: 0.9130 - val_loss: 0.4336 - val_accuracy: 0.9293\nEpoch 43/60\n52/52 [==============================] - 5s 88ms/step - loss: 0.4045 - accuracy: 0.9179 - val_loss: 0.4649 - val_accuracy: 0.9203\nEpoch 44/60\n52/52 [==============================] - 5s 87ms/step - loss: 0.4076 - accuracy: 0.9136 - val_loss: 0.4291 - val_accuracy: 0.9112\nEpoch 45/60\n52/52 [==============================] - 5s 87ms/step - loss: 0.3302 - accuracy: 0.9209 - val_loss: 0.2896 - val_accuracy: 0.9312\nEpoch 46/60\n52/52 [==============================] - 5s 87ms/step - loss: 0.3827 - accuracy: 0.9281 - val_loss: 0.3913 - val_accuracy: 0.8986\nEpoch 47/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.3418 - accuracy: 0.9318 - val_loss: 0.4035 - val_accuracy: 0.9257\nEpoch 48/60\n52/52 [==============================] - 4s 86ms/step - loss: 0.3014 - accuracy: 0.9269 - val_loss: 0.4625 - val_accuracy: 0.9176\nEpoch 49/60\n52/52 [==============================] - 4s 87ms/step - loss: 0.4472 - accuracy: 0.9088 - val_loss: 0.3397 - val_accuracy: 0.9330\nEpoch 50/60\n52/52 [==============================] - 5s 88ms/step - loss: 0.4393 - accuracy: 0.9149 - val_loss: 0.3462 - val_accuracy: 0.9402\nEpoch 51/60\n52/52 [==============================] - 5s 87ms/step - loss: 0.5724 - accuracy: 0.8998 - val_loss: 0.4607 - val_accuracy: 0.9194\nEpoch 52/60\n52/52 [==============================] - 5s 87ms/step - loss: 0.2455 - accuracy: 0.9360 - val_loss: 0.4064 - val_accuracy: 0.9275\nEpoch 53/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.3215 - accuracy: 0.9281 - val_loss: 0.4593 - val_accuracy: 0.9094\nEpoch 54/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.2615 - accuracy: 0.9457 - val_loss: 0.5163 - val_accuracy: 0.9185\nEpoch 55/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.2925 - accuracy: 0.9336 - val_loss: 0.4614 - val_accuracy: 0.9130\nEpoch 56/60\n52/52 [==============================] - 5s 90ms/step - loss: 0.3001 - accuracy: 0.9342 - val_loss: 0.4383 - val_accuracy: 0.9303\nEpoch 57/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.3375 - accuracy: 0.9263 - val_loss: 0.3264 - val_accuracy: 0.9212\nEpoch 58/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.2731 - accuracy: 0.9408 - val_loss: 0.3392 - val_accuracy: 0.9239\nEpoch 59/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.2615 - accuracy: 0.9402 - val_loss: 0.4506 - val_accuracy: 0.9239\nEpoch 60/60\n52/52 [==============================] - 5s 89ms/step - loss: 0.2636 - accuracy: 0.9360 - val_loss: 0.3663 - val_accuracy: 0.9366\n","output_type":"stream"}]},{"cell_type":"code","source":"cnn_bigru = keras.models.Sequential()\ncnn_bigru.add(keras.layers.Conv2D(32, \n                              kernel_size=(3,3), \n                              activation='relu', \n                              strides=(1,1), \n                              input_shape=(350, 350, 3)))\ncnn_bigru.add(keras.layers.MaxPooling2D((2,2)))\ncnn_bigru.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\ncnn_bigru.add(keras.layers.Dropout(0.2))\ncnn_bigru.add(keras.layers.MaxPooling2D((4,4)))\ncnn_bigru.add(keras.layers.Reshape((-1, 64)))\n\ncnn_bigru.add(keras.layers.Bidirectional(keras.layers.GRU(64, activation='tanh', return_sequences=True)))\ncnn_bigru.add(keras.layers.Bidirectional(keras.layers.GRU(128, activation='tanh', return_sequences=True)))\ncnn_bigru.add(keras.layers.Dropout(0.5))\ncnn_bigru.add(keras.layers.Bidirectional(keras.layers.GRU(64, activation='tanh')))\n\ncnn_bigru.add(keras.layers.Dense(64, activation='relu'))\ncnn_bigru.add(keras.layers.Dense(8, activation='softmax'))\n\ncnn_bigru.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(1e-3), metrics=['accuracy'])\n\nhistory_cnn_bigru = cnn_bigru.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-12T04:29:57.757656Z","iopub.execute_input":"2023-08-12T04:29:57.758057Z","iopub.status.idle":"2023-08-12T05:06:06.302098Z","shell.execute_reply.started":"2023-08-12T04:29:57.758021Z","shell.execute_reply":"2023-08-12T05:06:06.301010Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"2023-08-12 04:30:43.781200: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_5/dropout_9/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"52/52 [==============================] - 83s 693ms/step - loss: 0.6505 - accuracy: 0.8551 - val_loss: 0.5717 - val_accuracy: 0.8623\nEpoch 2/60\n52/52 [==============================] - 36s 701ms/step - loss: 0.5840 - accuracy: 0.8617 - val_loss: 0.5771 - val_accuracy: 0.8623\nEpoch 3/60\n52/52 [==============================] - 36s 696ms/step - loss: 0.5800 - accuracy: 0.8617 - val_loss: 0.5464 - val_accuracy: 0.8623\nEpoch 4/60\n52/52 [==============================] - 33s 645ms/step - loss: 0.5482 - accuracy: 0.8617 - val_loss: 0.5533 - val_accuracy: 0.8623\nEpoch 5/60\n52/52 [==============================] - 33s 645ms/step - loss: 0.5295 - accuracy: 0.8617 - val_loss: 0.5309 - val_accuracy: 0.8623\nEpoch 6/60\n52/52 [==============================] - 36s 701ms/step - loss: 0.5220 - accuracy: 0.8611 - val_loss: 0.6226 - val_accuracy: 0.8623\nEpoch 7/60\n52/52 [==============================] - 33s 644ms/step - loss: 0.5341 - accuracy: 0.8617 - val_loss: 0.5498 - val_accuracy: 0.8623\nEpoch 8/60\n52/52 [==============================] - 36s 702ms/step - loss: 0.5147 - accuracy: 0.8617 - val_loss: 0.5631 - val_accuracy: 0.8623\nEpoch 9/60\n52/52 [==============================] - 36s 702ms/step - loss: 0.5403 - accuracy: 0.8617 - val_loss: 0.5600 - val_accuracy: 0.8623\nEpoch 10/60\n52/52 [==============================] - 36s 699ms/step - loss: 0.5372 - accuracy: 0.8617 - val_loss: 0.5620 - val_accuracy: 0.8623\nEpoch 11/60\n52/52 [==============================] - 36s 695ms/step - loss: 0.5029 - accuracy: 0.8599 - val_loss: 0.5418 - val_accuracy: 0.8623\nEpoch 12/60\n52/52 [==============================] - 36s 697ms/step - loss: 0.4938 - accuracy: 0.8605 - val_loss: 0.5461 - val_accuracy: 0.8623\nEpoch 13/60\n52/52 [==============================] - 33s 645ms/step - loss: 0.5064 - accuracy: 0.8599 - val_loss: 0.5256 - val_accuracy: 0.8623\nEpoch 14/60\n52/52 [==============================] - 33s 644ms/step - loss: 0.5044 - accuracy: 0.8617 - val_loss: 0.4729 - val_accuracy: 0.8623\nEpoch 15/60\n52/52 [==============================] - 36s 701ms/step - loss: 0.4867 - accuracy: 0.8617 - val_loss: 0.5669 - val_accuracy: 0.8578\nEpoch 16/60\n52/52 [==============================] - 33s 642ms/step - loss: 0.4858 - accuracy: 0.8617 - val_loss: 0.4873 - val_accuracy: 0.8623\nEpoch 17/60\n52/52 [==============================] - 36s 701ms/step - loss: 0.4655 - accuracy: 0.8611 - val_loss: 0.4594 - val_accuracy: 0.8623\nEpoch 18/60\n52/52 [==============================] - 36s 700ms/step - loss: 0.4900 - accuracy: 0.8605 - val_loss: 0.5678 - val_accuracy: 0.8587\nEpoch 19/60\n52/52 [==============================] - 36s 700ms/step - loss: 0.4805 - accuracy: 0.8617 - val_loss: 0.6017 - val_accuracy: 0.8623\nEpoch 20/60\n52/52 [==============================] - 36s 695ms/step - loss: 0.4859 - accuracy: 0.8617 - val_loss: 0.5737 - val_accuracy: 0.8623\nEpoch 21/60\n52/52 [==============================] - 33s 643ms/step - loss: 0.4770 - accuracy: 0.8617 - val_loss: 0.5913 - val_accuracy: 0.8596\nEpoch 22/60\n52/52 [==============================] - 36s 702ms/step - loss: 0.4654 - accuracy: 0.8617 - val_loss: 0.5423 - val_accuracy: 0.8569\nEpoch 23/60\n52/52 [==============================] - 36s 699ms/step - loss: 0.4685 - accuracy: 0.8617 - val_loss: 0.4891 - val_accuracy: 0.8623\nEpoch 24/60\n52/52 [==============================] - 33s 645ms/step - loss: 0.4615 - accuracy: 0.8617 - val_loss: 0.5295 - val_accuracy: 0.8623\nEpoch 25/60\n52/52 [==============================] - 33s 646ms/step - loss: 0.4746 - accuracy: 0.8569 - val_loss: 0.4985 - val_accuracy: 0.8623\nEpoch 26/60\n52/52 [==============================] - 36s 700ms/step - loss: 0.4605 - accuracy: 0.8599 - val_loss: 0.5348 - val_accuracy: 0.8623\nEpoch 27/60\n52/52 [==============================] - 36s 700ms/step - loss: 0.4643 - accuracy: 0.8605 - val_loss: 0.5702 - val_accuracy: 0.8623\nEpoch 28/60\n52/52 [==============================] - 36s 695ms/step - loss: 0.4490 - accuracy: 0.8617 - val_loss: 0.5392 - val_accuracy: 0.8623\nEpoch 29/60\n52/52 [==============================] - 36s 697ms/step - loss: 0.4591 - accuracy: 0.8629 - val_loss: 0.4802 - val_accuracy: 0.8605\nEpoch 30/60\n52/52 [==============================] - 36s 701ms/step - loss: 0.4508 - accuracy: 0.8629 - val_loss: 0.4716 - val_accuracy: 0.8614\nEpoch 31/60\n52/52 [==============================] - 36s 701ms/step - loss: 0.4336 - accuracy: 0.8599 - val_loss: 0.5039 - val_accuracy: 0.8542\nEpoch 32/60\n52/52 [==============================] - 36s 700ms/step - loss: 0.4247 - accuracy: 0.8611 - val_loss: 0.5049 - val_accuracy: 0.8605\nEpoch 33/60\n52/52 [==============================] - 36s 702ms/step - loss: 0.4373 - accuracy: 0.8617 - val_loss: 0.4856 - val_accuracy: 0.8623\nEpoch 34/60\n52/52 [==============================] - 33s 645ms/step - loss: 0.4312 - accuracy: 0.8611 - val_loss: 0.5016 - val_accuracy: 0.8623\nEpoch 35/60\n52/52 [==============================] - 34s 647ms/step - loss: 0.4476 - accuracy: 0.8599 - val_loss: 0.5103 - val_accuracy: 0.8605\nEpoch 36/60\n52/52 [==============================] - 36s 695ms/step - loss: 0.4427 - accuracy: 0.8575 - val_loss: 0.4820 - val_accuracy: 0.8623\nEpoch 37/60\n52/52 [==============================] - 36s 698ms/step - loss: 0.4244 - accuracy: 0.8611 - val_loss: 0.4873 - val_accuracy: 0.8605\nEpoch 38/60\n52/52 [==============================] - 36s 700ms/step - loss: 0.4245 - accuracy: 0.8611 - val_loss: 0.5035 - val_accuracy: 0.8623\nEpoch 39/60\n52/52 [==============================] - 36s 701ms/step - loss: 0.4196 - accuracy: 0.8617 - val_loss: 0.5283 - val_accuracy: 0.8623\nEpoch 40/60\n52/52 [==============================] - 33s 645ms/step - loss: 0.4202 - accuracy: 0.8605 - val_loss: 0.4836 - val_accuracy: 0.8505\nEpoch 41/60\n52/52 [==============================] - 36s 700ms/step - loss: 0.4069 - accuracy: 0.8684 - val_loss: 0.5011 - val_accuracy: 0.8433\nEpoch 42/60\n52/52 [==============================] - 36s 701ms/step - loss: 0.4198 - accuracy: 0.8653 - val_loss: 0.4870 - val_accuracy: 0.8514\nEpoch 43/60\n52/52 [==============================] - 36s 697ms/step - loss: 0.4256 - accuracy: 0.8641 - val_loss: 0.4734 - val_accuracy: 0.8614\nEpoch 44/60\n52/52 [==============================] - 33s 642ms/step - loss: 0.4287 - accuracy: 0.8684 - val_loss: 0.4897 - val_accuracy: 0.8632\nEpoch 45/60\n52/52 [==============================] - 36s 702ms/step - loss: 0.4029 - accuracy: 0.8684 - val_loss: 0.5280 - val_accuracy: 0.8587\nEpoch 46/60\n52/52 [==============================] - 36s 700ms/step - loss: 0.4088 - accuracy: 0.8720 - val_loss: 0.5223 - val_accuracy: 0.8614\nEpoch 47/60\n52/52 [==============================] - 36s 700ms/step - loss: 0.3964 - accuracy: 0.8659 - val_loss: 0.5758 - val_accuracy: 0.8542\nEpoch 48/60\n52/52 [==============================] - 33s 645ms/step - loss: 0.4036 - accuracy: 0.8678 - val_loss: 0.5828 - val_accuracy: 0.8533\nEpoch 49/60\n52/52 [==============================] - 33s 645ms/step - loss: 0.4134 - accuracy: 0.8678 - val_loss: 0.5105 - val_accuracy: 0.8460\nEpoch 50/60\n52/52 [==============================] - 36s 700ms/step - loss: 0.3962 - accuracy: 0.8653 - val_loss: 0.4910 - val_accuracy: 0.8623\nEpoch 51/60\n52/52 [==============================] - 36s 700ms/step - loss: 0.3949 - accuracy: 0.8659 - val_loss: 0.5897 - val_accuracy: 0.8623\nEpoch 52/60\n52/52 [==============================] - 33s 644ms/step - loss: 0.4104 - accuracy: 0.8659 - val_loss: 0.5098 - val_accuracy: 0.8623\nEpoch 53/60\n52/52 [==============================] - 36s 694ms/step - loss: 0.4037 - accuracy: 0.8684 - val_loss: 0.4987 - val_accuracy: 0.8551\nEpoch 54/60\n52/52 [==============================] - 33s 644ms/step - loss: 0.4085 - accuracy: 0.8665 - val_loss: 0.5543 - val_accuracy: 0.8605\nEpoch 55/60\n52/52 [==============================] - 33s 644ms/step - loss: 0.4052 - accuracy: 0.8647 - val_loss: 0.4964 - val_accuracy: 0.8460\nEpoch 56/60\n52/52 [==============================] - 36s 701ms/step - loss: 0.4173 - accuracy: 0.8678 - val_loss: 0.7051 - val_accuracy: 0.8614\nEpoch 57/60\n52/52 [==============================] - 33s 645ms/step - loss: 0.4019 - accuracy: 0.8696 - val_loss: 0.5727 - val_accuracy: 0.8623\nEpoch 58/60\n52/52 [==============================] - 36s 701ms/step - loss: 0.3891 - accuracy: 0.8702 - val_loss: 0.6428 - val_accuracy: 0.8333\nEpoch 59/60\n52/52 [==============================] - 36s 700ms/step - loss: 0.3999 - accuracy: 0.8653 - val_loss: 0.7219 - val_accuracy: 0.8614\nEpoch 60/60\n52/52 [==============================] - 36s 701ms/step - loss: 0.3965 - accuracy: 0.8641 - val_loss: 0.6675 - val_accuracy: 0.8623\n","output_type":"stream"}]},{"cell_type":"code","source":"cnn_bilstm = keras.models.Sequential()\n\ncnn_bilstm.add(keras.layers.Conv2D(32, \n                              kernel_size=(3,3), \n                              activation='relu', \n                              strides=(1,1), \n                              input_shape=(350, 350, 3)))\ncnn_bilstm.add(keras.layers.MaxPooling2D((2,2)))\ncnn_bilstm.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\ncnn_bilstm.add(keras.layers.Dropout(0.2))\ncnn_bilstm.add(keras.layers.MaxPooling2D((4,4)))\ncnn_bilstm.add(keras.layers.Reshape((-1, 64)))\n\ncnn_bilstm.add(keras.layers.Bidirectional(keras.layers.LSTM(64, activation='tanh', return_sequences=True)))\ncnn_bilstm.add(keras.layers.Bidirectional(keras.layers.LSTM(128, activation='tanh', return_sequences=True)))\ncnn_bilstm.add(keras.layers.Dropout(0.5))\ncnn_bilstm.add(keras.layers.Bidirectional(keras.layers.LSTM(64, activation='tanh')))\n\ncnn_bilstm.add(keras.layers.Dense(64, activation='relu'))\ncnn_bilstm.add(keras.layers.Dense(8, activation='softmax'))\n\nprint(cnn_bilstm.summary())\n\ncnn_bilstm.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(1e-3), metrics=['accuracy'])\n\nhistory_cnn_bilstm = cnn_bilstm.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-12T05:06:49.588808Z","iopub.execute_input":"2023-08-12T05:06:49.589297Z","iopub.status.idle":"2023-08-12T05:29:00.040513Z","shell.execute_reply.started":"2023-08-12T05:06:49.589254Z","shell.execute_reply":"2023-08-12T05:29:00.038849Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Model: \"sequential_6\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_12 (Conv2D)          (None, 348, 348, 32)      896       \n                                                                 \n max_pooling2d_12 (MaxPoolin  (None, 174, 174, 32)     0         \n g2D)                                                            \n                                                                 \n conv2d_13 (Conv2D)          (None, 172, 172, 64)      18496     \n                                                                 \n dropout_11 (Dropout)        (None, 172, 172, 64)      0         \n                                                                 \n max_pooling2d_13 (MaxPoolin  (None, 43, 43, 64)       0         \n g2D)                                                            \n                                                                 \n reshape_5 (Reshape)         (None, 1849, 64)          0         \n                                                                 \n bidirectional_15 (Bidirecti  (None, 1849, 128)        66048     \n onal)                                                           \n                                                                 \n bidirectional_16 (Bidirecti  (None, 1849, 256)        263168    \n onal)                                                           \n                                                                 \n dropout_12 (Dropout)        (None, 1849, 256)         0         \n                                                                 \n bidirectional_17 (Bidirecti  (None, 128)              164352    \n onal)                                                           \n                                                                 \n dense_13 (Dense)            (None, 64)                8256      \n                                                                 \n dense_14 (Dense)            (None, 8)                 520       \n                                                                 \n=================================================================\nTotal params: 521,736\nTrainable params: 521,736\nNon-trainable params: 0\n_________________________________________________________________\nNone\nEpoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"2023-08-12 05:06:59.552744: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_6/dropout_11/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"52/52 [==============================] - 50s 755ms/step - loss: 0.7237 - accuracy: 0.8400 - val_loss: 0.6263 - val_accuracy: 0.8623\nEpoch 2/60\n52/52 [==============================] - 37s 721ms/step - loss: 0.6405 - accuracy: 0.8617 - val_loss: 0.6182 - val_accuracy: 0.8623\nEpoch 3/60\n52/52 [==============================] - 37s 720ms/step - loss: 0.6220 - accuracy: 0.8617 - val_loss: 0.6334 - val_accuracy: 0.8623\nEpoch 4/60\n52/52 [==============================] - 37s 720ms/step - loss: 0.6199 - accuracy: 0.8617 - val_loss: 0.5988 - val_accuracy: 0.8623\nEpoch 5/60\n52/52 [==============================] - 37s 720ms/step - loss: 0.6095 - accuracy: 0.8617 - val_loss: 0.5727 - val_accuracy: 0.8623\nEpoch 6/60\n52/52 [==============================] - 37s 720ms/step - loss: 0.6050 - accuracy: 0.8617 - val_loss: 0.5851 - val_accuracy: 0.8623\nEpoch 7/60\n52/52 [==============================] - 35s 678ms/step - loss: 0.5787 - accuracy: 0.8617 - val_loss: 0.6968 - val_accuracy: 0.8623\nEpoch 8/60\n52/52 [==============================] - 37s 721ms/step - loss: 0.5936 - accuracy: 0.8617 - val_loss: 0.5842 - val_accuracy: 0.8623\nEpoch 9/60\n52/52 [==============================] - 37s 722ms/step - loss: 0.6167 - accuracy: 0.8617 - val_loss: 0.5939 - val_accuracy: 0.8623\nEpoch 10/60\n52/52 [==============================] - 37s 721ms/step - loss: 0.6101 - accuracy: 0.8617 - val_loss: 0.5675 - val_accuracy: 0.8623\nEpoch 11/60\n52/52 [==============================] - 37s 721ms/step - loss: 0.5920 - accuracy: 0.8617 - val_loss: 0.5896 - val_accuracy: 0.8623\nEpoch 12/60\n52/52 [==============================] - 37s 722ms/step - loss: 0.5671 - accuracy: 0.8617 - val_loss: 0.5822 - val_accuracy: 0.8623\nEpoch 13/60\n52/52 [==============================] - 37s 716ms/step - loss: 0.6032 - accuracy: 0.8617 - val_loss: 0.5752 - val_accuracy: 0.8623\nEpoch 14/60\n52/52 [==============================] - 37s 720ms/step - loss: 0.6059 - accuracy: 0.8617 - val_loss: 0.5708 - val_accuracy: 0.8623\nEpoch 15/60\n52/52 [==============================] - 37s 721ms/step - loss: 0.5850 - accuracy: 0.8617 - val_loss: 0.5783 - val_accuracy: 0.8623\nEpoch 16/60\n52/52 [==============================] - 37s 723ms/step - loss: 0.5704 - accuracy: 0.8617 - val_loss: 0.7667 - val_accuracy: 0.8623\nEpoch 17/60\n52/52 [==============================] - 37s 721ms/step - loss: 0.5977 - accuracy: 0.8617 - val_loss: 0.6025 - val_accuracy: 0.8623\nEpoch 18/60\n52/52 [==============================] - 37s 715ms/step - loss: 0.5677 - accuracy: 0.8617 - val_loss: 0.6119 - val_accuracy: 0.8623\nEpoch 19/60\n52/52 [==============================] - 37s 719ms/step - loss: 0.5627 - accuracy: 0.8617 - val_loss: 0.6286 - val_accuracy: 0.8623\nEpoch 20/60\n52/52 [==============================] - 37s 720ms/step - loss: 0.5656 - accuracy: 0.8617 - val_loss: 0.6658 - val_accuracy: 0.8623\nEpoch 21/60\n52/52 [==============================] - 37s 719ms/step - loss: 0.5685 - accuracy: 0.8617 - val_loss: 0.5707 - val_accuracy: 0.8623\nEpoch 22/60\n52/52 [==============================] - 37s 721ms/step - loss: 0.5881 - accuracy: 0.8617 - val_loss: 0.7125 - val_accuracy: 0.8623\nEpoch 23/60\n52/52 [==============================] - 37s 720ms/step - loss: 0.5964 - accuracy: 0.8617 - val_loss: 0.6375 - val_accuracy: 0.8623\nEpoch 24/60\n52/52 [==============================] - 37s 716ms/step - loss: 0.5845 - accuracy: 0.8617 - val_loss: 0.5515 - val_accuracy: 0.8623\nEpoch 25/60\n52/52 [==============================] - 35s 680ms/step - loss: 0.5687 - accuracy: 0.8617 - val_loss: 0.5723 - val_accuracy: 0.8623\nEpoch 26/60\n52/52 [==============================] - 37s 721ms/step - loss: 0.5516 - accuracy: 0.8617 - val_loss: 0.6015 - val_accuracy: 0.8623\nEpoch 27/60\n52/52 [==============================] - 35s 679ms/step - loss: 0.5273 - accuracy: 0.8617 - val_loss: 0.5826 - val_accuracy: 0.8623\nEpoch 28/60\n52/52 [==============================] - 37s 721ms/step - loss: 0.5512 - accuracy: 0.8617 - val_loss: 0.5902 - val_accuracy: 0.8623\nEpoch 29/60\n52/52 [==============================] - 37s 720ms/step - loss: 0.5242 - accuracy: 0.8617 - val_loss: 0.6511 - val_accuracy: 0.8623\nEpoch 30/60\n52/52 [==============================] - 37s 716ms/step - loss: 0.5242 - accuracy: 0.8617 - val_loss: 0.5809 - val_accuracy: 0.8623\nEpoch 31/60\n52/52 [==============================] - 37s 720ms/step - loss: 0.5454 - accuracy: 0.8617 - val_loss: 0.6545 - val_accuracy: 0.8623\nEpoch 32/60\n52/52 [==============================] - 37s 720ms/step - loss: 0.5803 - accuracy: 0.8617 - val_loss: 0.6429 - val_accuracy: 0.8623\nEpoch 33/60\n52/52 [==============================] - 37s 720ms/step - loss: 0.6084 - accuracy: 0.8617 - val_loss: 0.5829 - val_accuracy: 0.8623\nEpoch 34/60\n52/52 [==============================] - 37s 722ms/step - loss: 0.5437 - accuracy: 0.8617 - val_loss: 0.6324 - val_accuracy: 0.8623\nEpoch 35/60\n52/52 [==============================] - 37s 717ms/step - loss: 0.5287 - accuracy: 0.8617 - val_loss: 0.6485 - val_accuracy: 0.8623\nEpoch 36/60\n35/52 [===================>..........] - ETA: 8s - loss: 0.5555 - accuracy: 0.8652","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(cnn_bilstm\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     24\u001b[0m cnn_bilstm\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m1e-3\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 26\u001b[0m history_cnn_bilstm \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_bilstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"cnn_gru = keras.models.Sequential()\ncnn_gru.add(keras.layers.Conv2D(32, \n                              kernel_size=(3,3), \n                              activation='relu', \n                              strides=(1,1), \n                              input_shape=(350, 350, 3)))\ncnn_gru.add(keras.layers.MaxPooling2D((2,2)))\ncnn_gru.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\ncnn_gru.add(keras.layers.Dropout(0.2))\ncnn_gru.add(keras.layers.MaxPooling2D((4,4)))\ncnn_gru.add(keras.layers.Reshape((-1, 64)))\n\ncnn_gru.add(keras.layers.GRU(64, activation='tanh', return_sequences=True))\ncnn_gru.add(keras.layers.GRU(128, activation='tanh', return_sequences=True))\ncnn_gru.add(keras.layers.Dropout(0.5))\ncnn_gru.add(keras.layers.GRU(64, activation='tanh'))\n\ncnn_gru.add(keras.layers.Dense(64, activation='relu'))\ncnn_gru.add(keras.layers.Dense(8, activation='softmax'))\n\ncnn_gru.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(1e-3), metrics=['accuracy'])\n\nhistory_cnn_gru = cnn_gru.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-12T05:29:11.115988Z","iopub.execute_input":"2023-08-12T05:29:11.116415Z","iopub.status.idle":"2023-08-12T05:49:39.277630Z","shell.execute_reply.started":"2023-08-12T05:29:11.116374Z","shell.execute_reply":"2023-08-12T05:49:39.276389Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"2023-08-12 05:29:17.026203: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_7/dropout_13/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"52/52 [==============================] - 27s 395ms/step - loss: 0.6963 - accuracy: 0.8502 - val_loss: 0.5968 - val_accuracy: 0.8623\nEpoch 2/60\n52/52 [==============================] - 19s 358ms/step - loss: 0.6076 - accuracy: 0.8617 - val_loss: 0.5647 - val_accuracy: 0.8623\nEpoch 3/60\n52/52 [==============================] - 20s 387ms/step - loss: 0.6015 - accuracy: 0.8617 - val_loss: 0.5598 - val_accuracy: 0.8623\nEpoch 4/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.5714 - accuracy: 0.8617 - val_loss: 0.5832 - val_accuracy: 0.8623\nEpoch 5/60\n52/52 [==============================] - 20s 388ms/step - loss: 0.5652 - accuracy: 0.8617 - val_loss: 0.5806 - val_accuracy: 0.8623\nEpoch 6/60\n52/52 [==============================] - 20s 382ms/step - loss: 0.5533 - accuracy: 0.8617 - val_loss: 0.5238 - val_accuracy: 0.8623\nEpoch 7/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.5418 - accuracy: 0.8617 - val_loss: 0.5179 - val_accuracy: 0.8623\nEpoch 8/60\n52/52 [==============================] - 20s 386ms/step - loss: 0.5253 - accuracy: 0.8617 - val_loss: 0.5625 - val_accuracy: 0.8623\nEpoch 9/60\n52/52 [==============================] - 20s 380ms/step - loss: 0.5347 - accuracy: 0.8617 - val_loss: 0.5369 - val_accuracy: 0.8623\nEpoch 10/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.5705 - accuracy: 0.8617 - val_loss: 0.5255 - val_accuracy: 0.8623\nEpoch 11/60\n52/52 [==============================] - 20s 386ms/step - loss: 0.5174 - accuracy: 0.8617 - val_loss: 0.5729 - val_accuracy: 0.8623\nEpoch 12/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.4996 - accuracy: 0.8617 - val_loss: 0.5103 - val_accuracy: 0.8623\nEpoch 13/60\n52/52 [==============================] - 19s 361ms/step - loss: 0.4806 - accuracy: 0.8617 - val_loss: 0.5238 - val_accuracy: 0.8623\nEpoch 14/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.4865 - accuracy: 0.8617 - val_loss: 0.5576 - val_accuracy: 0.8623\nEpoch 15/60\n52/52 [==============================] - 20s 380ms/step - loss: 0.5046 - accuracy: 0.8617 - val_loss: 0.4949 - val_accuracy: 0.8623\nEpoch 16/60\n52/52 [==============================] - 20s 387ms/step - loss: 0.4686 - accuracy: 0.8605 - val_loss: 0.5075 - val_accuracy: 0.8623\nEpoch 17/60\n52/52 [==============================] - 20s 380ms/step - loss: 0.4758 - accuracy: 0.8623 - val_loss: 0.5661 - val_accuracy: 0.8623\nEpoch 18/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.4707 - accuracy: 0.8617 - val_loss: 0.6385 - val_accuracy: 0.8089\nEpoch 19/60\n52/52 [==============================] - 20s 387ms/step - loss: 0.4688 - accuracy: 0.8623 - val_loss: 0.5172 - val_accuracy: 0.8632\nEpoch 20/60\n52/52 [==============================] - 20s 382ms/step - loss: 0.4530 - accuracy: 0.8617 - val_loss: 0.5631 - val_accuracy: 0.8623\nEpoch 21/60\n52/52 [==============================] - 20s 387ms/step - loss: 0.4493 - accuracy: 0.8641 - val_loss: 0.6161 - val_accuracy: 0.8406\nEpoch 22/60\n52/52 [==============================] - 20s 387ms/step - loss: 0.4591 - accuracy: 0.8623 - val_loss: 0.5907 - val_accuracy: 0.8478\nEpoch 23/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.4379 - accuracy: 0.8635 - val_loss: 0.6609 - val_accuracy: 0.8143\nEpoch 24/60\n52/52 [==============================] - 20s 386ms/step - loss: 0.4251 - accuracy: 0.8641 - val_loss: 0.5113 - val_accuracy: 0.8524\nEpoch 25/60\n52/52 [==============================] - 20s 380ms/step - loss: 0.4355 - accuracy: 0.8605 - val_loss: 0.6011 - val_accuracy: 0.8469\nEpoch 26/60\n52/52 [==============================] - 18s 354ms/step - loss: 0.4099 - accuracy: 0.8635 - val_loss: 0.7292 - val_accuracy: 0.8025\nEpoch 27/60\n52/52 [==============================] - 19s 360ms/step - loss: 0.4091 - accuracy: 0.8659 - val_loss: 0.5254 - val_accuracy: 0.8533\nEpoch 28/60\n52/52 [==============================] - 20s 382ms/step - loss: 0.4075 - accuracy: 0.8641 - val_loss: 0.6103 - val_accuracy: 0.8089\nEpoch 29/60\n52/52 [==============================] - 20s 385ms/step - loss: 0.3978 - accuracy: 0.8665 - val_loss: 0.4799 - val_accuracy: 0.8560\nEpoch 30/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.4014 - accuracy: 0.8678 - val_loss: 0.4771 - val_accuracy: 0.8614\nEpoch 31/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.4008 - accuracy: 0.8671 - val_loss: 0.5584 - val_accuracy: 0.8243\nEpoch 32/60\n52/52 [==============================] - 20s 385ms/step - loss: 0.4151 - accuracy: 0.8684 - val_loss: 0.5315 - val_accuracy: 0.8252\nEpoch 33/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.3857 - accuracy: 0.8671 - val_loss: 0.5031 - val_accuracy: 0.8569\nEpoch 34/60\n52/52 [==============================] - 20s 382ms/step - loss: 0.3888 - accuracy: 0.8671 - val_loss: 0.5842 - val_accuracy: 0.8007\nEpoch 35/60\n52/52 [==============================] - 20s 386ms/step - loss: 0.3604 - accuracy: 0.8732 - val_loss: 0.6169 - val_accuracy: 0.8361\nEpoch 36/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.3551 - accuracy: 0.8768 - val_loss: 0.6835 - val_accuracy: 0.7754\nEpoch 37/60\n52/52 [==============================] - 20s 386ms/step - loss: 0.3627 - accuracy: 0.8708 - val_loss: 0.5234 - val_accuracy: 0.8415\nEpoch 38/60\n52/52 [==============================] - 19s 362ms/step - loss: 0.3569 - accuracy: 0.8756 - val_loss: 0.4951 - val_accuracy: 0.8451\nEpoch 39/60\n52/52 [==============================] - 18s 356ms/step - loss: 0.3647 - accuracy: 0.8786 - val_loss: 0.6493 - val_accuracy: 0.8143\nEpoch 40/60\n52/52 [==============================] - 19s 360ms/step - loss: 0.3395 - accuracy: 0.8841 - val_loss: 0.5526 - val_accuracy: 0.8134\nEpoch 41/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.3367 - accuracy: 0.8810 - val_loss: 0.5262 - val_accuracy: 0.8261\nEpoch 42/60\n52/52 [==============================] - 20s 386ms/step - loss: 0.3695 - accuracy: 0.8756 - val_loss: 0.4852 - val_accuracy: 0.8505\nEpoch 43/60\n52/52 [==============================] - 20s 387ms/step - loss: 0.3412 - accuracy: 0.8816 - val_loss: 0.5720 - val_accuracy: 0.8034\nEpoch 44/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.3489 - accuracy: 0.8804 - val_loss: 0.6296 - val_accuracy: 0.8080\nEpoch 45/60\n52/52 [==============================] - 20s 385ms/step - loss: 0.3465 - accuracy: 0.8841 - val_loss: 0.5922 - val_accuracy: 0.8216\nEpoch 46/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.3222 - accuracy: 0.8865 - val_loss: 0.5347 - val_accuracy: 0.8514\nEpoch 47/60\n52/52 [==============================] - 18s 355ms/step - loss: 0.3310 - accuracy: 0.8895 - val_loss: 0.5707 - val_accuracy: 0.8197\nEpoch 48/60\n52/52 [==============================] - 19s 359ms/step - loss: 0.3186 - accuracy: 0.8871 - val_loss: 0.7298 - val_accuracy: 0.8487\nEpoch 49/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.3207 - accuracy: 0.8877 - val_loss: 0.8212 - val_accuracy: 0.8587\nEpoch 50/60\n52/52 [==============================] - 20s 387ms/step - loss: 0.3219 - accuracy: 0.8780 - val_loss: 0.5840 - val_accuracy: 0.8496\nEpoch 51/60\n52/52 [==============================] - 20s 383ms/step - loss: 0.3066 - accuracy: 0.8907 - val_loss: 0.5743 - val_accuracy: 0.8379\nEpoch 52/60\n52/52 [==============================] - 18s 356ms/step - loss: 0.2981 - accuracy: 0.8925 - val_loss: 0.7069 - val_accuracy: 0.7989\nEpoch 53/60\n52/52 [==============================] - 19s 361ms/step - loss: 0.3006 - accuracy: 0.8949 - val_loss: 0.6816 - val_accuracy: 0.7889\nEpoch 54/60\n52/52 [==============================] - 20s 380ms/step - loss: 0.3111 - accuracy: 0.8943 - val_loss: 0.6052 - val_accuracy: 0.8225\nEpoch 55/60\n52/52 [==============================] - 20s 385ms/step - loss: 0.2871 - accuracy: 0.9004 - val_loss: 0.6487 - val_accuracy: 0.8279\nEpoch 56/60\n52/52 [==============================] - 20s 385ms/step - loss: 0.2807 - accuracy: 0.8998 - val_loss: 0.6497 - val_accuracy: 0.8324\nEpoch 57/60\n52/52 [==============================] - 20s 380ms/step - loss: 0.2784 - accuracy: 0.9022 - val_loss: 0.6519 - val_accuracy: 0.8406\nEpoch 58/60\n52/52 [==============================] - 19s 359ms/step - loss: 0.2900 - accuracy: 0.8992 - val_loss: 0.7011 - val_accuracy: 0.8342\nEpoch 59/60\n52/52 [==============================] - 19s 359ms/step - loss: 0.3006 - accuracy: 0.8961 - val_loss: 0.7116 - val_accuracy: 0.8098\nEpoch 60/60\n52/52 [==============================] - 20s 381ms/step - loss: 0.2818 - accuracy: 0.9028 - val_loss: 0.6739 - val_accuracy: 0.8397\n","output_type":"stream"}]},{"cell_type":"code","source":"cnn_lstm = keras.models.Sequential()\n\ncnn_lstm.add(keras.layers.Conv2D(32, \n                              kernel_size=(3,3), \n                              activation='relu', \n                              strides=(1,1), \n                              input_shape=(350, 350, 3)))\ncnn_lstm.add(keras.layers.MaxPooling2D((2,2)))\ncnn_lstm.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\ncnn_lstm.add(keras.layers.Dropout(0.2))\ncnn_lstm.add(keras.layers.MaxPooling2D((4,4)))\ncnn_lstm.add(keras.layers.Reshape((-1, 64)))\n\ncnn_lstm.add(keras.layers.LSTM(64, activation='tanh', return_sequences=True))\ncnn_lstm.add(keras.layers.LSTM(128, activation='tanh', return_sequences=True))\ncnn_lstm.add(keras.layers.Dropout(0.5))\ncnn_lstm.add(keras.layers.LSTM(64, activation='tanh'))\n\ncnn_lstm.add(keras.layers.Dense(64, activation='relu'))\ncnn_lstm.add(keras.layers.Dense(8, activation='softmax'))\n\nprint(cnn_lstm.summary())\n\ncnn_lstm.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(1e-5), metrics=['accuracy'])\n\nhistory_cnn_lstm = cnn_lstm.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-12T04:29:51.422721Z","iopub.status.idle":"2023-08-12T04:29:51.423479Z","shell.execute_reply.started":"2023-08-12T04:29:51.423247Z","shell.execute_reply":"2023-08-12T04:29:51.423270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}